{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KwQ8Zp3llyi-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666498638912,"user_tz":300,"elapsed":18366,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}},"outputId":"a79c38d5-6bd5-4f3b-d3bb-23c6f5fc1b4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","    import sys\n","    from google.colab import drive, output\n","    drive.mount('/content/drive')\n","    !pip install torchaudio\n","    !pip install wandb --upgrade\n","    !wandb login\n","    output.clear()\n","    %load_ext autoreload\n","    %autoreload 1\n","    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n","    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n","    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n","else:\n","    \"Running local\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8418,"status":"ok","timestamp":1666498647322,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"ZeYXtNUUhRWh","outputId":"d02f9bde-4f9f-49b7-d396-38eb63643a9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielnieto\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["# from __future__ import print_function\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from six.moves import xrange\n","import datetime\n","import gc\n","\n","from scipy import signal\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import torchaudio.transforms as audio_transform\n","\n","#from ResidualStack import ResidualStack\n","#from Residual import Residual\n","\n","from Jaguas_DataLoader_HPSS import SoundscapeData\n","from Models import ConvAE as AE\n","from AE_training_functions import TestModel, TrainModel\n","from AE_Clustering import AE_Clustering \n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = xm.xla_device()\n","print(device)\n","\n","from datetime import timedelta\n","import wandb\n","from wandb import AlertLevel\n","wandb.login()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cMG_87FKb26h","executionInfo":{"status":"ok","timestamp":1666498656952,"user_tz":300,"elapsed":9633,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}}},"outputs":[],"source":["root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Jaguas_2018'\n","\n","\n","dataset = SoundscapeData(root_path, audio_length=12, ext=\"wav\", win_length=1028)\n","dataset_train, dataset_test = random_split(dataset,\n","                                           [round(len(dataset)*0.3), len(dataset) - round(len(dataset)*0.3)], \n","                                           generator=torch.Generator().manual_seed(1024))\n","\n","config = {\n","    \"project\" : \"AE-Jaguas\",\n","    \"audio_length\": dataset.audio_length,\n","    \"batch_size\" : 14,\n","    \"num_epochs\": 6,\n","    \"num_hiddens\" : 64,\n","    \"gamma_lr\" : 0.1,\n","    \"learning_rate\" : 1e-2,\n","    \"dataset\" : \"Audios Jaguas\",\n","    \"architecture\": \"AE_hpss_h\",\n","    \"win_length\" : dataset.win_length\n","}\n","\n","torch.save(dataset_test, \"temporal/dataset_test_ae_jaguas_hpss\")\n","training_loader = DataLoader(dataset_train, batch_size=config[\"batch_size\"])\n","test_loader = DataLoader(dataset_test, batch_size=config[\"batch_size\"])\n","\n","\n","model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], amsgrad=False)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size = 2, gamma = config[\"gamma_lr\"] )\n","\n","config[\"optimizer\"] = optimizer\n","config[\"scheduler\"] = scheduler\n","config[\"num_training_updates\"] = len(training_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6YtKCwnNnDYP","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1mOmMqdngn5P2LWWcoeZU4w1fcbLuCJyi"},"outputId":"1cb01c81-acda-42be-dd58-764f843d5c84"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["Training = TrainModel(model)\n","model, logs, run_name = Training.fordward(training_loader, test_loader, config)\n","time = datetime.datetime.now()\n","torch.save(model.state_dict(),f'{run_name}_day_{time.day}_hour_{time.hour}.pkl')\n","torch.save(config,f'config_{run_name}_day_{time.day}_hour_{time.hour}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5sjhlDScl3G"},"outputs":[],"source":["model.load_state_dict(torch.load(f'Models/AE_audio_length_12_win_length_1028_batch_size 8_epoch_6_23_55.pkl', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mBePtMUv5MD7"},"outputs":[],"source":["root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Porce_2019'\n","\n","\n","dataset = SoundscapeData(root_path, audio_length=12, ext=\"WAV\", win_length=1028)\n","dataset_train, dataset_test = random_split(dataset,\n","                                           [round(len(dataset)*0.7), len(dataset) - round(len(dataset)*0.7)], \n","                                           generator=torch.Generator().manual_seed(1024))\n","Dataset_train = DataLoader(dataset_train, batch_size=54, shuffle=True)\n","Dataset = DataLoader(dataset_test, batch_size=54, shuffle=True)\n","\n","training_loader = DataLoader(dataset_train, batch_size=config[\"batch_size\"])\n","test_loader = DataLoader(dataset_test, batch_size=config[\"batch_size\"])\n","iterator = iter(test_loader)\n","testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWREIMjnUf9x"},"outputs":[],"source":["originals, reconstructions, encodings, label, loss= testing.run()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFQvOLxb7Ytc"},"outputs":[],"source":["wav_origin=testing.waveform_generator(spec=originals)\n","print(wav_origin[0:1])\n","wav_origin = np.interp(wav_origin, (wav_origin.min(), wav_origin.max()), (-1, +1))\n","print(wav_origin[0:1])\n","wav_recons=testing.waveform_generator(spec=reconstructions)\n","wav_recons= np.interp(wav_recons, (wav_recons.min(), wav_recons.max()), (-1, +1))\n","testing.plot_psd(wav_origin[0:4],2)\n","testing.plot_psd(wav_origin[10:14],2)\n","#testing.plot_psd(wav_origin[18:22],2)\n","plt.savefig(\"original_psd.pdf\")\n","plt.figure()\n","testing.plot_psd(wav_recons[0:4],2)\n","testing.plot_psd(wav_recons[10:14],2)\n","#testing.plot_psd(wav_recons[18:22],2)\n","plt.savefig(\"recon_psd.pdf\")\n","wav_diff = wav_origin-wav_recons\n","plt.figure()\n","testing.plot_psd(wav_diff,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBEMoCDtUhDZ"},"outputs":[],"source":["wav_origin=testing.waveform_generator(spec=originals)\n","print(wav_origin[0:1])\n","wav_origin = np.interp(wav_origin, (wav_origin.min(), wav_origin.max()), (-1, +1))\n","print(wav_origin[0:1])\n","wav_recons=testing.waveform_generator(spec=reconstructions)\n","wav_recons= np.interp(wav_recons, (wav_recons.min(), wav_recons.max()), (-1, +1))\n","testing.plot_psd(wav_origin,4)\n","plt.savefig(\"original_psd.pdf\")\n","plt.figure()\n","testing.plot_psd(wav_recons,4)\n","plt.savefig(\"recon_psd.pdf\")\n","wav_diff = wav_origin-wav_recons\n","plt.figure()\n","testing.plot_psd(wav_diff,4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0E_jW1OyNlm"},"outputs":[],"source":["plt.plot(wav_origin[11,0])\n","plt.plot(wav_recons[11,0], color='red', alpha = 0.4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUNZFPQNmhEj"},"outputs":[],"source":["iterator_Dataset = iter(Dataset)\n","testing = TestModel(model, iterator_Dataset, device=torch.device(\"cuda\"))\n","Clustering = AE_Clustering(testing, Dataset, 54)\n","kmeans = Clustering.fordward()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs-21vU9cBBT"},"outputs":[],"source":["Clustering.plot_centroids()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68wxgeupqxBv"},"outputs":[],"source":["encodings_size = [64,9,9]\n","plt.figure(figsize=(18, 18))\n","model.to(\"cpu\")\n","for i, spec in enumerate(kmeans.cluster_centers_):\n","    encodings = spec.reshape(encodings_size)\n","    encodings = torch.tensor(encodings).float()\n","    decodings = model.decoder(encodings).detach().numpy()\n","    plt.subplot(9, 9, i + 1)\n","    plt.imshow(decodings[0,:,:], cmap=\"inferno\", interpolation=\"nearest\",vmin=0, vmax=0.02)\n","    plt.xticks(())\n","    plt.yticks(())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPQR_aIPcZ7-"},"outputs":[],"source":["from scipy.io.wavfile import write\n","\n","class TestModel:\n","\n","    def __init__(self, model, iterator, num_views):\n","        self._model = model\n","        self._iterator = iterator\n","        self.num_views = num_views\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    def save_waveform(self, waveform, directory=None):\n","        scaled = np.int16(waveform[0,0]/np.max(np.abs(waveform[0,0])) * 32767)\n","        write(directory + '.wav', 22050, scaled)\n","\n","    def plot_waveform(self, waveform, n_rows=4):\n","        fig, axs = plt.subplots(n_rows, figsize=(10, 6), constrained_layout=True)\n","        for i in range(n_rows):\n","            axs[i].plot(waveform[i,0])               \n","        plt.show()\n","        \n","        \n","    def waveform_generator(self, spec, n_fft=1028, win_length=1028, audio_length=12, base_win=256):\n","        spec = spec.cdouble()\n","        spec = spec.to(\"cpu\")\n","        # hop_length = int(np.round(base_win/win_length * 172.3))\n","        transformation = audio_transform.InverseSpectrogram(n_fft=n_fft, win_length=win_length)\n","        waveform = transformation(spec)\n","        waveform = waveform.cpu().detach().numpy()\n","        return waveform\n","    \n","    def plot_psd(self, waveform, n_wavs=1):\n","        for i in range(n_wavs):\n","            plt.psd(waveform[i][0])\n","            plt.xlabel(\"Frequency\", fontsize=16)\n","            plt.ylabel(\"Power Spectral Density\", fontsize=16)\n","            plt.xticks(fontsize=16)\n","            plt.yticks(fontsize=16)\n","\n","\n","\n","    def plot_reconstructions(self, imgs_original, imgs_reconstruction, num_views:int = 8):\n","        output = torch.cat((imgs_original[0:self.num_views], imgs_reconstruction[0:self.num_views]), 0)\n","        img_grid = make_grid(output, nrow=self.num_views, pad_value=20)\n","        fig, ax = plt.subplots(figsize=(20,5))\n","        ax.imshow(img_grid[1,:,:].cpu(), vmin=0, vmax=0.02, origin = \"lower\")\n","        ax.axis(\"off\")\n","        plt.show()\n","        return fig\n","\n","    def reconstruct(self):\n","        self._model.eval()\n","        (valid_originals, _, label) = next(self._iterator)\n","        valid_originals = torch.reshape(valid_originals, (valid_originals.shape[0] * valid_originals.shape[1], \n","                                                    valid_originals.shape[2], valid_originals.shape[3]))\n","        valid_originals = torch.unsqueeze(valid_originals,1)\n","\n","        valid_originals = valid_originals.to(self.device)\n","\n","        valid_encodings = self._model.encoder(valid_originals)\n","\n","        valid_reconstructions = self._model.decoder(valid_encodings)\n","\n","        valid_originals_nonorm = torch.expm1(valid_originals)\n","        valid_reconstructions_nonorm = torch.expm1(valid_reconstructions)\n","\n","        BCE = F.mse_loss(valid_reconstructions, valid_originals)\n","        loss = BCE\n","\n","        return valid_originals, valid_reconstructions, valid_encodings, label, loss\n","\n","    def run(self, plot=True, wave_return=True, wave_plot=True, directory=None):\n","        wave_original = []\n","        wave_reconstruction = []\n","        originals, reconstructions, encodings, label, error = self.reconstruct() \n","        if plot:\n","            self.plot_reconstructions(originals, reconstructions)\n","        if wave_return:\n","            wave_original = self.waveform_generator(originals)\n","            wave_reconstruction = self.waveform_generator(reconstructions)\n","            if wave_plot:\n","                self.plot_waveform(wave_original, n_rows=4)\n","                self.plot_waveform(wave_reconstruction, n_rows=4)\n","            if directory != None:\n","                dir_ori = directory+\"original_\"\n","                dir_recon = directory+\"reconstruction_\"\n","                self.save_waveform(wave_original, dir_ori)\n","                self.save_waveform(wave_reconsctruction, dir_recon)\n","\n","        return originals, reconstructions, encodings, label, error\n","\n","\n","class TrainModel:\n","\n","    def __init__(self, model):\n","        self._model = model\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    def wandb_init(self, config, keys=[\"audio_length\", \"win_length\", \"batch_size\"]):\n","        try:\n","            run_name = \"AE_\"\n","            for key in keys:\n","                if key in config.keys():\n","                    run_name = run_name + key + \":\" + str(config[key]) + \"_\"\n","                else:\n","                    run_name = run_name + str(key)\n","\n","            wandb.login()\n","            wandb.finish()\n","            wandb.init(project=\"AE-Jaguas\", config=config)\n","            wandb.run.name = run_name\n","            wandb.run.save()\n","            wandb.watch(self._model, F.mse_loss, log=\"all\", log_freq=1)\n","            is_wandb_enable = True         \n","        except Exception as e:\n","            print(e)\n","            is_wandb_enable = False\n","\n","        return is_wandb_enable, run_name\n","\n","    def wandb_logging(self, dict):\n","        for keys in dict:\n","            wandb.log({keys: dict[keys]})\n","\n","\n","    def fordward(self, training_loader, test_loader, config):\n","        iterator = iter(test_loader)\n","        wandb_enable, run_name = self.wandb_init(config)\n","        optimizer = config[\"optimizer\"]\n","        scheduler = config[\"scheduler\"]\n","\n","        train_res_recon_error = []\n","        train_res_perplexity = []\n","        logs = []\n","        best_loss = 10000\n","\n","        for epoch in range(config[\"num_epochs\"]):\n","            iterator_train = iter(training_loader)\n","            for i in xrange(config[\"num_training_updates\"]):\n","                self._model.train()\n","                try:\n","                    (data, _,_) = next(iterator_train)\n","                except Exception as e:\n","                    print(\"error\")\n","                    print(e)\n","                    logs.append(e)\n","                    continue\n","\n","                data = torch.reshape(data, (data.shape[0] * data.shape[1], data.shape[2], data.shape[3]))\n","                data = torch.unsqueeze(data,1)\n","                data = data.to(self.device)\n","\n","                optimizer.zero_grad()\n","                data_recon = self._model(data)\n","\n","                loss = F.mse_loss(data_recon, data)\n","                loss.backward()\n","\n","                optimizer.step()\n","                print(f'epoch: {epoch+1} of {config[\"num_epochs\"]} \\t iteration: {(i+1)} of {config[\"num_training_updates\"]} \\t loss: {np.round(loss.item(),4)}')\n","                dict = {\"loss\":loss.item()}\n","                self.wandb_logging(dict)\n","                                \n","                \n","                if (i+1) % 50 == 0:\n","                    try:\n","                        test_ = TestModel(self._model, iterator, 8)\n","                        #torch.save(model.state_dict(),f'model_{epoch}_{i}.pkl')\n","                        originals, reconstructions, encodings, labels, test_error = test_.reconstruct()\n","                        fig = test_.plot_reconstructions(originals, reconstructions, 8)\n","                        images = wandb.Image(fig, caption= f\"recon_error: {np.round(test_error.item(),4)}\")\n","                        self.wandb_logging({\"examples\": images, \"step\": i+1//50})\n","                        \n","                    except Exception as e:\n","                        print(\"error\")\n","                        logs.append(e)\n","                        continue\n","                else:\n","                    pass\n","\n","                if loss < 0.05:\n","                    wandb.alert(\n","                    title='High accuracy',\n","                    text=f'Recon error {loss} is lower than 0.05',\n","                    level=AlertLevel.WARN,\n","                    wait_duration=timedelta(minutes=5)\n","                                )        \n","                    torch.save(self._model.state_dict(),f'{run_name}_low_error.pkl')\n","                else:\n","                    pass\n","            \n","            scheduler.step()\n","            torch.cuda.empty_cache()\n","            time = datetime.datetime.now()\n","            torch.save(self._model.state_dict(),f'{run_name}_epoch:{epoch+1}_{time.day}_{time.hour}.pkl')\n","            output.clear()\n","            print(optimizer.state_dict()[\"param_groups\"][0][\"lr\"])\n","\n","        wandb.finish()\n","        return self._model, logs, run_name"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUEupOTUQ2kS"},"outputs":[],"source":["from sklearn.cluster import MiniBatchKMeans\n","from sklearn.manifold import TSNE\n","from sklearn.metrics.pairwise import pairwise_distances_argmin\n","from sklearn import preprocessing\n","\n","class AE_Clustering:\n","\n","    def __init__(self, AE_testing, dataset, n_clusters:int = 27):\n","        self._ae_testing = AE_testing\n","        self._dataset = dataset\n","        self._n_clusters = n_clusters\n","\n","    def labeling(self, label, repetitions:int = 4, axes:int = 0):\n","        le = preprocessing.LabelEncoder()\n","        labela = np.array(label)\n","        labels= np.repeat(label, repetitions, axes)\n","        le.fit(labels)\n","        labels = le.transform(labels)\n","        return labels\n","\n","    def plot_clusters(self, X_embedded, original_labels, cluster_labels):\n","        plt.close(\"all\")\n","        output.clear()\n","        fig = plt.figure(figsize=(15,15))\n","        ax = fig.add_subplot(2,1,1) \n","        ax.scatter(X_embedded[:,0], X_embedded[:,1],c=cluster_labels)\n","        ax = fig.add_subplot(2,1,2)\n","        ax.scatter(X_embedded[:,0], X_embedded[:,1],c=original_labels)\n","        plt.show() \n","\n","    def plot_centroids(self):\n","        plt.figure(figsize=(18, 18))\n","        self._ae_testing._model.to(\"cpu\")\n","        for i, spec in enumerate(self.kmeans.cluster_centers_):\n","            encodings = spec.reshape(self._encodings_size)\n","            encodings = torch.tensor(encodings).float()\n","            decodings = self._ae_testing._model.decoder(encodings).detach().numpy()\n","            plt.subplot(9, 9, i + 1)\n","            plt.imshow(decodings[0,:,:], cmap=\"inferno\", interpolation=\"nearest\",vmin=0, vmax=0.02)\n","            plt.xticks(())\n","            plt.yticks(())\n","\n","    def fordward(self):\n","        for id, item in enumerate(self._dataset):\n","            self._ae_testing._model.to(\"cuda\")\n","            originals, reconstructions, encodings, label, loss = self._ae_testing.reconstruct()\n","            self._encodings_size = encodings[0].shape\n","            #label = label.to(\"cpu\")\n","            labels = self.labeling(label, repetitions=4, axes=0)\n","            self.kmeans = MiniBatchKMeans(n_clusters=self._n_clusters, random_state=0)\n","            encodings = encodings.to(\"cpu\").detach()\n","            encodings = encodings.reshape(216,\n","                                        encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n","            self.kmeans = self.kmeans.partial_fit(encodings)\n","            embedding = self.kmeans.transform(encodings)\n","            mbk_means_cluster_centers = self.kmeans.cluster_centers_\n","            # mbk_means_labels = pairwise_distances_argmin(encodings, mbk_means_cluster_centers)\n","            mbk_means_labels = self.kmeans.predict(encodings)\n","            X_embedded = TSNE(n_components=2, learning_rate='auto', init='random', random_state=0).fit_transform(encodings)\n","            print(X_embedded.shape)\n","            self.plot_clusters(X_embedded, mbk_means_labels, labels)\n","        return self.kmeans\n","\n","    \n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"15FiCdrQdIiLbRJdrnLgeGSWmPZR-eIZZ","timestamp":1666495856613}],"authorship_tag":"ABX9TyNnIF5NR1VchkuzE9IuisVa"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}