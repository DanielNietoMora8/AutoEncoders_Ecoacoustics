{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1a613c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T15:11:58.425895Z",
     "start_time": "2024-08-16T15:11:58.420754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1eb0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31343"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8577b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA_ = PCA(n_components=60).fit(X_norm)\n",
    "# X_PCA = PCA_.transform(X_norm)\n",
    "# # X_TSNE = TSNE(n_components=60, learning_rate=\"auto\", init='random', random_state=0).fit_transform(X_PCA)\n",
    "# reducer = umap.UMAP(min_dist=0.9, n_components=60)\n",
    "# X_UMAP = reducer.fit_transform(X_norm)\n",
    "# X_batch = np.reshape(X_UMAP, (X_UMAP.shape[0]//5,5,X_UMAP.shape[1]))\n",
    "# # X_UMAP_Norm = Normalizer().fit_transform(X_UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2237d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_audios_Zamuro = f\"{root}/Zamuro/Complementary_Files/zamuro_audios.csv\"\n",
    "root_recorders_Zamuro = f\"{root}/Zamuro/Complementary_Files/zamuro_recorders.csv\"\n",
    "\n",
    "audios = pd.read_csv(root_audios_Zamuro, index_col=0)\n",
    "recorders = pd.read_csv(root_recorders_Zamuro, index_col=0)\n",
    "\n",
    "def combinar_nombre_ubicacion(row):\n",
    "    return f\"{row['field_number_PR']}_{row['Filename']}\"\n",
    "\n",
    "# Aplicando la funciÃ³n a cada fila del DataFrame para crear la nueva columna\n",
    "audios['Filename_'] = audios.apply(combinar_nombre_ubicacion, axis=1)\n",
    "\n",
    "audios.set_index(\"Filename_\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f927c49",
   "metadata": {},
   "source": [
    "# AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1e154a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m recalls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m  i, mod_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[0;32m---> 13\u001b[0m     X_ae \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmod_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/AE_features_Zamuro.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,  map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m     X_ae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(X_ae)\n\u001b[1;32m     15\u001b[0m     y_path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmod_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/AE_test_path_samples_Zamuro.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,  map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "models = [1,3,5,7,10,20,30,40,50]\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "recalls = []\n",
    "for  i, mod_id in enumerate(models):\n",
    "\n",
    "    X_ae = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/{mod_id}/AE_features_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "    X_ae = np.asarray(X_ae)\n",
    "    y_path = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/{mod_id}/AE_test_path_samples_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "    \n",
    "    y = np.asarray(y_path)\n",
    "    y_2 = y[:,0]\n",
    "    for i in range(len(y_2)):\n",
    "        y_2[i] = y_2[i][0:-2] \n",
    "    y_2 = list(y_2)\n",
    "    y_3 = np.repeat(y_2, 5)\n",
    "    labels_ae = []\n",
    "    for i in range(len(y_2)):\n",
    "        labels_ae.append(audios.loc[y_2[i], \"cover\"])\n",
    "        \n",
    "    X_ae = np.reshape(X_ae, [X_ae.shape[0]//5, 5, X_ae.shape[1]])\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ae, labels_ae, test_size=0.2,random_state=0)\n",
    "    \n",
    "    X_train = np.reshape(X_train, [X_train.shape[0]*5, X_train.shape[2]])\n",
    "    X_test = np.reshape(X_test, [X_test.shape[0]*5, X_test.shape[2]])\n",
    "    \n",
    "    y_train = np.repeat(y_train,5)\n",
    "    y_test = np.repeat(y_test,5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1_score)\n",
    "    recalls.append(recall)\n",
    "    \n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/accuracies.npy\", accuracies)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/f1_scores.npy\", f1_scores)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/recalls.npy\", recalls)\n",
    "\n",
    "# X_ae = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_features_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "# X_ae = np.asarray(X_ae)\n",
    "# y_path = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_test_path_samples_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "\n",
    "# scaler = StandardScaler().fit(X_ae)\n",
    "# X_scaled = scaler.transform(X_ae)\n",
    "\n",
    "# Normalizer_ = Normalizer().fit(X_ae)\n",
    "# X_norm = Normalizer_.transform(X_ae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfd858",
   "metadata": {},
   "source": [
    "## 5 segments flattened "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda905f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ae = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_features_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "X_ae = np.asarray(X_ae)\n",
    "y_path = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_test_path_samples_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "\n",
    "y = np.asarray(y_path)\n",
    "y_2 = y[:,0]\n",
    "for i in range(len(y_2)):\n",
    "    y_2[i] = y_2[i][0:-2] \n",
    "y_2 = list(y_2)\n",
    "y_3 = np.repeat(y_2, 5)\n",
    "labels_ae = []\n",
    "for i in range(len(y_3)):\n",
    "    labels_ae.append(audios.loc[y_3[i], \"cover\"])\n",
    "\n",
    "df_ae = pd.DataFrame(X_ae)\n",
    "df_ae[\"y\"] = y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d728ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts(row):\n",
    "    parts = row.split('_')\n",
    "    location = parts[0]\n",
    "    date = parts[1]\n",
    "    time = parts[2].split('.')[0]  # Eliminar la extensiÃ³n .WAV\n",
    "    day = date[-2:]  # Ãltimos dos caracteres para el dÃ­a\n",
    "    hour = time[:2]\n",
    "    return pd.Series([location, day, hour])\n",
    "\n",
    "# Aplicar la funciÃ³n a la columna 'y' y crear nuevas columnas\n",
    "df_ae[['location', 'day', 'hour']] =df_ae['y'].apply(extract_parts)\n",
    "\n",
    "def define_hour_stage(hour):\n",
    "    hour = int(hour)\n",
    "    if 5 <= hour <= 8:\n",
    "        return 'morning'\n",
    "    elif 9 <= hour <= 16:\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "df_ae['hour_stage'] =df_ae['hour'].apply(define_hour_stage)\n",
    "df_ae.set_index(\"y\", inplace=True, drop=False)\n",
    "df_ae['cover'] = df_ae.index.map(audios['cover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0937b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df_day={}\n",
    "accuracies_ae = []\n",
    "f1_scores_ae = []\n",
    "recalls_ae = []\n",
    "for i in [\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\"]:\n",
    "    df_day = df_ae[df_ae['day'].isin([i])]\n",
    "    X = np.asarray(df_day.loc[:,0:5183])\n",
    "    y = np.asarray(df_day.loc[:,\"cover\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "\n",
    "    accuracies_ae.append(accuracy)\n",
    "    f1_scores_ae.append(f1_score)\n",
    "    recalls_ae.append(recall)\n",
    "    \n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/accuracies_ae.npy\", accuracies_ae)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/f1_scores_ae.npy\", f1_scores_ae)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/recalls_ae.npy\", recalls_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7f53d",
   "metadata": {},
   "source": [
    "## UNFLAT Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26cd777",
   "metadata": {},
   "source": [
    "print(X_ae.shape)\n",
    "X_ae_unflat = np.reshape(X_ae, [X_ae.shape[0]//5,5,X_ae.shape[1]])\n",
    "print(X_ae_unflat.shape)\n",
    "X_ae_unflat2 = np.reshape(X_ae_unflat, [X_ae_unflat.shape[0], X_ae_unflat.shape[1]*X_ae_unflat.shape[2]])\n",
    "print(X_ae_unflat2.shape)\n",
    "X_ae_unflat3 = np.reshape(X_ae_unflat2, [X_ae_unflat2.shape[0], 5, X_ae_unflat2.shape[1]//5])\n",
    "print(X_ae_unflat3.shape)\n",
    "X_ae_flat = np.reshape(X_ae_unflat3, [X_ae_unflat3.shape[0]*5,X_ae_unflat3.shape[2]])\n",
    "print(X_ae_flat.shape)\n",
    "print((X_ae_flat == X_ae).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e85b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ae_unflat = np.reshape(X_ae, [X_ae.shape[0]//5,5,X_ae.shape[1]])\n",
    "# X_ae_unflat = X_ae_unflat2.mean(axis=1)\n",
    "# X_ae_unflat = np.median(X_ae_unflat, axis=1)\n",
    "X_ae_unflat = np.reshape(X_ae_unflat, [X_ae_unflat.shape[0], X_ae_unflat.shape[1]*X_ae_unflat.shape[2]])\n",
    "df_ae_unflat = pd.DataFrame(X_ae_unflat)\n",
    "df_ae_unflat[\"y\"] = y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ad1851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts(row):\n",
    "    parts = row.split('_')\n",
    "    location = parts[0]\n",
    "    date = parts[1]\n",
    "    time = parts[2].split('.')[0]  # Eliminar la extensiÃ³n .WAV\n",
    "    day = date[-2:]  # Ãltimos dos caracteres para el dÃ­a\n",
    "    hour = time[:2]\n",
    "    return pd.Series([location, day, hour])\n",
    "\n",
    "# Aplicar la funciÃ³n a la columna 'y' y crear nuevas columnas\n",
    "df_ae_unflat[['location', 'day', 'hour']] =df_ae_unflat['y'].apply(extract_parts)\n",
    "\n",
    "def define_hour_stage(hour):\n",
    "    hour = int(hour)\n",
    "    if 5 <= hour <= 8:\n",
    "        return 'morning'\n",
    "    elif 9 <= hour <= 16:\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "df_ae_unflat['hour_stage'] =df_ae_unflat['hour'].apply(define_hour_stage)\n",
    "df_ae_unflat.set_index(\"y\", inplace=True, drop=False)\n",
    "df_ae_unflat['cover'] = df_ae_unflat.index.map(audios['cover'])\n",
    "df_ae_unflat['habitat'] = df_ae_unflat.index.map(audios['habitat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c712bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25916</th>\n",
       "      <th>25917</th>\n",
       "      <th>25918</th>\n",
       "      <th>25919</th>\n",
       "      <th>y</th>\n",
       "      <th>location</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_stage</th>\n",
       "      <th>cover</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RZUH02_20220903_090000.WAV</th>\n",
       "      <td>9.426662</td>\n",
       "      <td>10.290031</td>\n",
       "      <td>10.414343</td>\n",
       "      <td>10.073651</td>\n",
       "      <td>8.735041</td>\n",
       "      <td>8.646876</td>\n",
       "      <td>9.901097</td>\n",
       "      <td>11.451177</td>\n",
       "      <td>9.508819</td>\n",
       "      <td>10.445171</td>\n",
       "      <td>...</td>\n",
       "      <td>8.660295</td>\n",
       "      <td>8.710748</td>\n",
       "      <td>8.684983</td>\n",
       "      <td>8.699404</td>\n",
       "      <td>RZUH02_20220903_090000.WAV</td>\n",
       "      <td>RZUH02</td>\n",
       "      <td>03</td>\n",
       "      <td>09</td>\n",
       "      <td>day</td>\n",
       "      <td>pasture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RZUH02_20220903_091500.WAV</th>\n",
       "      <td>10.044794</td>\n",
       "      <td>10.056710</td>\n",
       "      <td>10.027611</td>\n",
       "      <td>10.155375</td>\n",
       "      <td>10.139009</td>\n",
       "      <td>10.162149</td>\n",
       "      <td>10.144095</td>\n",
       "      <td>10.186112</td>\n",
       "      <td>10.098737</td>\n",
       "      <td>10.518700</td>\n",
       "      <td>...</td>\n",
       "      <td>8.705967</td>\n",
       "      <td>8.711951</td>\n",
       "      <td>8.701811</td>\n",
       "      <td>8.677699</td>\n",
       "      <td>RZUH02_20220903_091500.WAV</td>\n",
       "      <td>RZUH02</td>\n",
       "      <td>03</td>\n",
       "      <td>09</td>\n",
       "      <td>day</td>\n",
       "      <td>pasture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RZUH02_20220903_093000.WAV</th>\n",
       "      <td>18.995157</td>\n",
       "      <td>11.270409</td>\n",
       "      <td>11.494708</td>\n",
       "      <td>13.810095</td>\n",
       "      <td>13.095420</td>\n",
       "      <td>15.798622</td>\n",
       "      <td>10.388437</td>\n",
       "      <td>14.229605</td>\n",
       "      <td>20.270258</td>\n",
       "      <td>10.302647</td>\n",
       "      <td>...</td>\n",
       "      <td>8.686976</td>\n",
       "      <td>8.732903</td>\n",
       "      <td>8.695786</td>\n",
       "      <td>8.686226</td>\n",
       "      <td>RZUH02_20220903_093000.WAV</td>\n",
       "      <td>RZUH02</td>\n",
       "      <td>03</td>\n",
       "      <td>09</td>\n",
       "      <td>day</td>\n",
       "      <td>pasture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RZUH02_20220903_094500.WAV</th>\n",
       "      <td>10.212321</td>\n",
       "      <td>10.148938</td>\n",
       "      <td>10.122599</td>\n",
       "      <td>10.128122</td>\n",
       "      <td>10.166744</td>\n",
       "      <td>10.125995</td>\n",
       "      <td>10.045304</td>\n",
       "      <td>10.284530</td>\n",
       "      <td>9.023882</td>\n",
       "      <td>10.529044</td>\n",
       "      <td>...</td>\n",
       "      <td>8.708529</td>\n",
       "      <td>8.702578</td>\n",
       "      <td>8.716885</td>\n",
       "      <td>8.705018</td>\n",
       "      <td>RZUH02_20220903_094500.WAV</td>\n",
       "      <td>RZUH02</td>\n",
       "      <td>03</td>\n",
       "      <td>09</td>\n",
       "      <td>day</td>\n",
       "      <td>pasture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RZUH02_20220903_100000.WAV</th>\n",
       "      <td>9.903143</td>\n",
       "      <td>10.076799</td>\n",
       "      <td>10.140228</td>\n",
       "      <td>9.986540</td>\n",
       "      <td>9.887734</td>\n",
       "      <td>10.269837</td>\n",
       "      <td>11.899821</td>\n",
       "      <td>10.151425</td>\n",
       "      <td>10.000853</td>\n",
       "      <td>10.482151</td>\n",
       "      <td>...</td>\n",
       "      <td>8.667990</td>\n",
       "      <td>8.717656</td>\n",
       "      <td>8.691320</td>\n",
       "      <td>8.687242</td>\n",
       "      <td>RZUH02_20220903_100000.WAV</td>\n",
       "      <td>RZUH02</td>\n",
       "      <td>03</td>\n",
       "      <td>10</td>\n",
       "      <td>day</td>\n",
       "      <td>pasture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 25926 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0          1          2          3  \\\n",
       "y                                                                        \n",
       "RZUH02_20220903_090000.WAV   9.426662  10.290031  10.414343  10.073651   \n",
       "RZUH02_20220903_091500.WAV  10.044794  10.056710  10.027611  10.155375   \n",
       "RZUH02_20220903_093000.WAV  18.995157  11.270409  11.494708  13.810095   \n",
       "RZUH02_20220903_094500.WAV  10.212321  10.148938  10.122599  10.128122   \n",
       "RZUH02_20220903_100000.WAV   9.903143  10.076799  10.140228   9.986540   \n",
       "\n",
       "                                    4          5          6          7  \\\n",
       "y                                                                        \n",
       "RZUH02_20220903_090000.WAV   8.735041   8.646876   9.901097  11.451177   \n",
       "RZUH02_20220903_091500.WAV  10.139009  10.162149  10.144095  10.186112   \n",
       "RZUH02_20220903_093000.WAV  13.095420  15.798622  10.388437  14.229605   \n",
       "RZUH02_20220903_094500.WAV  10.166744  10.125995  10.045304  10.284530   \n",
       "RZUH02_20220903_100000.WAV   9.887734  10.269837  11.899821  10.151425   \n",
       "\n",
       "                                    8          9  ...     25916     25917  \\\n",
       "y                                                 ...                       \n",
       "RZUH02_20220903_090000.WAV   9.508819  10.445171  ...  8.660295  8.710748   \n",
       "RZUH02_20220903_091500.WAV  10.098737  10.518700  ...  8.705967  8.711951   \n",
       "RZUH02_20220903_093000.WAV  20.270258  10.302647  ...  8.686976  8.732903   \n",
       "RZUH02_20220903_094500.WAV   9.023882  10.529044  ...  8.708529  8.702578   \n",
       "RZUH02_20220903_100000.WAV  10.000853  10.482151  ...  8.667990  8.717656   \n",
       "\n",
       "                               25918     25919                           y  \\\n",
       "y                                                                            \n",
       "RZUH02_20220903_090000.WAV  8.684983  8.699404  RZUH02_20220903_090000.WAV   \n",
       "RZUH02_20220903_091500.WAV  8.701811  8.677699  RZUH02_20220903_091500.WAV   \n",
       "RZUH02_20220903_093000.WAV  8.695786  8.686226  RZUH02_20220903_093000.WAV   \n",
       "RZUH02_20220903_094500.WAV  8.716885  8.705018  RZUH02_20220903_094500.WAV   \n",
       "RZUH02_20220903_100000.WAV  8.691320  8.687242  RZUH02_20220903_100000.WAV   \n",
       "\n",
       "                            location  day  hour  hour_stage    cover  \n",
       "y                                                                     \n",
       "RZUH02_20220903_090000.WAV    RZUH02   03    09         day  pasture  \n",
       "RZUH02_20220903_091500.WAV    RZUH02   03    09         day  pasture  \n",
       "RZUH02_20220903_093000.WAV    RZUH02   03    09         day  pasture  \n",
       "RZUH02_20220903_094500.WAV    RZUH02   03    09         day  pasture  \n",
       "RZUH02_20220903_100000.WAV    RZUH02   03    10         day  pasture  \n",
       "\n",
       "[5 rows x 25926 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee1017",
   "metadata": {},
   "source": [
    "## Cover Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e8dad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 5, 5184) (231, 5, 5184)\n",
      "Accuracy: 0.8683982683982684\n",
      "f1: 0.862888300412774\n",
      "recall 0.8383158682979654\n",
      "(4028, 5, 5184) (1008, 5, 5184)\n",
      "Accuracy: 0.7990079365079366\n",
      "f1: 0.6095890734608318\n",
      "recall 0.5751852469102036\n",
      "(6267, 5, 5184) (1567, 5, 5184)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(y_test,\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     21\u001b[0m clf_rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mclf_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m clf_rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     24\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_pred_rf)\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/threading.py:600\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 600\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df_day={}\n",
    "accuracies_ae_unflat_covers = []\n",
    "f1_scores_ae_unflat_covers = []\n",
    "recalls_ae_unflat_covers = []\n",
    "for i in [\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\"]:\n",
    "    df_day = df_ae_unflat[df_ae_unflat['day'].isin([i])]\n",
    "    X = np.asarray(df_day.loc[:,0:25919])\n",
    "    y = np.asarray(df_day.loc[:,\"cover\"])\n",
    "    X = np.reshape(X, [X.shape[0], 5, X.shape[1]//5])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    X_train = np.reshape(X_train, [X_train.shape[0]*5,X_train.shape[2]])\n",
    "    X_test = np.reshape(X_test, [X_test.shape[0]*5,X_test.shape[2]])\n",
    "    y_train = np.repeat(y_train,5)\n",
    "    y_test = np.repeat(y_test,5)\n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "\n",
    "    accuracies_ae_unflat_covers.append(accuracy)\n",
    "    f1_scores_ae_unflat_covers.append(f1_score)\n",
    "    recalls_ae_unflat_covers.append(recall)\n",
    "    \n",
    "# np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/accuracies_ae_unflat_covers.npy\", accuracies_ae_unflat_covers)\n",
    "# np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/f1_scores_ae_unflat_covers.npy\", f1_scores_ae_unflat_covers)\n",
    "# np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/recalls_ae_unflat_covers.npy\", recalls_ae_unflat_covers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d462316",
   "metadata": {},
   "source": [
    "## Hour Stage Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f894c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9376623376623376\n",
      "f1: 0.612615823235923\n",
      "recall 0.61177304964539\n",
      "Accuracy: 0.8823412698412698\n",
      "f1: 0.8006949569747902\n",
      "recall 0.779771722709968\n",
      "Accuracy: 0.8611359285258455\n",
      "f1: 0.7927775970404195\n",
      "recall 0.7802045378380269\n",
      "Accuracy: 0.8970114942528735\n",
      "f1: 0.8613218632952521\n",
      "recall 0.8495485635108841\n",
      "Accuracy: 0.900114547537228\n",
      "f1: 0.8606986275978993\n",
      "recall 0.8462843499011427\n",
      "Accuracy: 0.8717715768981181\n",
      "f1: 0.840594870966723\n",
      "recall 0.8254954691120387\n",
      "Accuracy: 0.8301392301392302\n",
      "f1: 0.6684664588424942\n",
      "recall 0.6577380945915365\n",
      "Accuracy: 0.8244807121661721\n",
      "f1: 0.6574266160407841\n",
      "recall 0.6681496018236107\n",
      "Accuracy: 0.8679298245614036\n",
      "f1: 0.8362010930974281\n",
      "recall 0.8280783382386101\n",
      "Accuracy: 0.8584650112866817\n",
      "f1: 0.8407648390230474\n",
      "recall 0.8374125362291739\n",
      "Accuracy: 0.8349442379182156\n",
      "f1: 0.8021718306944304\n",
      "recall 0.7976693944353519\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df_day={}\n",
    "accuracies_ae_unflat_hours = []\n",
    "f1_scores_ae_unflat_hours = []\n",
    "recalls_ae_unflat_hours = []\n",
    "for i in [\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\"]:\n",
    "    df_day = df_ae_unflat[df_ae_unflat['day'].isin([i])]\n",
    "    X = np.asarray(df_day.loc[:,0:25919])\n",
    "    y = np.asarray(df_day.loc[:,\"hour_stage\"])\n",
    "    X = np.reshape(X, [X.shape[0], 5, X.shape[1]//5])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "    X_train = np.reshape(X_train, [X_train.shape[0]*5,X_train.shape[2]])\n",
    "    X_test = np.reshape(X_test, [X_test.shape[0]*5,X_test.shape[2]])\n",
    "    y_train = np.repeat(y_train,5)\n",
    "    y_test = np.repeat(y_test,5)\n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "\n",
    "    accuracies_ae_unflat_hours.append(accuracy)\n",
    "    f1_scores_ae_unflat_hours.append(f1_score)\n",
    "    recalls_ae_unflat_hours.append(recall)\n",
    "    \n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/accuracies_ae_unflat_hours.npy\", accuracies_ae_unflat_hours)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/f1_scores_ae_unflat_hours.npy\", f1_scores_ae_unflat_hours)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/recalls_ae_unflat_hours.npy\", recalls_ae_unflat_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc2d1e",
   "metadata": {},
   "source": [
    "### Autoencoders Features and Labels using independent segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ae, labels_ae, test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda32a30",
   "metadata": {},
   "source": [
    "### Autoencoders Features and Labels using 5 segments of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e27e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.reshape(X_ae, (X_ae.shape[0]//5,5,X_ae.shape[1]))\n",
    "y_batch = np.reshape(y_ae, (y_ae.shape[0]//5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 == y_path[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_ai), y_path[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_batch, y_path, test_size=0.2,random_state=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0]*X_test.shape[1], X_test.shape[2])\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_train = y_train.reshape(y_train.shape[0]*y_train.shape[1])\n",
    "y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
    "\n",
    "labels_train = []\n",
    "for i in range(len(y_train)):\n",
    "    labels_train.append(audios.loc[y_train[i], \"cover\"])\n",
    "labels_test = []\n",
    "for i in range(len(y_test)):\n",
    "    labels_test.append(audios.loc[y_test[i], \"cover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, labels_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(labels_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b62a25",
   "metadata": {},
   "source": [
    "# Autoencoders Features and Labels using voting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf2 = np.asarray(y_pred_rf)\n",
    "y_pred_rf2 = np.reshape(y_pred_rf2,(y_pred_rf2.shape[0]//5,5))\n",
    "y_test2 = np.asarray(labels_test)\n",
    "y_test2 = np.reshape(y_test2,(y_test2.shape[0]//5,5))\n",
    "\n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "labels_test2 = []\n",
    "labels_pred = []\n",
    "for i in range(len(y_pred_rf2)):\n",
    "    labels_pred.append(most_frequent(list(y_pred_rf2[i])))\n",
    "    labels_test2.append(most_frequent(list(y_test2[i])))\n",
    "accuracy_ae = metrics.accuracy_score(labels_test2, labels_pred)\n",
    "f1_score_ae = metrics.f1_score(labels_test2, labels_pred, average=\"macro\")\n",
    "recall_ae = metrics.recall_score(labels_test2, labels_pred, average=\"macro\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_ae)\n",
    "print(\"f1:\", f1_score_ae)\n",
    "print(\"recall\", recall_ae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
