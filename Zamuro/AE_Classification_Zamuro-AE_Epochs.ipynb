{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1a613c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T15:11:58.425895Z",
     "start_time": "2024-08-16T15:11:58.420754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1eb0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31343"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "import random\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8577b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA_ = PCA(n_components=60).fit(X_norm)\n",
    "# X_PCA = PCA_.transform(X_norm)\n",
    "# # X_TSNE = TSNE(n_components=60, learning_rate=\"auto\", init='random', random_state=0).fit_transform(X_PCA)\n",
    "# reducer = umap.UMAP(min_dist=0.9, n_components=60)\n",
    "# X_UMAP = reducer.fit_transform(X_norm)\n",
    "# X_batch = np.reshape(X_UMAP, (X_UMAP.shape[0]//5,5,X_UMAP.shape[1]))\n",
    "# # X_UMAP_Norm = Normalizer().fit_transform(X_UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2237d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_audios_Zamuro = f\"{root}/Zamuro/Complementary_Files/zamuro_audios.csv\"\n",
    "root_recorders_Zamuro = f\"{root}/Zamuro/Complementary_Files/zamuro_recorders.csv\"\n",
    "\n",
    "audios = pd.read_csv(root_audios_Zamuro, index_col=0)\n",
    "recorders = pd.read_csv(root_recorders_Zamuro, index_col=0)\n",
    "\n",
    "def combinar_nombre_ubicacion(row):\n",
    "    return f\"{row['field_number_PR']}_{row['Filename']}\"\n",
    "\n",
    "# Aplicando la funciÃ³n a cada fila del DataFrame para crear la nueva columna\n",
    "audios['Filename_'] = audios.apply(combinar_nombre_ubicacion, axis=1)\n",
    "\n",
    "audios.set_index(\"Filename_\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f927c49",
   "metadata": {},
   "source": [
    "# AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1e154a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m recalls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m  i, mod_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[0;32m---> 13\u001b[0m     X_ae \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmod_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/AE_features_Zamuro.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,  map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     14\u001b[0m     X_ae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(X_ae)\n\u001b[1;32m     15\u001b[0m     y_path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmod_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/AE_test_path_samples_Zamuro.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,  map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "models = [1,3,5,7,10,20,30,40,50]\n",
    "\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "recalls = []\n",
    "for  i, mod_id in enumerate(models):\n",
    "\n",
    "    X_ae = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/{mod_id}/AE_features_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "    X_ae = np.asarray(X_ae)\n",
    "    y_path = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/{mod_id}/AE_test_path_samples_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "    \n",
    "    y = np.asarray(y_path)\n",
    "    y_2 = y[:,0]\n",
    "    for i in range(len(y_2)):\n",
    "        y_2[i] = y_2[i][0:-2] \n",
    "    y_2 = list(y_2)\n",
    "    y_3 = np.repeat(y_2, 5)\n",
    "    labels_ae = []\n",
    "    for i in range(len(y_2)):\n",
    "        labels_ae.append(audios.loc[y_2[i], \"cover\"])\n",
    "        \n",
    "    X_ae = np.reshape(X_ae, [X_ae.shape[0]//5, 5, X_ae.shape[1]])\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ae, labels_ae, test_size=0.2,random_state=0)\n",
    "    \n",
    "    X_train = np.reshape(X_train, [X_train.shape[0]*5, X_train.shape[2]])\n",
    "    X_test = np.reshape(X_test, [X_test.shape[0]*5, X_test.shape[2]])\n",
    "    \n",
    "    y_train = np.repeat(y_train,5)\n",
    "    y_test = np.repeat(y_test,5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1_score)\n",
    "    recalls.append(recall)\n",
    "    \n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/accuracies.npy\", accuracies)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/f1_scores.npy\", f1_scores)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/recalls.npy\", recalls)\n",
    "\n",
    "# X_ae = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_features_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "# X_ae = np.asarray(X_ae)\n",
    "# y_path = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_test_path_samples_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "\n",
    "# scaler = StandardScaler().fit(X_ae)\n",
    "# X_scaled = scaler.transform(X_ae)\n",
    "\n",
    "# Normalizer_ = Normalizer().fit(X_ae)\n",
    "# X_norm = Normalizer_.transform(X_ae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfd858",
   "metadata": {},
   "source": [
    "## 5 segments flattened "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda905f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ae = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_features_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "X_ae = np.asarray(X_ae)\n",
    "y_path = torch.load(f\"{root}/Zamuro/temporal_zamuro/Features/log_standarization_epochs_10/AE_test_path_samples_Zamuro.pth\",  map_location=torch.device('cpu'))\n",
    "\n",
    "y = np.asarray(y_path)\n",
    "y_2 = y[:,0]\n",
    "for i in range(len(y_2)):\n",
    "    y_2[i] = y_2[i][0:-2] \n",
    "y_2 = list(y_2)\n",
    "y_3 = np.repeat(y_2, 5)\n",
    "labels_ae = []\n",
    "for i in range(len(y_3)):\n",
    "    labels_ae.append(audios.loc[y_3[i], \"cover\"])\n",
    "\n",
    "df_ae = pd.DataFrame(X_ae)\n",
    "df_ae[\"y\"] = y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d728ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts(row):\n",
    "    parts = row.split('_')\n",
    "    location = parts[0]\n",
    "    date = parts[1]\n",
    "    time = parts[2].split('.')[0]  # Eliminar la extensiÃ³n .WAV\n",
    "    day = date[-2:]  # Ãltimos dos caracteres para el dÃ­a\n",
    "    hour = time[:2]\n",
    "    return pd.Series([location, day, hour])\n",
    "\n",
    "# Aplicar la funciÃ³n a la columna 'y' y crear nuevas columnas\n",
    "df_ae[['location', 'day', 'hour']] =df_ae['y'].apply(extract_parts)\n",
    "\n",
    "def define_hour_stage(hour):\n",
    "    hour = int(hour)\n",
    "    if 5 <= hour <= 8:\n",
    "        return 'morning'\n",
    "    elif 9 <= hour <= 16:\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "df_ae['hour_stage'] =df_ae['hour'].apply(define_hour_stage)\n",
    "df_ae.set_index(\"y\", inplace=True, drop=False)\n",
    "df_ae['cover'] = df_ae.index.map(audios['cover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0937b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df_day={}\n",
    "accuracies_ae = []\n",
    "f1_scores_ae = []\n",
    "recalls_ae = []\n",
    "for i in [\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\"]:\n",
    "    df_day = df_ae[df_ae['day'].isin([i])]\n",
    "    X = np.asarray(df_day.loc[:,0:5183])\n",
    "    y = np.asarray(df_day.loc[:,\"cover\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "\n",
    "    accuracies_ae.append(accuracy)\n",
    "    f1_scores_ae.append(f1_score)\n",
    "    recalls_ae.append(recall)\n",
    "    \n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/accuracies_ae.npy\", accuracies_ae)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/f1_scores_ae.npy\", f1_scores_ae)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/recalls_ae.npy\", recalls_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7f53d",
   "metadata": {},
   "source": [
    "## UNFLAT Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7696f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_ae.shape)\n",
    "X_ae_unflat = np.reshape(X_ae, [X_ae.shape[0]//5,5,X_ae.shape[1]])\n",
    "print(X_ae_unflat.shape)\n",
    "X_ae_unflat2 = np.reshape(X_ae_unflat, [X_ae_unflat.shape[0], X_ae_unflat.shape[1]*X_ae_unflat.shape[2]])\n",
    "print(X_ae_unflat2.shape)\n",
    "X_ae_unflat3 = np.reshape(X_ae_unflat2, [X_ae_unflat2.shape[0], 5, X_ae_unflat2.shape[1]//5])\n",
    "print(X_ae_unflat3.shape)\n",
    "X_ae_flat = np.reshape(X_ae_unflat3, [X_ae_unflat3.shape[0]*5,X_ae_unflat3.shape[2]])\n",
    "print(X_ae_flat.shape)\n",
    "print((X_ae_flat == X_ae).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e85b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ae_unflat = np.reshape(X_ae, [X_ae.shape[0]//5,5,X_ae.shape[1]])\n",
    "# X_ae_unflat = X_ae_unflat2.mean(axis=1)\n",
    "# X_ae_unflat = np.median(X_ae_unflat, axis=1)\n",
    "X_ae_unflat = np.reshape(X_ae_unflat, [X_ae_unflat.shape[0], X_ae_unflat.shape[1]*X_ae_unflat.shape[2]])\n",
    "df_ae_unflat = pd.DataFrame(X_ae_unflat)\n",
    "df_ae_unflat[\"y\"] = y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad1851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_parts(row):\n",
    "    parts = row.split('_')\n",
    "    location = parts[0]\n",
    "    date = parts[1]\n",
    "    time = parts[2].split('.')[0]  # Eliminar la extensiÃ³n .WAV\n",
    "    day = date[-2:]  # Ãltimos dos caracteres para el dÃ­a\n",
    "    hour = time[:2]\n",
    "    return pd.Series([location, day, hour])\n",
    "\n",
    "# Aplicar la funciÃ³n a la columna 'y' y crear nuevas columnas\n",
    "df_ae_unflat[['location', 'day', 'hour']] =df_ae_unflat['y'].apply(extract_parts)\n",
    "\n",
    "def define_hour_stage(hour):\n",
    "    hour = int(hour)\n",
    "    if 5 <= hour <= 8:\n",
    "        return 'morning'\n",
    "    elif 9 <= hour <= 16:\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "df_ae_unflat['hour_stage'] =df_ae_unflat['hour'].apply(define_hour_stage)\n",
    "df_ae_unflat.set_index(\"y\", inplace=True, drop=False)\n",
    "df_ae_unflat['cover'] = df_ae_unflat.index.map(audios['cover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8dad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8874458874458875\n",
      "f1: 0.8202336179968279\n",
      "recall 0.7784285633342237\n",
      "Accuracy: 0.8406746031746032\n",
      "f1: 0.7760975851166583\n",
      "recall 0.7393010181734642\n",
      "Accuracy: 0.8255264837268667\n",
      "f1: 0.7753539486730737\n",
      "recall 0.7487375898604104\n",
      "Accuracy: 0.8295402298850575\n",
      "f1: 0.772362826427761\n",
      "recall 0.7508791174330485\n",
      "Accuracy: 0.8239404352806414\n",
      "f1: 0.7644580696611154\n",
      "recall 0.7384025674843651\n",
      "Accuracy: 0.771966255678131\n",
      "f1: 0.6961359076327854\n",
      "recall 0.6721932723419181\n",
      "Accuracy: 0.8552006552006552\n",
      "f1: 0.8046740106409622\n",
      "recall 0.7870620258788471\n",
      "Accuracy: 0.8370919881305638\n",
      "f1: 0.790777378552724\n",
      "recall 0.7706063991477358\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "df_day={}\n",
    "accuracies_ae_unflat = []\n",
    "f1_scores_ae_unflat = []\n",
    "recalls_ae_unflat = []\n",
    "for i in [\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\"]:\n",
    "    df_day = df_ae_unflat[df_ae_unflat['day'].isin([i])]\n",
    "    X = np.asarray(df_day.loc[:,0:25919])\n",
    "    y = np.asarray(df_day.loc[:,\"cover\"])\n",
    "    X = np.reshape(X, [X.shape[0], 5, X.shape[1]//5])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "    X_train = np.reshape(X_train, [X_train.shape[0]*5,X_train.shape[2]])\n",
    "#     X_test = np.reshape(X_test, [X_test.shape[0], 5, X_test.shape[1]//5])\n",
    "    X_test = np.reshape(X_test, [X_test.shape[0]*5,X_test.shape[2]])\n",
    "    y_train = np.repeat(y_train,5)\n",
    "    y_test = np.repeat(y_test,5)\n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "\n",
    "    accuracies_ae_unflat.append(accuracy)\n",
    "    f1_scores_ae_unflat.append(f1_score)\n",
    "    recalls_ae_unflat.append(recall)\n",
    "    \n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/accuracies_ae_unflat.npy\", accuracies_ae_unflat)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/f1_scores_ae_unflat.npy\", f1_scores_ae_unflat)\n",
    "np.save(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/recalls_ae_unflat.npy\", recalls_ae_unflat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc2d1e",
   "metadata": {},
   "source": [
    "### Autoencoders Features and Labels using independent segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ae, labels_ae, test_size=0.2,random_state=0)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda32a30",
   "metadata": {},
   "source": [
    "### Autoencoders Features and Labels using 5 segments of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e27e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.reshape(X_ae, (X_ae.shape[0]//5,5,X_ae.shape[1]))\n",
    "y_batch = np.reshape(y_ae, (y_ae.shape[0]//5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3 == y_path[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels_ai), y_path[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_batch, y_path, test_size=0.2,random_state=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0]*X_test.shape[1], X_test.shape[2])\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_train = y_train.reshape(y_train.shape[0]*y_train.shape[1])\n",
    "y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
    "\n",
    "labels_train = []\n",
    "for i in range(len(y_train)):\n",
    "    labels_train.append(audios.loc[y_train[i], \"cover\"])\n",
    "labels_test = []\n",
    "for i in range(len(y_test)):\n",
    "    labels_test.append(audios.loc[y_test[i], \"cover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, labels_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(labels_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b62a25",
   "metadata": {},
   "source": [
    "# Autoencoders Features and Labels using voting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf2 = np.asarray(y_pred_rf)\n",
    "y_pred_rf2 = np.reshape(y_pred_rf2,(y_pred_rf2.shape[0]//5,5))\n",
    "y_test2 = np.asarray(labels_test)\n",
    "y_test2 = np.reshape(y_test2,(y_test2.shape[0]//5,5))\n",
    "\n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "labels_test2 = []\n",
    "labels_pred = []\n",
    "for i in range(len(y_pred_rf2)):\n",
    "    labels_pred.append(most_frequent(list(y_pred_rf2[i])))\n",
    "    labels_test2.append(most_frequent(list(y_test2[i])))\n",
    "accuracy_ae = metrics.accuracy_score(labels_test2, labels_pred)\n",
    "f1_score_ae = metrics.f1_score(labels_test2, labels_pred, average=\"macro\")\n",
    "recall_ae = metrics.recall_score(labels_test2, labels_pred, average=\"macro\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_ae)\n",
    "print(\"f1:\", f1_score_ae)\n",
    "print(\"recall\", recall_ae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
