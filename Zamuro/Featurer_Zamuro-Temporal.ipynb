{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T19:12:02.593018Z",
     "start_time": "2024-07-31T19:12:02.564222Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18052,
     "status": "ok",
     "timestamp": 1678388233869,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "2OLjDqbgadV7",
    "outputId": "a38c57aa-e4dd-46fe-aca2-9e6bd6d0cd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    # !wandb login\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4523,
     "status": "ok",
     "timestamp": 1678388238390,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ucIGvQ7GczZb",
    "outputId": "0bdf55db-463b-4047-8259-f7dc96b407f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio.transforms as audio_transform\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel # For AE\n",
    "# from PosAE_training_functions import posautoencoding_m1 as AE, TestModel, TrainModel # For PosAE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "print(device)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jPCv40Ugk0I",
    "outputId": "b093c1e1-5419-407e-a180-ab158e8f79ba"
   },
   "outputs": [],
   "source": [
    "def featuring_autoencoders(dataset, date_format, model, len_features=None, save=True, identifier=None):\n",
    "    training_loader = DataLoader(dataset, batch_size=1)\n",
    "    iterator = iter(training_loader)\n",
    "    testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "\n",
    "    training_recorder_list = []\n",
    "    training_hour_list = []\n",
    "    training_minute_list = []\n",
    "    delete_samples = []\n",
    "    training_path_samples = []\n",
    "    training_samples_list_torch = []\n",
    "    \n",
    "    if len_features == None:\n",
    "        len_features = len(training_loader)\n",
    "    else:\n",
    "        len_features = len_features\n",
    "        \n",
    "    batch = int(len_features*0.1)\n",
    "    \n",
    "    for id in range(len_features):\n",
    "        if (id+1)% batch == 0:\n",
    "            print(f\"id: {id + 1} of {len_features}\")\n",
    "        try:\n",
    "            originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "        except:\n",
    "            print(f\"error id: {id}\")\n",
    "            delete_samples.append(id)\n",
    "            continue\n",
    "\n",
    "    #     encodings_size = encodings[0].shape\n",
    "        encodings = encodings.to(\"cuda\").detach()\n",
    "        encodings = encodings.reshape(encodings.shape[0],\n",
    "                                    encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "        training_samples_list_torch.append(encodings)\n",
    "        label[\"recorder\"]=np.repeat(label[\"recorder\"][0][0],5)\n",
    "#         training_recorder_list.append(label[\"recorder\"])\n",
    "#         training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "#         training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "\n",
    "\n",
    "        path = np.asarray(path, dtype=\"U32\")\n",
    "        path = np.repeat(path, 5)\n",
    "        indexer = [\"_1\",\"_2\",\"_3\",\"_4\",\"_5\"]\n",
    "        indexer = np.asarray(indexer)\n",
    "        # path = path.astype(\"float64\")\n",
    "        for i in range(len(path)):\n",
    "            path[i] = label[\"recorder\"][0] + \"_\" + path[i] + indexer[i]\n",
    "\n",
    "        training_path_samples.append(path)\n",
    "    \n",
    "#     training_recorder_list = torch.cat(training_recorder_list,dim=0)\n",
    "#     training_hour_list = torch.cat(training_hour_list,dim=0)\n",
    "#     training_minute_list = torch.cat(training_minute_list,dim=0)\n",
    "    training_samples_list_torch = torch.cat(training_samples_list_torch, dim=0)\n",
    "    \n",
    "    if save == True:\n",
    "    \n",
    "        if \"filters\" in dataset.kwargs.keys():\n",
    "            for value in dataset.filters.values():\n",
    "                date_format = f\"{date_format}_{value}\" \n",
    "        if identifier != None:\n",
    "            date_format = f\"{date_format}_{identifier}\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        torch.save(training_path_samples, f\"temporal_zamuro/Features/standarized_epochs_50/AE_test_path_samples_{date_format}.pth\")\n",
    "        torch.save(training_samples_list_torch, f\"temporal_zamuro/Features/standarized_epochs_50/AE_features_{date_format}.pth\")\n",
    "#         training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "#         torch.save(training_labels_list, f\"temporal_zamuro/Features/epochs_50/AE_labels_{date_format}.pth\")\n",
    "#         torch.save(delete_samples, f\"temporal_zamuro/Features/epochs_50/AE_test_corrupted_samples_list_{date_format}.pth\")\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1678388246582,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "qemaBluJa22A",
    "outputId": "30519d6b-ea58-4423-cb89-b2c5ffb7d854",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n",
      "RZUD06.csv\n",
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'date_format' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m filters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrain_FI\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNO\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     16\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SoundscapeData(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedia/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m                      dataframe_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplementary_Files/Audios_Zamuro/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m                      audio_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m                      win_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1028\u001b[39m, filters\u001b[38;5;241m=\u001b[39mfilters)\n\u001b[0;32m---> 20\u001b[0m featuring_autoencoders(dataset, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_rain\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, len_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, identifier\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'date_format' is not defined"
     ]
    }
   ],
   "source": [
    "# models = [\"epoch_50_training.pth\", \"epoch_40_training.pth\", \"epoch_30_training.pth\", \"epoch_20_training.pth\", \"epoch_10_training.pth\"]\n",
    "\n",
    "day = 7\n",
    "hour = 9\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "epochs = [1, 3, 5, 7]\n",
    "for i, epoch in enumerate(epochs):\n",
    "    print(f\"Running epoch: {epoch}\")\n",
    "    model_name = f\"{root}/Zamuro/temporal_zamuro/models/model_AE_Standarized_batch_size_20_num_hiddens_64__month_7_day_25_50_epochs/epoch_{epoch}_training.pth\"\n",
    "    model = AE(num_hiddens=64).to(device)\n",
    "    model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))\n",
    "\n",
    "    import os\n",
    "    folders = os.listdir(f\"Complementary_Files/Audios_Zamuro/\")\n",
    "\n",
    "    for folder in folders:\n",
    "        print(folder)\n",
    "        fold = folder.split(\".\")[0]        \n",
    "        filters = {\"rain_FI\": \"NO\"}\n",
    "        dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                             dataframe_path=f\"Complementary_Files/Audios_Zamuro/{folder}\",\n",
    "                             audio_length=12, ext=\"wav\",\n",
    "                             win_length=1028, filters=filters)\n",
    "        featuring_autoencoders(dataset, f\"{date_format}_rain\", model=model, len_features=None, save=True, identifier=f\"{fold}_epoch_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos\n",
    "input_folder = '/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics/Zamuro/temporal_zamuro/Features/log'\n",
    "\n",
    "# Ruta donde se crearán las nuevas carpetas\n",
    "output_folder = '/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics/Zamuro/temporal_zamuro/Features/log/ordered'\n",
    "\n",
    "# Listar todos los archivos en la carpeta de entrada\n",
    "files = os.listdir(input_folder)\n",
    "\n",
    "# Iterar sobre todos los archivos\n",
    "for file in files:\n",
    "    # Verificar si el archivo termina en '.pth'\n",
    "    if file.endswith('.pth'):\n",
    "        # Extraer el número del sufijo (el último número antes de .pth)\n",
    "        suffix = file.split('_')[-1].split('.')[0]\n",
    "        \n",
    "        # Crear el nombre de la carpeta de destino basado en el sufijo\n",
    "        target_folder = os.path.join(output_folder, suffix)\n",
    "        \n",
    "        # Crear la carpeta si no existe\n",
    "        os.makedirs(target_folder, exist_ok=True)\n",
    "        \n",
    "        # Mover el archivo a la carpeta de destino\n",
    "        shutil.move(os.path.join(input_folder, file), os.path.join(target_folder, file))\n",
    "\n",
    "print(\"Archivos organizados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "audios_zamuro = pd.read_csv(f\"{root}/Zamuro/Complementary_Files/zamuro_audios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = list(set(audios_zamuro[\"field_number_PR\"]))\n",
    "lista.sort()\n",
    "\n",
    "month = 7\n",
    "day = 25\n",
    "hour = 50\n",
    "date_format = f\"month_{month}_day_{day}_{hour}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load(f\"temporal_zamuro/Features/standarized_epochs_50/7/AE_features_{date_format}_rain_NO_{lista[0]}_epoch_7.pth\",  map_location=torch.device('cpu'))\n",
    "y = torch.load(f\"temporal_zamuro/Features/standarized_epochs_50/7/AE_test_path_samples_{date_format}_rain_NO_{lista[0]}_epoch_7.pth\",  map_location=torch.device('cpu'))\n",
    "for i, csv in enumerate(lista[1::]):\n",
    "    X_i = torch.load(f\"temporal_zamuro/Features/standarized_epochs_50/7/AE_features_{date_format}_rain_NO_{csv}_epoch_7.pth\",  map_location=torch.device('cpu'))\n",
    "    y_i = torch.load(f\"temporal_zamuro/Features/standarized_epochs_50/7/AE_test_path_samples_{date_format}_rain_NO_{csv}_epoch_7.pth\",  map_location=torch.device('cpu'))\n",
    "    X = torch.cat((X,X_i),0)\n",
    "    y = y + y_i\n",
    "torch.save(X, f\"temporal_zamuro/Features/standarized_epochs_50/7/AE_features_Zamuro.pth\")\n",
    "torch.save(y, f\"temporal_zamuro/Features/standarized_epochs_50/7/AE_test_path_samples_Zamuro.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features by folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folders = [\"Audios_Jaguas\"]\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    filters = {\"rain_FI\": \"NO\"}\n",
    "    dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                         dataframe_path=f\"Complementary_Files/Audios_Zamuro/{folder}\",\n",
    "                         audio_length=12, ext=\"wav\",\n",
    "                         win_length=1028, filters=filters)\n",
    "    featuring_autoencoders(dataset, f\"{date_format}_rain\", model=model, len_features=None, save=True, identifier=f\"{folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\"rain_FI\": \"NO\"}\n",
    "dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                     dataframe_path=\"Complementary_Files/zamuro_audios.csv\",\n",
    "                     audio_length=12, ext=\"wav\",\n",
    "                     win_length=1028, filters=filters)\n",
    "\n",
    "len_features=None\n",
    "save=True\n",
    "identifier=None\n",
    "\n",
    "training_loader = DataLoader(dataset, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "\n",
    "training_recorder_list = []\n",
    "training_hour_list = []\n",
    "training_minute_list = []\n",
    "delete_samples = []\n",
    "training_path_samples = []\n",
    "training_samples_list_torch = []\n",
    "\n",
    "if len_features == None:\n",
    "        len_features = len(training_loader)\n",
    "else:\n",
    "    len_features = len_features\n",
    "        \n",
    "batch = int(len_features*0.1)\n",
    "\n",
    "for id in range(len_features):\n",
    "#     if (id+1)%3 == 0:\n",
    "#         break\n",
    "    if (id+1)% batch == 0:\n",
    "        print(f\"id: {id + 1} of {len_features}\")\n",
    "        \n",
    "(originals, reconstructions, encodings, label, loss, path) = testing.reconstruct()\n",
    "#         except:\n",
    "#             print(f\"error id: {id}\")\n",
    "#             delete_samples.append(id)\n",
    "#             continue\n",
    "\n",
    "    #     encodings_size = encodings[0].shape\n",
    "encodings = encodings.to(\"cuda\").detach()\n",
    "encodings = encodings.reshape(encodings.shape[0],\n",
    "                            encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "training_samples_list_torch.append(encodings)\n",
    "label[\"recorder\"]=np.repeat(label[\"recorder\"][0][0],5)\n",
    "training_recorder_list.append(label[\"recorder\"])\n",
    "training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 9\n",
    "hour = 4\n",
    "month = 6\n",
    "folder = \"AE_rain\"\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "y = torch.load(f\"temporal_zamuro/Features/{folder}/AE_labels_{date_format}_rain_NO_RZUA01.pth\",  map_location=torch.device('cpu'))\n",
    "X = torch.load(f\"temporal_zamuro/Features/{folder}/AE_features_{date_format}_rain_NO_RZUA01.pth\",  map_location=torch.device('cpu'))\n",
    "path = torch.load(f\"temporal_zamuro/Features/{folder}/AE_test_path_samples_{date_format}_rain_NO_RZUA01.pth\",  map_location=torch.device('cpu'))\n",
    "path_flat = [item for sublist in path for item in sublist]\n",
    "path_flat = np.asarray(path_flat)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
