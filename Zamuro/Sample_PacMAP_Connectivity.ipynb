{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a56defc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-25T15:17:20.757764Z",
     "start_time": "2025-03-25T15:17:20.742368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !pip install umap-learn\n",
    "    !pip install umap-learn[plot]\n",
    "    !pip install holoviews\n",
    "\n",
    "    !pip install joypy\n",
    "\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b618bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "gc.collect()  #\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "from Modules.Clustering_Utils_Zamuro import plot_silhouette\n",
    "from Modules.Clustering_Utils_Zamuro import plot_centroids\n",
    "from Modules.Clustering_Utils_Zamuro import ClusteringResults\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import pacmap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import random\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a03974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n"
     ]
    }
   ],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 4\n",
    "hour = 9\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "\n",
    "model_name = f\"{root}/Zamuro/temporal_zamuro/models/log_standarization_model_epochs_10/model_{model_type}_{identifier}_{date_format}_final.pth\"\n",
    "model = AE(num_hiddens=64).to(device)\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "filters = {\"rain_FI\": \"NO\"}\n",
    "dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                         dataframe_path=\"Complementary_Files/zamuro_audios.csv\",\n",
    "                         audio_length=12, ext=\"wav\",\n",
    "                         win_length=1028, filters=filters)\n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=100)\n",
    "iterator = iter(test_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96906d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52603, 5184)\n"
     ]
    }
   ],
   "source": [
    "audios = pd.read_csv(f\"Complementary_Files/zamuro_audios_complete.csv\", index_col=0)\n",
    "recorders = pd.read_csv(f\"Complementary_Files/zamuro_recorders_satelites.csv\", index_col=0)\n",
    "df_ae = pd.read_csv(f\"temporal_zamuro/Features/New_df_ae_unflat.csv\")\n",
    "df_ae = df_ae[df_ae['location'] != 'RZUD06']\n",
    "X = np.asarray(df_ae.loc[:,\"0\":\"25919\"])\n",
    "X = np.reshape(X, [X.shape[0], 5, X.shape[1]//5])\n",
    "X = np.mean(X, axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703eb5e",
   "metadata": {},
   "source": [
    "day=5\n",
    "df_day = df_ae[df_ae['day'].isin([day])]\n",
    "X_day = np.asarray(df_day.loc[:,\"0\":\"5183\"])\n",
    "\n",
    "Normalizer_ = Normalizer().fit(X_day)\n",
    "X = Normalizer_.transform(X_day)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c781a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ae.set_index(\"y\", inplace=True)\n",
    "df_ae = df_ae.join(audios[['longitud_IG', 'latitude_IG']], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b39f80",
   "metadata": {},
   "source": [
    "## Conectividad en audios por dÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381da2eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pacmap\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk  # Estilo visual mejorado\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.spatial import distance_matrix\n",
    "import time\n",
    "\n",
    "days = list(set(df_ae[\"day\"]))\n",
    "\n",
    "for day in days:\n",
    "    df_day = df_ae[df_ae['day'].isin([day])]\n",
    "    X_day = np.asarray(df_day.loc[:,\"0\":\"25919\"])\n",
    "    X_day = np.reshape(X_day, [X_day.shape[0], 5, X_day.shape[1]//5])\n",
    "    X_day = np.mean(X_day, axis=1)\n",
    "\n",
    "    Normalizer_ = Normalizer().fit(X_day)\n",
    "    X = Normalizer_.transform(X_day)\n",
    "\n",
    "    # ðŸ”¹ Aplicar PacMAP para reducir a 2D\n",
    "\n",
    "    print(\"Computing PacMAP features\")\n",
    "    start_time = time.time()\n",
    "    pacmap_reducer = pacmap.PaCMAP(n_components=2, n_neighbors=75, MN_ratio=1, FP_ratio=20)\n",
    "    X_pacmap = pacmap_reducer.fit_transform(X)\n",
    "    print(f\"PacMAP completed in {time.time() - start_time:.2f} secs.\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X_pacmap[:,0], X_pacmap[:,1], s=1, alpha=1)\n",
    "    plt.title(\"PacMAP Projection\")\n",
    "    plt.show()\n",
    "\n",
    "    # ðŸ”¹ Construir matriz de distancias de Hamming en el espacio reducido\n",
    "    print(\"Computing Hamming distance matrix in PacMAP space...\")\n",
    "    start_time = time.time()\n",
    "    distance_mat = distance_matrix(X_pacmap, X_pacmap, p=1)  # Distancia de Hamming en 2D\n",
    "    print(f\"Hamming distance computed in {time.time() - start_time:.2f} secs.\")\n",
    "\n",
    "    # ðŸ”¹ Crear grafo basado en distancia de Hamming en el espacio PacMAP\n",
    "    print(\"Computing Graph...\")\n",
    "    G = nx.Graph()\n",
    "    threshold = np.percentile(distance_mat, 5)  # Tomar un umbral bajo para conexiones cercanas\n",
    "    graph_edges = []\n",
    "    for i in range(len(X_pacmap)):\n",
    "        for j in range(i + 1, len(X_pacmap)):\n",
    "            if distance_mat[i, j] < threshold:\n",
    "                G.add_edge(i, j)\n",
    "                graph_edges.append((i, j))\n",
    "    print(f\"Graph computed with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "    # ðŸ”¹ Usar las coordenadas de PacMAP como layout\n",
    "    print(\"Applying PacMAP-Based Layout...\")\n",
    "    start_time = time.time()\n",
    "    pos_pacmap = {i: X_pacmap[i] for i in range(len(X_pacmap))}  # Usa PacMAP como layout\n",
    "    print(f\"PacMAP Layout completed in {time.time() - start_time:.2f} secs.\")\n",
    "\n",
    "    # ðŸ”¹ Graficar con mejor estilo\n",
    "    plt.style.use(\"seaborn-whitegrid\")  # Activar el estilo seaborn-whitegrid\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    nx.draw_networkx_nodes(G, pos_pacmap, node_size=5, node_color='black', alpha=0.8)\n",
    "    nx.draw_networkx_edges(G, pos_pacmap, edgelist=graph_edges, width=0.3, edge_color=\"red\", alpha=0.3)\n",
    "\n",
    "    print(\"Graph plotted\")\n",
    "\n",
    "    # ðŸ”¹ Efectos visuales\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    plt.title(\"Hamming Layout Edge Bundling (PacMAP)\")\n",
    "    plt.xlabel(\"PacMAP 1\")\n",
    "    plt.ylabel(\"PacMAP 2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"temporal_zamuro/zamuro_connectivity_results/Days_Results/AE/PacMAP/connectivity_{str(day)}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee3e73f",
   "metadata": {},
   "source": [
    "## Conectividad en Grabadoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6e75a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point, LineString\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datashader.bundling import hammer_bundle\n",
    "from scipy.special import softmax\n",
    "\n",
    "print(\"Muestreando datos...\")\n",
    "sampled_df_ae = df_ae.sample(frac=0.02, random_state=42)  # Tomar el 5% de los datos para prueba rÃ¡pida\n",
    "# sampled_df_ae = df_ae  # Tomar el 5% de los datos para prueba rÃ¡pida\n",
    "\n",
    "\n",
    "print(\"Calculando caracterÃ­sticas acÃºsticas...\")\n",
    "X = np.asarray(sampled_df_ae.loc[:, \"0\":\"25919\"])\n",
    "X = np.reshape(X, [X.shape[0], 5, X.shape[1]//5])\n",
    "X = np.mean(X, axis=1)\n",
    "Normalizer_ = Normalizer().fit(X)\n",
    "X = Normalizer_.transform(X)\n",
    "\n",
    "print(\"Computando PacMAP...\")\n",
    "pacmap_reducer = pacmap.PaCMAP(n_components=2, n_neighbors=75, MN_ratio=1, FP_ratio=20)\n",
    "X_pacmap = pacmap_reducer.fit_transform(X)\n",
    "print(\"PacMAP completado\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52585f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from shapely.geometry import Point, LineString\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.special import softmax\n",
    "\n",
    "print(\"Extrayendo datos de sampled_df_ae...\")\n",
    "grabadoras = sampled_df_ae['location'].unique()\n",
    "n_grabadoras = len(grabadoras)\n",
    "location_map = {loc: i for i, loc in enumerate(grabadoras)}\n",
    "sampled_df_ae['grabadora_id'] = sampled_df_ae['location'].map(location_map)\n",
    "\n",
    "print(\"Extrayendo coordenadas de grabadoras...\")\n",
    "coordenadas_grabadoras = {\n",
    "    location_map[loc]: Point(sampled_df_ae[sampled_df_ae['location'] == loc][\"longitud_IG\"].mean(), \n",
    "                             sampled_df_ae[sampled_df_ae['location'] == loc][\"latitude_IG\"].mean())\n",
    "    for loc in grabadoras\n",
    "}\n",
    "\n",
    "print(\"Construyendo grafo de conectividad entre audios...\")\n",
    "X_audio = X_pacmap\n",
    "audio_graph = kneighbors_graph(X_audio, n_neighbors=50, mode=\"connectivity\", include_self=False)\n",
    "G_audio = nx.from_scipy_sparse_array(audio_graph)\n",
    "\n",
    "print(\"Construyendo grafo de grabadoras basado en conexiones de audio...\")\n",
    "G_grabadoras = nx.Graph()\n",
    "for i in range(n_grabadoras):\n",
    "    G_grabadoras.add_node(i, pos=coordenadas_grabadoras[i])\n",
    "\n",
    "print(\"Definiendo funciÃ³n de atenciÃ³n basada en conexiones entre grabadoras...\")\n",
    "audio_counts = {}\n",
    "for i, j in G_audio.edges():\n",
    "    g1, g2 = sampled_df_ae.iloc[i]['grabadora_id'], sampled_df_ae.iloc[j]['grabadora_id']\n",
    "    if g1 != g2:\n",
    "        audio_counts[(g1, g2)] = audio_counts.get((g1, g2), 0) + 1\n",
    "\n",
    "# Agregar conexiones al grafo de grabadoras\n",
    "for (g1, g2), count in audio_counts.items():\n",
    "    G_grabadoras.add_edge(g1, g2, weight=count)\n",
    "\n",
    "print(\"Aplicando Softmax por grabadora...\")\n",
    "# Diccionario para almacenar los pesos normalizados por cada grabadora\n",
    "normalized_weights = {}\n",
    "\n",
    "# Aplicar softmax a las conexiones de cada grabadora individualmente\n",
    "for grabadora in G_grabadoras.nodes():\n",
    "    vecinos = list(G_grabadoras[grabadora])\n",
    "    if not vecinos:\n",
    "        continue  # Si no tiene conexiones, continuar\n",
    "\n",
    "    # Obtener los pesos originales de las conexiones\n",
    "    pesos = np.array([G_grabadoras[grabadora][v]['weight'] for v in vecinos], dtype=np.float32)\n",
    "    \n",
    "    # Aplicar softmax a los pesos de esta grabadora\n",
    "    pesos_softmax = softmax(pesos)\n",
    "\n",
    "    # Asignar los pesos normalizados al grafo\n",
    "    for idx, v in enumerate(vecinos):\n",
    "        normalized_weights[(grabadora, v)] = pesos_softmax[idx]\n",
    "\n",
    "# Aplicar umbral y actualizar el grafo\n",
    "threshold = 0.05  # Ajusta segÃºn necesidad\n",
    "edges_to_remove = []\n",
    "\n",
    "for (g1, g2), weight in normalized_weights.items():\n",
    "    if weight < threshold:\n",
    "        edges_to_remove.append((g1, g2))  # Marcar para eliminar\n",
    "    else:\n",
    "        G_grabadoras[g1][g2]['weight'] = weight  # Asignar peso normalizado\n",
    "\n",
    "# Eliminar conexiones dÃ©biles\n",
    "G_grabadoras.remove_edges_from(edges_to_remove)\n",
    "\n",
    "print(f\"Grafo de grabadoras actualizado: {G_grabadoras.number_of_nodes()} nodos, {G_grabadoras.number_of_edges()} conexiones despuÃ©s del umbral.\")\n",
    "\n",
    "print(\"Visualizando grafo de grabadoras...\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Crear GeoDataFrame para visualizar las grabadoras\n",
    "geo_df = gpd.GeoDataFrame({\"grabadora\": list(coordenadas_grabadoras.keys()), \"geometry\": list(coordenadas_grabadoras.values())})\n",
    "geo_df.plot(ax=ax, color='red', markersize=50, label=\"Grabadoras\")\n",
    "\n",
    "# Obtener valores de pesos para escalar el grosor de las conexiones\n",
    "edge_weights = [G_grabadoras[i][j]['weight'] for i, j in G_grabadoras.edges()]\n",
    "edge_weights = np.array(edge_weights)\n",
    "\n",
    "# Normalizar los pesos para ajustar el grosor de lÃ­nea\n",
    "if len(edge_weights) > 0:\n",
    "    min_weight = edge_weights.min()\n",
    "    max_weight = edge_weights.max()\n",
    "    if max_weight > min_weight:\n",
    "        edge_weights = 1 + 5 * (edge_weights - min_weight) / (max_weight - min_weight)\n",
    "    else:\n",
    "        edge_weights = np.ones_like(edge_weights)  # Evitar divisiÃ³n por cero\n",
    "\n",
    "# Dibujar las conexiones con grosor proporcional al peso\n",
    "for idx, (i, j) in enumerate(G_grabadoras.edges()):\n",
    "    if i in coordenadas_grabadoras and j in coordenadas_grabadoras:\n",
    "        line = LineString([coordenadas_grabadoras[i], coordenadas_grabadoras[j]])\n",
    "        gpd.GeoSeries([line]).plot(ax=ax, color='blue', linewidth=edge_weights[idx], alpha=0.6)\n",
    "\n",
    "# Obtener etiquetas de las grabadoras desde sampled_df_ae\n",
    "labels = sampled_df_ae.set_index(\"grabadora_id\")[\"location\"].to_dict()\n",
    "\n",
    "# Dibujar etiquetas sobre los nodos en el grafo\n",
    "for grabadora_id, point in coordenadas_grabadoras.items():\n",
    "    ax.text(point.x, point.y, labels[grabadora_id], fontsize=5, ha='right', color='black')\n",
    "\n",
    "ax.set_title(f\"Mapa de conectividad entre grabadoras (Threshold={threshold})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f366bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Point, LineString\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.special import softmax\n",
    "\n",
    "# ---- Cargar el raster COB.tif ----\n",
    "raster_path = \"Complementary_Files/COB.tif\"\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(1)  # Leer la primera banda\n",
    "    raster_bounds = src.bounds  # Obtener el bounding box del raster\n",
    "    raster_crs = src.crs  # Obtener la proyecciÃ³n del raster\n",
    "\n",
    "# ---- Transformar coordenadas de grabadoras al sistema del raster ----\n",
    "print(\"Transformando coordenadas de grabadoras al CRS del raster...\")\n",
    "gdf_grabadoras = gpd.GeoDataFrame(\n",
    "    {\"grabadora\": sampled_df_ae['location'].unique()},\n",
    "    geometry=[Point(sampled_df_ae[sampled_df_ae['location'] == loc][\"longitud_IG\"].mean(), \n",
    "                    sampled_df_ae[sampled_df_ae['location'] == loc][\"latitude_IG\"].mean()) \n",
    "              for loc in sampled_df_ae['location'].unique()],\n",
    "    crs=\"EPSG:4326\"  # Sistema original (Lat/Lon)\n",
    ")\n",
    "\n",
    "# Transformar al sistema de coordenadas del raster\n",
    "gdf_grabadoras = gdf_grabadoras.to_crs(raster_crs)\n",
    "\n",
    "# Guardar coordenadas transformadas\n",
    "coordenadas_grabadoras = {row.grabadora: row.geometry for _, row in gdf_grabadoras.iterrows()}\n",
    "\n",
    "# ---- ConstrucciÃ³n del grafo de audios basado en vecinos cercanos ----\n",
    "n_neighbors = 1\n",
    "X_audio = X_pacmap  # Usar la proyecciÃ³n PaCMAP\n",
    "print(\"Construyendo grafo de audio basado en vecinos cercanos...\")\n",
    "audio_graph = kneighbors_graph(X_audio, n_neighbors=n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "G_audio = nx.from_scipy_sparse_array(audio_graph)\n",
    "\n",
    "# ---- ConstrucciÃ³n del grafo de grabadoras ----\n",
    "print(\"Construyendo grafo de grabadoras basado en conexiones de audio...\")\n",
    "G_grabadoras = nx.Graph()\n",
    "\n",
    "# Agregar nodos con nombres de grabadoras\n",
    "for grabadora in coordenadas_grabadoras:\n",
    "    G_grabadoras.add_node(grabadora, pos=(coordenadas_grabadoras[grabadora].x, coordenadas_grabadoras[grabadora].y))\n",
    "\n",
    "# ---- Agregar conexiones al grafo de grabadoras usando nombres ----\n",
    "audio_counts = {}\n",
    "for i, j in G_audio.edges():\n",
    "    g1, g2 = sampled_df_ae.iloc[i]['location'], sampled_df_ae.iloc[j]['location']\n",
    "    if g1 != g2:\n",
    "        audio_counts[(g1, g2)] = audio_counts.get((g1, g2), 0) + 1\n",
    "\n",
    "# Agregar conexiones con conteo sin normalizar\n",
    "for (g1, g2), count in audio_counts.items():\n",
    "    if g1 in G_grabadoras and g2 in G_grabadoras:\n",
    "        G_grabadoras.add_edge(g1, g2, weight=count)\n",
    "\n",
    "# ---- Aplicando Softmax por grabadora ----\n",
    "print(\"Aplicando Softmax por grabadora...\")\n",
    "normalized_weights = {}\n",
    "\n",
    "for grabadora in G_grabadoras.nodes():\n",
    "    vecinos = list(G_grabadoras[grabadora])\n",
    "    if not vecinos:\n",
    "        continue\n",
    "\n",
    "    pesos = np.array([G_grabadoras[grabadora][v]['weight'] for v in vecinos], dtype=np.float32)\n",
    "    pesos_softmax = softmax(pesos)\n",
    "\n",
    "    for idx, v in enumerate(vecinos):\n",
    "        normalized_weights[(grabadora, v)] = pesos_softmax[idx]\n",
    "\n",
    "# ---- Aplicar umbral y actualizar el grafo ----\n",
    "threshold = 0.75\n",
    "edges_to_remove = []\n",
    "\n",
    "for (g1, g2), weight in normalized_weights.items():\n",
    "    if weight < threshold:\n",
    "        edges_to_remove.append((g1, g2))\n",
    "    else:\n",
    "        G_grabadoras[g1][g2]['weight'] = weight\n",
    "\n",
    "G_grabadoras.remove_edges_from(edges_to_remove)\n",
    "\n",
    "print(f\"Grafo de grabadoras actualizado: {G_grabadoras.number_of_nodes()} nodos, {G_grabadoras.number_of_edges()} conexiones despuÃ©s del umbral.\")\n",
    "\n",
    "# ---- VisualizaciÃ³n ----\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Mostrar el raster de fondo\n",
    "with rasterio.open(raster_path) as src:\n",
    "    show(src, ax=ax, extent=raster_bounds, alpha=0.6)\n",
    "\n",
    "# Dibujar nodos con nombres correctos\n",
    "for grabadora, pos in coordenadas_grabadoras.items():\n",
    "    ax.scatter(pos.x, pos.y, color='red', s=50, edgecolors='black', zorder=3)\n",
    "    ax.text(pos.x, pos.y, grabadora, fontsize=6, ha='right', color='black', bbox=dict(facecolor='none', alpha=0.5, edgecolor='none'))\n",
    "    \n",
    "\n",
    "# Dibujar los edges con `ax.plot()` y grosor proporcional al peso\n",
    "for i, j in G_grabadoras.edges():\n",
    "    if i in coordenadas_grabadoras and j in coordenadas_grabadoras:\n",
    "        x_values = [coordenadas_grabadoras[i].x, coordenadas_grabadoras[j].x]\n",
    "        y_values = [coordenadas_grabadoras[i].y, coordenadas_grabadoras[j].y]\n",
    "        weight = G_grabadoras[i][j]['weight']\n",
    "        ax.plot(x_values, y_values, color='red', linewidth=weight*3, alpha=0.75, zorder=3)\n",
    "        \n",
    "\n",
    "ax.set_title(f\"Mapa de Conectividad de Grabadoras sobre COB.tif (Threshold={threshold})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfdcfa0",
   "metadata": {},
   "source": [
    "## Edge Bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aplicando Hammer Edge Bundling...\")\n",
    "edge_list = [(u, v, G_grabadoras.edges[u, v]['weight']) for u, v in G_grabadoras.edges()]\n",
    "node_positions = {n: (p.x, p.y) for n, p in coordenadas_grabadoras.items()}\n",
    "import numpy.lib.recfunctions as rfn\n",
    "\n",
    "# Convertir node_positions_array a un array estructurado con nombres de campo\n",
    "node_positions_array = np.array(\n",
    "    list(node_positions.values()), \n",
    "    dtype=[('x', np.float32), ('y', np.float32)]\n",
    ")\n",
    "edge_indices = np.array([(u, v) for u, v in G_grabadoras.edges()])\n",
    "\n",
    "# Convertir node_positions a un DataFrame\n",
    "node_positions_df = pd.DataFrame.from_dict(\n",
    "    node_positions, orient=\"index\", columns=[\"x\", \"y\"]\n",
    ")\n",
    "node_positions_df.index.name = \"node_id\"  # Asegurar que el Ã­ndice tenga un nombre\n",
    "\n",
    "# Convertir edge_indices a un DataFrame\n",
    "edge_indices_df = pd.DataFrame(\n",
    "    [(u, v) for u, v in G_grabadoras.edges()], columns=[\"source\", \"target\"]\n",
    ")\n",
    "\n",
    "bundled_edges = hammer_bundle(node_positions_df, edge_indices_df)\n",
    "# Asegurarnos de que bundled_edges sea una lista de listas de puntos\n",
    "bundled_edges.plot(x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34a5de",
   "metadata": {},
   "source": [
    "## Conectividad en grabadoras por dÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde10df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------DIA:3----------------------\n",
      "Transformando coordenadas de grabadoras al CRS del raster original...\n",
      "Muestreando datos...\n",
      "Calculando caracterÃ­sticas acÃºsticas...\n",
      "Computando PacMAP...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Point, LineString\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "raster_path = \"Complementary_Files/COB.tif\"\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(1)  # Leer la primera banda\n",
    "    raster_bounds = src.bounds  # Obtener el bounding box del raster\n",
    "    raster_crs = src.crs  # Obtener la proyecciÃ³n del raster\n",
    "\n",
    "\n",
    "days = list(set(df_ae[\"day\"]))\n",
    "for day in days:\n",
    "\n",
    "# day = 8\n",
    "      \n",
    "    print(f\"\\n-----------DIA:{day}----------------------\")\n",
    "     # ---- Transformar coordenadas de grabadoras al sistema del raster ----\n",
    "    print(\"Transformando coordenadas de grabadoras al CRS del raster original...\")\n",
    "    gdf_grabadoras_original = gpd.GeoDataFrame(\n",
    "        {\"grabadora\": df_ae['location'].unique()},\n",
    "        geometry=[Point(df_ae[df_ae['location'] == loc][\"longitud_IG\"].mean(), \n",
    "                        df_ae[df_ae['location'] == loc][\"latitude_IG\"].mean()) \n",
    "                  for loc in df_ae['location'].unique()],\n",
    "        crs=\"EPSG:4326\"  # Sistema original (Lat/Lon)\n",
    "    )\n",
    "\n",
    "    # Transformar al sistema de coordenadas del raster\n",
    "    gdf_grabadoras_original = gdf_grabadoras_original.to_crs(raster_crs)\n",
    "\n",
    "    # Guardar coordenadas transformadas\n",
    "    coordenadas_grabadoras_original = {row.grabadora: row.geometry for _, row in gdf_grabadoras_original.iterrows()}\n",
    "\n",
    "    print(\"Muestreando datos...\")\n",
    "    # sampled_df_ae = df_ae.sample(frac=0.02, random_state=42)  # Tomar el 5% de los datos para prueba rÃ¡pida\n",
    "    sampled_df_ae = df_ae[df_ae['day'].isin([day])]\n",
    "\n",
    "\n",
    "    print(\"Calculando caracterÃ­sticas acÃºsticas...\")\n",
    "    X_day = np.asarray(sampled_df_ae.loc[:,\"0\":\"25919\"])\n",
    "    X_day = np.reshape(X_day, [X_day.shape[0], 5, X_day.shape[1]//5])\n",
    "    X_day = np.mean(X_day, axis=1)\n",
    "    Normalizer_ = Normalizer().fit(X_day)\n",
    "    X_day = Normalizer_.transform(X_day)\n",
    "\n",
    "\n",
    "    print(\"Computando PacMAP...\")\n",
    "    pacmap_reducer = pacmap.PaCMAP(n_components=2, n_neighbors=75, MN_ratio=1, FP_ratio=20)\n",
    "    X_pacmap = pacmap_reducer.fit_transform(X_day)\n",
    "    print(\"PacMAP completado\")\n",
    "\n",
    "\n",
    "        # ---- Cargar el raster COB.tif ----\n",
    "    raster_path = \"Complementary_Files/COB.tif\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_data = src.read(1)  # Leer la primera banda\n",
    "        raster_bounds = src.bounds  # Obtener el bounding box del raster\n",
    "        raster_crs = src.crs  # Obtener la proyecciÃ³n del raster\n",
    "\n",
    "    # ---- Transformar coordenadas de grabadoras al sistema del raster ----\n",
    "    print(\"Transformando coordenadas de grabadoras al CRS del raster...\")\n",
    "    gdf_grabadoras = gpd.GeoDataFrame(\n",
    "        {\"grabadora\": sampled_df_ae['location'].unique()},\n",
    "        geometry=[Point(sampled_df_ae[sampled_df_ae['location'] == loc][\"longitud_IG\"].mean(), \n",
    "                        sampled_df_ae[sampled_df_ae['location'] == loc][\"latitude_IG\"].mean()) \n",
    "                  for loc in sampled_df_ae['location'].unique()],\n",
    "        crs=\"EPSG:4326\"  # Sistema original (Lat/Lon)\n",
    "    )\n",
    "\n",
    "    # Transformar al sistema de coordenadas del raster\n",
    "    gdf_grabadoras = gdf_grabadoras.to_crs(raster_crs)\n",
    "\n",
    "    # Guardar coordenadas transformadas\n",
    "    coordenadas_grabadoras = {row.grabadora: row.geometry for _, row in gdf_grabadoras.iterrows()}\n",
    "\n",
    "    # ---- ConstrucciÃ³n del grafo de audios basado en vecinos cercanos ----\n",
    "    n_neighbors = 1\n",
    "    X_audio = X_pacmap  # Usar la proyecciÃ³n PaCMAP\n",
    "    print(\"Construyendo grafo de audio basado en vecinos cercanos...\")\n",
    "    audio_graph = kneighbors_graph(X_audio, n_neighbors=n_neighbors, mode=\"connectivity\", include_self=False)\n",
    "    G_audio = nx.from_scipy_sparse_array(audio_graph)\n",
    "\n",
    "    # ---- ConstrucciÃ³n del grafo de grabadoras ----\n",
    "    print(\"Construyendo grafo de grabadoras basado en conexiones de audio...\")\n",
    "    G_grabadoras = nx.Graph()\n",
    "\n",
    "    # Agregar nodos con nombres de grabadoras\n",
    "    for grabadora in coordenadas_grabadoras:\n",
    "        G_grabadoras.add_node(grabadora, pos=(coordenadas_grabadoras[grabadora].x, coordenadas_grabadoras[grabadora].y))\n",
    "\n",
    "    # ---- Agregar conexiones al grafo de grabadoras usando nombres ----\n",
    "    audio_counts = {}\n",
    "    for i, j in G_audio.edges():\n",
    "        g1, g2 = sampled_df_ae.iloc[i]['location'], sampled_df_ae.iloc[j]['location']\n",
    "        if g1 != g2:\n",
    "            audio_counts[(g1, g2)] = audio_counts.get((g1, g2), 0) + 1\n",
    "\n",
    "    # Agregar conexiones con conteo sin normalizar\n",
    "    for (g1, g2), count in audio_counts.items():\n",
    "        if g1 in G_grabadoras and g2 in G_grabadoras:\n",
    "            G_grabadoras.add_edge(g1, g2, weight=count)\n",
    "\n",
    "    # ---- Aplicando Softmax por grabadora ----\n",
    "    print(\"Aplicando Softmax por grabadora...\")\n",
    "    normalized_weights = {}\n",
    "\n",
    "    for grabadora in G_grabadoras.nodes():\n",
    "        vecinos = list(G_grabadoras[grabadora])\n",
    "        if not vecinos:\n",
    "            continue\n",
    "\n",
    "        pesos = np.array([G_grabadoras[grabadora][v]['weight'] for v in vecinos], dtype=np.float32)\n",
    "        pesos_softmax = softmax(pesos)\n",
    "\n",
    "        for idx, v in enumerate(vecinos):\n",
    "            normalized_weights[(grabadora, v)] = pesos_softmax[idx]\n",
    "\n",
    "    # ---- Aplicar umbral y actualizar el grafo ----\n",
    "    threshold = 0.75\n",
    "    edges_to_remove = []\n",
    "\n",
    "    for (g1, g2), weight in normalized_weights.items():\n",
    "        if weight < threshold:\n",
    "            edges_to_remove.append((g1, g2))\n",
    "        else:\n",
    "            G_grabadoras[g1][g2]['weight'] = weight\n",
    "\n",
    "    G_grabadoras.remove_edges_from(edges_to_remove)\n",
    "\n",
    "    print(f\"Grafo de grabadoras actualizado: {G_grabadoras.number_of_nodes()} nodos, {G_grabadoras.number_of_edges()} conexiones despuÃ©s del umbral.\")\n",
    "\n",
    "    # ---- VisualizaciÃ³n ----\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # Mostrar el raster de fondo\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        show(src, ax=ax, extent=raster_bounds, alpha=0.6)\n",
    "\n",
    "    # Dibujar nodos con nombres correctos\n",
    "    for grabadora, pos in coordenadas_grabadoras_original.items():\n",
    "        ax.scatter(pos.x, pos.y, color='red', s=50, edgecolors='black', zorder=3)\n",
    "        ax.text(pos.x, pos.y+120, grabadora, fontsize=5, ha='right', color='black', bbox=dict(facecolor='none', alpha=1, edgecolor='none'))\n",
    "\n",
    "\n",
    "    # Dibujar los edges con `ax.plot()` y grosor proporcional al peso\n",
    "    for i, j in G_grabadoras.edges():\n",
    "        if i in coordenadas_grabadoras and j in coordenadas_grabadoras:\n",
    "            x_values = [coordenadas_grabadoras[i].x, coordenadas_grabadoras[j].x]\n",
    "            y_values = [coordenadas_grabadoras[i].y, coordenadas_grabadoras[j].y]\n",
    "            weight = G_grabadoras[i][j]['weight']\n",
    "            ax.plot(x_values, y_values, color='red', linewidth=weight*3, alpha=0.75, zorder=3)\n",
    "\n",
    "\n",
    "    ax.set_title(f\"Mapa de Conectividad de Grabadoras sobre COB.tif (Threshold={threshold})\")\n",
    "    plt.savefig(f\"temporal_zamuro/zamuro_connectivity_results/recorders_connectivity_threshold_day_{day}_{threshold}_neighbors_{n_neighbors}.jpg\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebe1cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Point, LineString\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.special import softmax\n",
    "from pyproj import CRS\n",
    "\n",
    "# Cargar el raster COB.tif\n",
    "raster_path = \"Complementary_Files/COB.tif\"\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_data = src.read(1)  # Leer la primera banda\n",
    "    raster_bounds = src.bounds  # Obtener el bounding box del raster\n",
    "    raster_crs = src.crs  # Obtener la proyecciÃ³n del raster\n",
    "\n",
    "# ---- Transformar coordenadas de grabadoras a ESRI:103599 ----\n",
    "print(\"Transformando coordenadas de grabadoras a ESRI:103599...\")\n",
    "gdf_grabadoras = gpd.GeoDataFrame(\n",
    "    {\"grabadora\": sampled_df_ae['location'].unique()},\n",
    "    geometry=[Point(sampled_df_ae[sampled_df_ae['location'] == loc][\"longitud_IG\"].mean(), \n",
    "                    sampled_df_ae[sampled_df_ae['location'] == loc][\"latitude_IG\"].mean()) \n",
    "              for loc in sampled_df_ae['location'].unique()],\n",
    "    crs=\"EPSG:4326\"  # Sistema original (Lat/Lon)\n",
    ")\n",
    "\n",
    "# Transformar al sistema de coordenadas del raster\n",
    "gdf_grabadoras = gdf_grabadoras.to_crs(raster_crs)\n",
    "\n",
    "# Guardar coordenadas transformadas en un diccionario\n",
    "coordenadas_grabadoras = {\n",
    "    gdf_grabadoras.iloc[i].grabadora: gdf_grabadoras.iloc[i].geometry for i in range(len(gdf_grabadoras))\n",
    "}\n",
    "\n",
    "# ---- ConstrucciÃ³n del grafo de grabadoras ----\n",
    "print(\"Construyendo grafo de grabadoras basado en conexiones de audio...\")\n",
    "G_grabadoras = nx.Graph()\n",
    "for grabadora in coordenadas_grabadoras:\n",
    "    G_grabadoras.add_node(grabadora, pos=(coordenadas_grabadoras[grabadora].x, coordenadas_grabadoras[grabadora].y))\n",
    "\n",
    "# Conteo de conexiones entre grabadoras a partir del grafo de audios\n",
    "print(\"Definiendo funciÃ³n de atenciÃ³n basada en conexiones entre grabadoras...\")\n",
    "audio_counts = {}\n",
    "for i, j in G_audio.edges():\n",
    "    g1, g2 = sampled_df_ae.iloc[i]['grabadora_id'], sampled_df_ae.iloc[j]['grabadora_id']\n",
    "    if g1 != g2:\n",
    "        audio_counts[(g1, g2)] = audio_counts.get((g1, g2), 0) + 1\n",
    "\n",
    "# Agregar conexiones al grafo de grabadoras\n",
    "for (g1, g2), count in audio_counts.items():\n",
    "    G_grabadoras.add_edge(g1, g2, weight=count)\n",
    "\n",
    "print(\"Aplicando Softmax por grabadora...\")\n",
    "# Diccionario para almacenar los pesos normalizados por cada grabadora\n",
    "normalized_weights = {}\n",
    "\n",
    "# Aplicar softmax a las conexiones de cada grabadora individualmente\n",
    "for grabadora in G_grabadoras.nodes():\n",
    "    vecinos = list(G_grabadoras[grabadora])\n",
    "    if not vecinos:\n",
    "        continue  # Si no tiene conexiones, continuar\n",
    "\n",
    "    # Obtener los pesos originales de las conexiones\n",
    "    pesos = np.array([G_grabadoras[grabadora][v]['weight'] for v in vecinos], dtype=np.float32)\n",
    "\n",
    "    # Aplicar softmax a los pesos de esta grabadora\n",
    "    pesos_softmax = softmax(pesos)\n",
    "\n",
    "    # Asignar los pesos normalizados al grafo\n",
    "    for idx, v in enumerate(vecinos):\n",
    "        normalized_weights[(grabadora, v)] = pesos_softmax[idx]\n",
    "\n",
    "# Aplicar umbral y actualizar el grafo\n",
    "threshold = 0.75  # Ajusta segÃºn necesidad\n",
    "edges_to_remove = []\n",
    "\n",
    "for (g1, g2), weight in normalized_weights.items():\n",
    "    if weight < threshold:\n",
    "        edges_to_remove.append((g1, g2))  # Marcar para eliminar\n",
    "    else:\n",
    "        G_grabadoras[g1][g2]['weight'] = weight  # Asignar peso normalizado\n",
    "\n",
    "# Eliminar conexiones dÃ©biles\n",
    "G_grabadoras.remove_edges_from(edges_to_remove)\n",
    "\n",
    "print(f\"Grafo de grabadoras actualizado: {G_grabadoras.number_of_nodes()} nodos, {G_grabadoras.number_of_edges()} conexiones despuÃ©s del umbral.\")\n",
    "\n",
    "# ---- VisualizaciÃ³n ----\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Mostrar el raster de fondo\n",
    "with rasterio.open(raster_path) as src:\n",
    "    show(src, ax=ax, extent=raster_bounds, alpha=0.6)\n",
    "\n",
    "# Dibujar los nodos de las grabadoras\n",
    "for grabadora, pos in coordenadas_grabadoras.items():\n",
    "    ax.scatter(pos.x, pos.y, color='red', s=50, edgecolors='black', zorder=3)\n",
    "    ax.text(pos.x, pos.y, grabadora, fontsize=8, ha='right', color='white', bbox=dict(facecolor='black', alpha=0.5, edgecolor='none'))\n",
    "\n",
    "# Dibujar los edges con grosor proporcional al peso\n",
    "for i, j in G_grabadoras.edges():\n",
    "    if i in coordenadas_grabadoras and j in coordenadas_grabadoras:\n",
    "        line = LineString([coordenadas_grabadoras[i], coordenadas_grabadoras[j]])\n",
    "        weight = G_grabadoras[i][j]['weight']\n",
    "        gpd.GeoSeries([line]).plot(ax=ax, color='black', linewidth = max(1.5, weight * 10) , alpha=0.7, zorder=2)\n",
    "\n",
    "ax.set_title(f\"Mapa de Conectividad de Grabadoras sobre COB.tif (Threshold={threshold})\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f61cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Extraer conexiones del grafo con sus pesos\n",
    "edges_data = [(i, j, G_grabadoras[i][j]['weight']) for i, j in G_grabadoras.edges()]\n",
    "\n",
    "# Convertir a DataFrame y ordenar por peso\n",
    "df_connections = pd.DataFrame(edges_data, columns=['Grabadora 1', 'Grabadora 2', 'Peso'])\n",
    "df_connections = df_connections.sort_values(by='Peso', ascending=False)\n",
    "\n",
    "# Mostrar las 10 conexiones mÃ¡s fuertes\n",
    "print(\"Top 10 conexiones con mayor similitud de audio:\")\n",
    "print(df_connections.head(10))\n",
    "\n",
    "# Crear matriz de similitud entre grabadoras\n",
    "grabadoras = list(coordenadas_grabadoras.keys())\n",
    "similarity_matrix = pd.DataFrame(0, index=grabadoras, columns=grabadoras)\n",
    "\n",
    "for i, j, weight in edges_data:\n",
    "    similarity_matrix.at[i, j] = weight\n",
    "    similarity_matrix.at[j, i] = weight  # Matriz simÃ©trica\n",
    "\n",
    "# Visualizar heatmap de similitud\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(similarity_matrix, annot=False, cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Mapa de Calor de Similitud entre Grabadoras\")\n",
    "plt.xlabel(\"Grabadora\")\n",
    "plt.ylabel(\"Grabadora\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
