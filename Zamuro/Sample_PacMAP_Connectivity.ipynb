{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a56defc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:32:45.386940Z",
     "start_time": "2025-02-24T15:32:45.370422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !pip install umap-learn\n",
    "    !pip install umap-learn[plot]\n",
    "    !pip install holoviews\n",
    "\n",
    "    !pip install joypy\n",
    "\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b618bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "gc.collect()  #\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "from Modules.Clustering_Utils_Zamuro import plot_silhouette\n",
    "from Modules.Clustering_Utils_Zamuro import plot_centroids\n",
    "from Modules.Clustering_Utils_Zamuro import ClusteringResults\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import pacmap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import random\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "077eb817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n"
     ]
    }
   ],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 4\n",
    "hour = 9\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "\n",
    "model_name = f\"{root}/Zamuro/temporal_zamuro/models/log_standarization_model_epochs_10/model_{model_type}_{identifier}_{date_format}_final.pth\"\n",
    "model = AE(num_hiddens=64).to(device)\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "filters = {\"rain_FI\": \"NO\"}\n",
    "dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                         dataframe_path=\"Complementary_Files/zamuro_audios.csv\",\n",
    "                         audio_length=12, ext=\"wav\",\n",
    "                         win_length=1028, filters=filters)\n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=100)\n",
    "iterator = iter(test_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e96906d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53275, 5184)\n"
     ]
    }
   ],
   "source": [
    "audios = pd.read_csv(f\"Complementary_Files/zamuro_audios_complete.csv\", index_col=0)\n",
    "recorders = pd.read_csv(f\"Complementary_Files/zamuro_recorders_satelites.csv\", index_col=0)\n",
    "df_ae = pd.read_csv(f\"temporal_zamuro/Features/New_df_ae_unflat.csv\")\n",
    "X = np.asarray(df_ae.loc[:,\"0\":\"25919\"])\n",
    "X = np.reshape(X, [X.shape[0], 5, X.shape[1]//5])\n",
    "X = np.mean(X, axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ddd5574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6403, 5184)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day=5\n",
    "df_day = df_ae[df_ae['day'].isin([day])]\n",
    "X_day = np.asarray(df_day.loc[:,\"0\":\"5183\"])\n",
    "\n",
    "Normalizer_ = Normalizer().fit(X_day)\n",
    "X = Normalizer_.transform(X_day)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d9f95ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PacMAP features\n",
      "PacMAP completed in 161.74 secs.\n",
      "Computing Hamming distance matrix in PacMAP space...\n",
      "Hamming distance computed in 1.78 secs.\n",
      "Computing Graph...\n",
      "Graph computed with 6429 nodes and 1030728 edges.\n",
      "Applying PacMAP-Based Layout...\n",
      "PacMAP Layout completed in 0.00 secs.\n",
      "Graph plotted\n"
     ]
    }
   ],
   "source": [
    "## import numpy as np\n",
    "import pacmap\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk  # Estilo visual mejorado\n",
    "from sklearn.datasets import make_blobs\n",
    "from scipy.spatial import distance_matrix\n",
    "import time\n",
    "\n",
    "\n",
    "# 🔹 Aplicar PacMAP para reducir a 2D\n",
    "\n",
    "print(\"Computing PacMAP features\")\n",
    "start_time = time.time()\n",
    "pacmap_reducer = pacmap.PaCMAP(n_components=2, n_neighbors=75, MN_ratio=1, FP_ratio=20)\n",
    "X_pacmap = pacmap_reducer.fit_transform(X)\n",
    "print(f\"PacMAP completed in {time.time() - start_time:.2f} secs.\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pacmap[:,0], X_pacmap[:,1], s=1, alpha=1)\n",
    "plt.title(\"PacMAP Projection\")\n",
    "plt.show()\n",
    "\n",
    "# 🔹 Construir matriz de distancias de Hamming en el espacio reducido\n",
    "print(\"Computing Hamming distance matrix in PacMAP space...\")\n",
    "start_time = time.time()\n",
    "distance_mat = distance_matrix(X_pacmap, X_pacmap, p=1)  # Distancia de Hamming en 2D\n",
    "print(f\"Hamming distance computed in {time.time() - start_time:.2f} secs.\")\n",
    "\n",
    "# 🔹 Crear grafo basado en distancia de Hamming en el espacio PacMAP\n",
    "print(\"Computing Graph...\")\n",
    "G = nx.Graph()\n",
    "threshold = np.percentile(distance_mat, 5)  # Tomar un umbral bajo para conexiones cercanas\n",
    "graph_edges = []\n",
    "for i in range(len(X_pacmap)):\n",
    "    for j in range(i + 1, len(X_pacmap)):\n",
    "        if distance_mat[i, j] < threshold:\n",
    "            G.add_edge(i, j)\n",
    "            graph_edges.append((i, j))\n",
    "print(f\"Graph computed with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "\n",
    "# 🔹 Usar las coordenadas de PacMAP como layout\n",
    "print(\"Applying PacMAP-Based Layout...\")\n",
    "start_time = time.time()\n",
    "pos_pacmap = {i: X_pacmap[i] for i in range(len(X_pacmap))}  # Usa PacMAP como layout\n",
    "print(f\"PacMAP Layout completed in {time.time() - start_time:.2f} secs.\")\n",
    "\n",
    "# 🔹 Graficar con mejor estilo\n",
    "plt.style.use(\"seaborn-whitegrid\")  # Activar el estilo seaborn-whitegrid\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "nx.draw_networkx_nodes(G, pos_pacmap, node_size=10, node_color='black', alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos_pacmap, edgelist=graph_edges, width=0.3, edge_color=\"red\", alpha=0.3)\n",
    "\n",
    "print(\"Graph plotted\")\n",
    "\n",
    "# 🔹 Efectos visuales\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "plt.title(\"Hamming Layout Edge Bundling (PacMAP)\")\n",
    "plt.xlabel(\"PacMAP 1\")\n",
    "plt.ylabel(\"PacMAP 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb680706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "# 🔹 Simulación de coordenadas de grabadoras en Sudamérica\n",
    "np.random.seed(42)\n",
    "n_grabadoras = 10\n",
    "n_audios = 2000  # 🔥 Ahora usamos 2000 muestras\n",
    "\n",
    "# Coordenadas aleatorias de grabadoras en Sudamérica (Brasil - Argentina)\n",
    "coordenadas_grabadoras = {\n",
    "    i: (np.random.uniform(-20, -5), np.random.uniform(-55, -40))  # Latitud y longitud\n",
    "    for i in range(n_grabadoras)\n",
    "}\n",
    "\n",
    "# 🔹 Asignar audios a grabadoras\n",
    "grabadora_id = np.random.choice(list(coordenadas_grabadoras.keys()), size=n_audios)\n",
    "\n",
    "# 🔹 Generar datos ficticios de espectrogramas (128 dimensiones)\n",
    "X_audio = np.random.rand(n_audios, 128)\n",
    "\n",
    "# 🔹 Construcción de grafo de conectividad entre audios\n",
    "audio_graph = kneighbors_graph(X_audio, n_neighbors=15, mode=\"connectivity\", include_self=False)\n",
    "G_audio = nx.from_scipy_sparse_array(audio_graph)\n",
    "\n",
    "# 🔹 Construcción de grafo de conectividad entre grabadoras\n",
    "G_places = nx.Graph()\n",
    "for i in range(n_grabadoras):\n",
    "    G_places.add_node(i, pos=coordenadas_grabadoras[i])  # Añadir nodos con ubicación geográfica\n",
    "\n",
    "# 🔹 Conectar grabadoras si tienen audios similares\n",
    "for i, j in G_audio.edges():\n",
    "    g1, g2 = grabadora_id[i], grabadora_id[j]\n",
    "    if g1 != g2:  # Solo conectamos si son grabadoras diferentes\n",
    "        if G_places.has_edge(g1, g2):\n",
    "            G_places[g1][g2][\"weight\"] += 1\n",
    "        else:\n",
    "            G_places.add_edge(g1, g2, weight=1)\n",
    "\n",
    "# 🔹 Convertir nodos a GeoDataFrame\n",
    "grabadoras_gdf = gpd.GeoDataFrame(\n",
    "    {\"id\": list(G_places.nodes())},\n",
    "    geometry=gpd.points_from_xy(\n",
    "        [coordenadas_grabadoras[i][1] for i in G_places.nodes()],  # Longitud\n",
    "        [coordenadas_grabadoras[i][0] for i in G_places.nodes()]   # Latitud\n",
    "    ),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# 🔹 Transformar posiciones del grafo para Geopandas\n",
    "pos_geo = {i: (grabadoras_gdf.geometry.x.iloc[i], grabadoras_gdf.geometry.y.iloc[i]) for i in G_places.nodes()}\n",
    "\n",
    "# 🔹 Aplicar Edge Bundling para reducir el cruce de líneas\n",
    "def edge_bundle(G, pos, alpha=0.3, segments=10):\n",
    "    \"\"\" Suaviza las conexiones entre nodos con Edge Bundling \"\"\"\n",
    "    new_edges = []\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        x1, y1 = pos[u]\n",
    "        x2, y2 = pos[v]\n",
    "        \n",
    "        # 🔹 Generamos puntos intermedios para suavizar la curva\n",
    "        x = np.linspace(x1, x2, segments)\n",
    "        y = np.linspace(y1, y2, segments)\n",
    "        \n",
    "        # 🔹 Ajustamos el peso para que las líneas sean más delgadas\n",
    "        weight = max(0.2, data[\"weight\"] * 0.1)  \n",
    "        \n",
    "        new_edges.append((x, y, weight))\n",
    "    \n",
    "    return new_edges\n",
    "\n",
    "# 🔹 Obtener las curvas de edge bundling\n",
    "bundled_edges = edge_bundle(G_places, pos_geo, alpha=0.3, segments=20)\n",
    "\n",
    "# 🔹 Graficar el grafo con Edge Bundling\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 🔹 Dibujar conexiones suavizadas\n",
    "for x, y, weight in bundled_edges:\n",
    "    ax.plot(x, y, color=\"red\", linewidth=weight, alpha=0.4)\n",
    "\n",
    "# 🔹 Dibujar nodos (grabadoras)\n",
    "grabadoras_gdf.plot(ax=ax, color=\"blue\", markersize=80, edgecolor=\"black\", label=\"Grabadoras\")\n",
    "\n",
    "# 🔹 Dibujar Convex Hull para resaltar el área ocupada por las grabadoras\n",
    "points = np.array([pos_geo[i] for i in G_places.nodes()])\n",
    "hull = ConvexHull(points)\n",
    "hull_path = points[hull.vertices]\n",
    "ax.fill(hull_path[:, 0], hull_path[:, 1], color=\"lightgray\", alpha=0.3, label=\"Área de Grabadoras\")\n",
    "\n",
    "# 🔹 Ajustar los límites del gráfico\n",
    "ax.set_xlim(grabadoras_gdf.geometry.x.min() - 2, grabadoras_gdf.geometry.x.max() + 2)\n",
    "ax.set_ylim(grabadoras_gdf.geometry.y.min() - 2, grabadoras_gdf.geometry.y.max() + 2)\n",
    "\n",
    "# 🔹 Ajustes finales\n",
    "plt.title(\"Conectividad entre Lugares Basada en Similitud Acústica (Edge Bundling)\")\n",
    "plt.xlabel(\"Longitud\")\n",
    "plt.ylabel(\"Latitud\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb652cfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import entropy\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "# 1️⃣ Simulación de datos: DataFrame con 1000 audios\n",
    "np.random.seed(42)\n",
    "n_audios = 1000\n",
    "n_features = 512\n",
    "n_grabadoras = 20\n",
    "\n",
    "grabadoras = np.random.randint(0, n_grabadoras, n_audios)  # Asignar cada audio a una grabadora\n",
    "X_audio = np.random.rand(n_audios, n_features)  # Simular características de audio\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(X_audio, columns=[f'feat_{i}' for i in range(n_features)])\n",
    "df['grabadora'] = grabadoras\n",
    "\n",
    "# 2️⃣ Calcular la matriz de distancia/similitud entre audios\n",
    "distance_matrix = squareform(pdist(X_audio, metric=\"euclidean\"))\n",
    "sim_matrix = np.exp(-distance_matrix / np.std(distance_matrix))  # Normalizar mejor la similitud\n",
    "\n",
    "# 3️⃣ Calcular la entropía de cada audio\n",
    "node_entropy = np.array([entropy(sim_matrix[i] + 1e-10) for i in range(n_audios)])  # Evitar log(0)\n",
    "\n",
    "# 4️⃣ Definir umbral de similitud para conexiones entre audios\n",
    "threshold = np.percentile(sim_matrix, 90)  # Usar percentil sobre sim_matrix en lugar de entropía\n",
    "connectivity_matrix = sim_matrix >= threshold  # Conectar audios con alta similitud\n",
    "\n",
    "# 5️⃣ Crear grafo de conectividad de audios\n",
    "G_audio = nx.Graph()\n",
    "for i in range(n_audios):\n",
    "    G_audio.add_node(i, grabadora=df['grabadora'][i])\n",
    "    for j in range(i + 1, n_audios):\n",
    "        if connectivity_matrix[i, j]:\n",
    "            G_audio.add_edge(i, j)\n",
    "\n",
    "# Verificar si el grafo tiene nodos y conexiones\n",
    "print(f\"Nodos en G_audio: {G_audio.number_of_nodes()}, Aristas en G_audio: {G_audio.number_of_edges()}\")\n",
    "\n",
    "# 6️⃣ Construir conectividad entre grabadoras a partir del grafo de audios\n",
    "G_grabadoras = nx.Graph()\n",
    "for i, j in G_audio.edges():\n",
    "    grabadora_i = df['grabadora'][i]\n",
    "    grabadora_j = df['grabadora'][j]\n",
    "    if grabadora_i != grabadora_j:\n",
    "        if G_grabadoras.has_edge(grabadora_i, grabadora_j):\n",
    "            G_grabadoras[grabadora_i][grabadora_j]['weight'] += 1\n",
    "        else:\n",
    "            G_grabadoras.add_edge(grabadora_i, grabadora_j, weight=1)\n",
    "\n",
    "# 7️⃣ Simulación de coordenadas de grabadoras para visualización\n",
    "coordenadas = {i: Point(np.random.uniform(-100, 100), np.random.uniform(-100, 100)) for i in range(n_grabadoras)}\n",
    "geo_df = gpd.GeoDataFrame({\"grabadora\": list(coordenadas.keys()), \"geometry\": list(coordenadas.values())})\n",
    "\n",
    "# 8️⃣ Visualización del mapa de conectividad entre grabadoras\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "geo_df.plot(ax=ax, color='red', markersize=50, label=\"Grabadoras\")\n",
    "\n",
    "# Dibujar conexiones entre grabadoras\n",
    "for i, j in G_grabadoras.edges():\n",
    "    if i in coordenadas and j in coordenadas:\n",
    "        line = LineString([coordenadas[i], coordenadas[j]])\n",
    "        gpd.GeoSeries([line]).plot(ax=ax, color='blue', linewidth=G_grabadoras[i][j]['weight'] * 0.001)\n",
    "\n",
    "ax.set_title(\"Mapa de conectividad entre grabadoras basado en Graph Entropy de Audios\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
