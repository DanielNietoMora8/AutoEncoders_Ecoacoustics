{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a56defc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:32:45.386940Z",
     "start_time": "2025-02-24T15:32:45.370422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !pip install umap-learn\n",
    "    !pip install umap-learn[plot]\n",
    "    !pip install holoviews\n",
    "\n",
    "    !pip install joypy\n",
    "\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b618bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "gc.collect()  #\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "from Modules.Clustering_Utils_Zamuro import plot_silhouette\n",
    "from Modules.Clustering_Utils_Zamuro import plot_centroids\n",
    "from Modules.Clustering_Utils_Zamuro import ClusteringResults\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import pacmap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import random\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660e6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n"
     ]
    }
   ],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 4\n",
    "hour = 9\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "\n",
    "model_name = f\"{root}/Zamuro/temporal_zamuro/models/log_standarization_model_epochs_10/model_{model_type}_{identifier}_{date_format}_final.pth\"\n",
    "model = AE(num_hiddens=64).to(device)\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "filters = {\"rain_FI\": \"NO\"}\n",
    "dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                         dataframe_path=\"Complementary_Files/zamuro_audios.csv\",\n",
    "                         audio_length=12, ext=\"wav\",\n",
    "                         win_length=1028, filters=filters)\n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=100)\n",
    "iterator = iter(test_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e96906d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53275, 5184)\n"
     ]
    }
   ],
   "source": [
    "audios = pd.read_csv(f\"Complementary_Files/zamuro_audios_complete.csv\", index_col=0)\n",
    "recorders = pd.read_csv(f\"Complementary_Files/zamuro_recorders_satelites.csv\", index_col=0)\n",
    "df_ae = pd.read_csv(f\"temporal_zamuro/Features/New_df_ae_unflat.csv\")\n",
    "X = np.asarray(df_ae.loc[:,\"0\":\"25919\"])\n",
    "X = np.reshape(X, [X.shape[0], 5, X.shape[1]//5])\n",
    "X = np.mean(X, axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ddd5574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6403, 5184)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day=5\n",
    "df_day = df_ae[df_ae['day'].isin([day])]\n",
    "X_day = np.asarray(df_day.loc[:,\"0\":\"5183\"])\n",
    "\n",
    "Normalizer_ = Normalizer().fit(X_day)\n",
    "X = Normalizer_.transform(X_day)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a06836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 515, 515)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "def plot_centroids_spec(point, model, extra=None, save=True, root=None):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    model._model.to(\"cpu\")\n",
    "    encodings = point.reshape(64, 9, 9)\n",
    "    encodings = torch.tensor(encodings).float()\n",
    "    decodings = model._model.decoder(encodings).detach().numpy()\n",
    "    print(decodings.shape)\n",
    "    plt.imshow(librosa.power_to_db(decodings[0, :, :]), origin=\"lower\", cmap=\"viridis\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    \n",
    "    \n",
    "points = np.array(X[200]).reshape(1, -1)\n",
    "\n",
    "plot_centroids_spec(points, testing)  # Generar espectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b74f1eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Configuraci칩n de la cuadr칤cula\n",
    "ROWS, COLS = 4, 4  # N칰mero de filas y columnas por p치gina\n",
    "IMAGES_PER_PAGE = ROWS * COLS  # Total de im치genes por p치gina\n",
    "\n",
    "plt.ion()  # Modo interactivo\n",
    "\n",
    "# Variables de paginaci칩n\n",
    "fig, axarr = None, None  \n",
    "img_count = 0  # Contador de im치genes en la p치gina actual\n",
    "page_count = 0  # Contador de p치ginas totales\n",
    "\n",
    "def new_page():\n",
    "    \"\"\"Crea una nueva p치gina cuando la cuadr칤cula est치 llena.\"\"\"\n",
    "    global fig, axarr, img_count, page_count\n",
    "    \n",
    "    fig, axarr = plt.subplots(ROWS, COLS, figsize=(12, 12))\n",
    "    fig.suptitle(f\"P치gina {page_count + 1}\", fontsize=16, fontweight=\"bold\")\n",
    "    img_count = 0  # Reiniciar contador\n",
    "    page_count += 1  # Incrementar n칰mero de p치gina\n",
    "\n",
    "    plt.pause(0.1)  # Peque침a pausa para actualizar la ventana\n",
    "\n",
    "def plot_centroids_spec(point, model, index, umap_coords, extra=None, save=True, root=None):\n",
    "    global img_count, fig, axarr  # Variables globales\n",
    "\n",
    "    model._model.to(\"cpu\")\n",
    "    encodings = point.reshape(64, 9, 9)\n",
    "    encodings = torch.tensor(encodings).float()\n",
    "    decodings = model._model.decoder(encodings).detach().numpy()\n",
    "\n",
    "    # 游댳 Crear nueva p치gina si es necesario\n",
    "    if img_count >= IMAGES_PER_PAGE:\n",
    "        new_page()\n",
    "\n",
    "    row, col = divmod(img_count, COLS)\n",
    "\n",
    "    # Graficar\n",
    "    axarr[row, col].imshow(librosa.power_to_db(decodings[0, :, :]), origin=\"lower\", cmap=\"viridis\")\n",
    "    axarr[row, col].set_xticks(())\n",
    "    axarr[row, col].set_yticks(())\n",
    "\n",
    "    # 游댳 Usar las coordenadas UMAP en el t칤tulo\n",
    "    axarr[row, col].set_title(f\"Punto {index} (UMAP: {umap_coords[0]:.2f}, {umap_coords[1]:.2f})\")\n",
    "\n",
    "    img_count += 1  # Incrementar el contador\n",
    "\n",
    "    plt.draw()  # 游댳 Actualizar la ventana inmediatamente\n",
    "    plt.pause(0.5)  # Peque침a pausa para visualizaci칩n fluida\n",
    "\n",
    "\n",
    "def plot_spec(index, df, extra=None, save=True, root=None):\n",
    "    \n",
    "    plt.figure(figsize=(18, 18))\n",
    "    model._model.to(\"cpu\")\n",
    "    encodings = point.reshape(64, 9, 9)\n",
    "    encodings = torch.tensor(encodings).float()\n",
    "    decodings = model._model.decoder(encodings).detach().numpy()\n",
    "    print(decodings.shape)\n",
    "    plt.imshow(librosa.power_to_db(decodings[0, :, :]), origin=\"lower\", cmap=\"viridis\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af483f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing UMAP features\n",
      "UMAP completed.\n",
      "Clicked on point 5598 at (UMAP1: 5.35, UMAP2: -1.78)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/matplotlib/cbook/__init__.py\", line 307, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_201620/3881413882.py\", line 76, in on_click\n",
      "    plot_centroids_spec(point, model, index, umap_coords)\n",
      "  File \"/tmp/ipykernel_201620/1504697735.py\", line 34, in plot_centroids_spec\n",
      "    model._model.to(\"cpu\")\n",
      "  File \"/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1265, in __getattr__\n",
      "    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
      "AttributeError: 'ConvAE' object has no attribute '_model'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "%matplotlib qt\n",
    "\n",
    "# 游댳 Configurar UMAP\n",
    "print(\"Computing UMAP features\")\n",
    "mapper = umap.UMAP(n_components=2, min_dist=0.01,\n",
    "                    metric=\"euclidean\", n_neighbors=75,\n",
    "                    random_state=0, n_jobs=-1).fit(X) \n",
    "X_UMAP = mapper.transform(X)\n",
    "print(\"UMAP completed.\")\n",
    "\n",
    "# 游댳 Graficar la proyecci칩n de UMAP\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(X_UMAP[:, 0], X_UMAP[:, 1], s=10, alpha=0.6, c='blue')\n",
    "ax.set_title(\"UMAP Projection\")\n",
    "ax.set_xlabel(\"UMAP 1\")\n",
    "ax.set_ylabel(\"UMAP 2\")\n",
    "\n",
    "# 游댳 Mostrar coordenadas en tiempo real\n",
    "tooltip = ax.text(0, 0, \"\", va=\"bottom\", ha=\"left\", fontsize=10, color=\"red\", backgroundcolor=\"white\")\n",
    "highlight, = ax.plot([], [], \"ro\", markersize=6)  # Punto resaltado\n",
    "\n",
    "# 游댳 Umbral de distancia para detectar puntos cercanos\n",
    "distance_threshold = 0.05  # Ajusta seg칰n la escala de tus datos\n",
    "\n",
    "def find_nearest_point(event):\n",
    "    \"\"\" Encuentra el punto m치s cercano al cursor dentro del umbral. \"\"\"\n",
    "    if event.inaxes == ax:\n",
    "        cursor = np.array([event.xdata, event.ydata])\n",
    "        distances = np.linalg.norm(X_UMAP - cursor, axis=1)\n",
    "        min_dist = np.min(distances)\n",
    "        index = np.argmin(distances)\n",
    "        \n",
    "        if min_dist < distance_threshold:  # Solo mostrar si est치 dentro del umbral\n",
    "            return index, X_UMAP[index]\n",
    "    return None, None\n",
    "\n",
    "def on_hover(event):\n",
    "    \"\"\" Muestra coordenadas solo si el cursor est치 cerca de un punto. \"\"\"\n",
    "    index, point = find_nearest_point(event)\n",
    "    if point is not None:\n",
    "        tooltip.set_position((point[0], point[1]))\n",
    "        tooltip.set_text(f\"({point[0]:.2f}, {point[1]:.2f})\")\n",
    "        highlight.set_data(point[0], point[1])  # Resaltar punto\n",
    "    else:\n",
    "        tooltip.set_text(\"\")\n",
    "        highlight.set_data([], [])  # Eliminar resaltado\n",
    "\n",
    "    fig.canvas.draw()\n",
    "\n",
    "def on_click(event):\n",
    "    global img_count, fig, axarr  # Asegurar uso de variables globales\n",
    "\n",
    "    if event.inaxes == ax:\n",
    "        # Encuentra el punto m치s cercano en X_UMAP\n",
    "        distances = np.linalg.norm(X_UMAP - np.array([event.xdata, event.ydata]), axis=1)\n",
    "        index = np.argmin(distances)\n",
    "\n",
    "        # Recuperar coordenadas UMAP\n",
    "        umap_coords = X_UMAP[index]  # [UMAP1, UMAP2]\n",
    "\n",
    "        print(f\"Clicked on point {index} at (UMAP1: {umap_coords[0]:.2f}, UMAP2: {umap_coords[1]:.2f})\")\n",
    "\n",
    "        # Transformar el punto de vuelta al espacio original (latente)\n",
    "        point = np.array([X_UMAP[index, 0], X_UMAP[index, 1]]).reshape(1, -1)\n",
    "        point = mapper.inverse_transform(point)  # Espacio original de reducci칩n\n",
    "        point = Normalizer_.inverse_transform(point)  # Datos antes de la normalizaci칩n\n",
    "\n",
    "        # 游댳 Si es el primer clic, abrir autom치ticamente la primera p치gina\n",
    "        if img_count == 0:\n",
    "            new_page()\n",
    "\n",
    "        # 游댳 Llamar a la funci칩n de espectrograma pasando UMAP coords\n",
    "        plot_centroids_spec(point, model, index, umap_coords)\n",
    "\n",
    "\n",
    "fig.canvas.mpl_connect(\"motion_notify_event\", on_hover)\n",
    "fig.canvas.mpl_connect(\"button_press_event\", on_click)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
