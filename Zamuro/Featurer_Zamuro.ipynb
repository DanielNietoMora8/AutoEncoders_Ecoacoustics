{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-03T17:06:39.352635192Z",
     "start_time": "2023-07-03T17:06:39.343527422Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18052,
     "status": "ok",
     "timestamp": 1678388233869,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "2OLjDqbgadV7",
    "outputId": "a38c57aa-e4dd-46fe-aca2-9e6bd6d0cd65"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    # !wandb login\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4523,
     "status": "ok",
     "timestamp": 1678388238390,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ucIGvQ7GczZb",
    "outputId": "0bdf55db-463b-4047-8259-f7dc96b407f1"
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio.transforms as audio_transform\n",
    "\n",
    "from Jaguas_DataLoader_rainless import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel # For AE\n",
    "# from PosAE_training_functions import posautoencoding_m1 as AE, TestModel, TrainModel # For PosAE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "print(device)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jPCv40Ugk0I",
    "outputId": "b093c1e1-5419-407e-a180-ab158e8f79ba"
   },
   "outputs": [],
   "source": [
    "def featuring_autoencoders(dataset, date_format, model, len_features=None, save=True, identifier=None):\n",
    "    training_loader = DataLoader(dataset, batch_size=1)\n",
    "    iterator = iter(training_loader)\n",
    "    testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "\n",
    "    training_recorder_list = []\n",
    "    training_hour_list = []\n",
    "    training_minute_list = []\n",
    "    delete_samples = []\n",
    "    training_path_samples = []\n",
    "    training_samples_list_torch = []\n",
    "    \n",
    "    if len_features == None:\n",
    "        len_features = len(training_loader)\n",
    "    else:\n",
    "        len_features = len_features\n",
    "        \n",
    "    batch = int(len_features*0.1)\n",
    "    \n",
    "    for id in range(len_features):\n",
    "    #     if (id+1)%3 == 0:\n",
    "    #         break\n",
    "        if (id+1)% batch == 0:\n",
    "            print(f\"id: {id + 1} of {len_features}\")\n",
    "        try:\n",
    "            originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "        except:\n",
    "            print(f\"error id: {id}\")\n",
    "            delete_samples.append(id)\n",
    "            continue\n",
    "\n",
    "    #     encodings_size = encodings[0].shape\n",
    "        encodings = encodings.to(\"cuda\").detach()\n",
    "        encodings = encodings.reshape(encodings.shape[0],\n",
    "                                    encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "        training_samples_list_torch.append(encodings)\n",
    "        training_recorder_list.append(label[\"recorder\"].reshape(label[\"recorder\"].shape[0]*label[\"recorder\"].shape[1]))\n",
    "        training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "        training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "\n",
    "\n",
    "        path = np.asarray(path, dtype=\"U32\")\n",
    "        path = np.repeat(path, 5)\n",
    "        indexer = [\"_1\",\"_2\",\"_3\",\"_4\",\"_5\"]\n",
    "        indexer = np.asarray(indexer)\n",
    "        # path = path.astype(\"float64\")\n",
    "        for i in range(len(path)):\n",
    "#             print(path[i] + identifier[i])\n",
    "            path[i] = path[i] + indexer[i]\n",
    "#             print(path[i]) \n",
    "        training_path_samples.append(path)\n",
    "\n",
    "    training_recorder_list = torch.cat(training_recorder_list,dim=0)\n",
    "    training_hour_list = torch.cat(training_hour_list,dim=0)\n",
    "    training_minute_list = torch.cat(training_minute_list,dim=0)\n",
    "    training_samples_list_torch = torch.cat(training_samples_list_torch, dim=0)\n",
    "    \n",
    "    if save == True:\n",
    "    \n",
    "        if \"filters\" in dataset.kwargs.keys():\n",
    "            for value in dataset.filters.values():\n",
    "                date_format = f\"{date_format}_{value}\" \n",
    "        print(identifier)\n",
    "        if identifier != None:\n",
    "            date_format = f\"{date_format}_{identifier}\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        torch.save(training_path_samples, f\"temporal/Features/AE_test_path_samples_{date_format}.pth\")\n",
    "        torch.save(training_samples_list_torch, f\"temporal/Features/AE_features_{date_format}.pth\")\n",
    "        training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "        torch.save(training_labels_list, f\"temporal/Features/AE_labels_{date_format}.pth\")\n",
    "        torch.save(delete_samples, f\"temporal/Features/AE_test_corrupted_samples_list_{date_format}.pth\")\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1678388246582,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "qemaBluJa22A",
    "outputId": "30519d6b-ea58-4423-cb89-b2c5ffb7d854"
   },
   "outputs": [],
   "source": [
    "model = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 11\n",
    "hour = 21\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "model_name = f\"{root}/Jaguas/temporal/models/model_{model}_{identifier}_{date_format}_final.pth\"\n",
    "config = torch.load(f'{root}/Jaguas/temporal/configs/config_{model}_{identifier}_{date_format}.pth', map_location=torch.device('cpu'))\n",
    "model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folders = os.listdir(f\"/{root_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [\"Audios_Jaguas\"]\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    filters = {\"Intensity_Category\": \"No_rain\"}\n",
    "    dataset = SoundscapeData(root_path, dataframe_path=f\"Complementary_Files/Audios_Jaguas/{folder}.csv\",\n",
    "                             audio_length=12, ext=\"wav\",\n",
    "                             win_length=1028, filters=filters)\n",
    "    featuring_autoencoders(dataset, f\"{date_format}_rain\", model=model, len_features=None, save=True, identifier=f\"{folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 9\n",
    "hour = 4\n",
    "month = 6\n",
    "folder = \"AE_rain\"\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "y = torch.load(f\"temporal/Features/{folder}/AE_labels_{date_format}_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "X = torch.load(f\"temporal/Features/{folder}/AE_features_{date_format}_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "path = torch.load(f\"temporal/Features/{folder}/AE_test_path_samples_{date_format}_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "path_flat = [item for sublist in path for item in sublist]\n",
    "path_flat = np.asarray(path_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "error",
     "timestamp": 1678388483545,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "SvnFOiVpq63a",
    "outputId": "58f9d9b0-d822-4f3b-c8d2-6e801391f3b2"
   },
   "outputs": [],
   "source": [
    "folder = \"Audios_Jaguas\"\n",
    "dataset = SoundscapeData(root_path, dataframe_path=f\"Complementary_Files/Audios_Jaguas/{folder}.csv\",\n",
    "                             audio_length=12, ext=\"wav\",\n",
    "                             win_length=1028)# filters=filters)\n",
    "training_loader = DataLoader(dataset, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "encodings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(dataset, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "encodings = encodings.to(\"cuda\").detach()\n",
    "encodings = encodings.reshape(encodings.shape[0],\n",
    "                            encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "prueba.append(encodings)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
