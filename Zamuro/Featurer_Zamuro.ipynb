{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T20:49:09.674455942Z",
     "start_time": "2024-02-08T20:49:09.662998758Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18052,
     "status": "ok",
     "timestamp": 1678388233869,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "2OLjDqbgadV7",
    "outputId": "a38c57aa-e4dd-46fe-aca2-9e6bd6d0cd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    # !wandb login\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4523,
     "status": "ok",
     "timestamp": 1678388238390,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ucIGvQ7GczZb",
    "outputId": "0bdf55db-463b-4047-8259-f7dc96b407f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio.transforms as audio_transform\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel # For AE\n",
    "# from PosAE_training_functions import posautoencoding_m1 as AE, TestModel, TrainModel # For PosAE\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "print(device)\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jPCv40Ugk0I",
    "outputId": "b093c1e1-5419-407e-a180-ab158e8f79ba"
   },
   "outputs": [],
   "source": [
    "def featuring_autoencoders(dataset, date_format, model, len_features=None, save=True, identifier=None):\n",
    "    training_loader = DataLoader(dataset, batch_size=1)\n",
    "    iterator = iter(training_loader)\n",
    "    testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "\n",
    "    training_recorder_list = []\n",
    "    training_hour_list = []\n",
    "    training_minute_list = []\n",
    "    delete_samples = []\n",
    "    training_path_samples = []\n",
    "    training_samples_list_torch = []\n",
    "    \n",
    "    if len_features == None:\n",
    "        len_features = len(training_loader)\n",
    "    else:\n",
    "        len_features = len_features\n",
    "        \n",
    "    batch = int(len_features*0.1)\n",
    "    \n",
    "    for id in range(len_features):\n",
    "        if (id+1)% batch == 0:\n",
    "            print(f\"id: {id + 1} of {len_features}\")\n",
    "        try:\n",
    "            originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "        except:\n",
    "            print(f\"error id: {id}\")\n",
    "            delete_samples.append(id)\n",
    "            continue\n",
    "\n",
    "    #     encodings_size = encodings[0].shape\n",
    "        encodings = encodings.to(\"cuda\").detach()\n",
    "        encodings = encodings.reshape(encodings.shape[0],\n",
    "                                    encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "        training_samples_list_torch.append(encodings)\n",
    "        label[\"recorder\"]=np.repeat(label[\"recorder\"][0][0],5)\n",
    "        training_recorder_list.append(label[\"recorder\"])\n",
    "        training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "        training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "\n",
    "\n",
    "        path = np.asarray(path, dtype=\"U32\")\n",
    "        path = np.repeat(path, 5)\n",
    "        indexer = [\"_1\",\"_2\",\"_3\",\"_4\",\"_5\"]\n",
    "        indexer = np.asarray(indexer)\n",
    "        # path = path.astype(\"float64\")\n",
    "        for i in range(len(path)):\n",
    "#             print(path[i] + identifier[i])\n",
    "            path[i] = path[i] + indexer[i]\n",
    "#             print(path[i]) \n",
    "        training_path_samples.append(path)\n",
    "    \n",
    "#     training_recorder_list = torch.cat(training_recorder_list,dim=0)\n",
    "    training_hour_list = torch.cat(training_hour_list,dim=0)\n",
    "    training_minute_list = torch.cat(training_minute_list,dim=0)\n",
    "    training_samples_list_torch = torch.cat(training_samples_list_torch, dim=0)\n",
    "    \n",
    "    if save == True:\n",
    "    \n",
    "        if \"filters\" in dataset.kwargs.keys():\n",
    "            for value in dataset.filters.values():\n",
    "                date_format = f\"{date_format}_{value}\" \n",
    "        if identifier != None:\n",
    "            date_format = f\"{date_format}_{identifier}\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        torch.save(training_path_samples, f\"temporal_zamuro/Features/AE_test_path_samples_{date_format}.pth\")\n",
    "        torch.save(training_samples_list_torch, f\"temporal_zamuro/Features/AE_features_{date_format}.pth\")\n",
    "        training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "        torch.save(training_labels_list, f\"temporal_zamuro/Features/AE_labels_{date_format}.pth\")\n",
    "        torch.save(delete_samples, f\"temporal_zamuro/Features/AE_test_corrupted_samples_list_{date_format}.pth\")\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1678388246582,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "qemaBluJa22A",
    "outputId": "30519d6b-ea58-4423-cb89-b2c5ffb7d854"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 4\n",
    "hour = 9\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "model_name = f\"{root}/Zamuro/temporal_zamuro/models/model_{model}_{identifier}_{date_format}_final.pth\"\n",
    "config = torch.load(f'{root}/Zamuro/temporal_zamuro/configs/config_{model}_{identifier}_{date_format}.pth', map_location=torch.device('cpu'))\n",
    "model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folders = os.listdir(f\"Complementary_Files/Audios_Zamuro/\")\n",
    "# folders = [os.path.splitext(filename)[0] for filename in os.listdir(f\"Complementary_Files/Audios_Zamuro/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RZUD06.csv\n",
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n",
      "id: 87 of 871\n",
      "id: 174 of 871\n",
      "id: 261 of 871\n",
      "id: 348 of 871\n",
      "id: 435 of 871\n",
      "id: 522 of 871\n",
      "id: 609 of 871\n",
      "id: 696 of 871\n",
      "id: 783 of 871\n",
      "id: 870 of 871\n",
      "RZUG04.csv\n",
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n",
      "id: 79 of 793\n",
      "id: 158 of 793\n",
      "id: 237 of 793\n",
      "id: 316 of 793\n",
      "id: 395 of 793\n",
      "id: 474 of 793\n",
      "id: 553 of 793\n",
      "id: 632 of 793\n",
      "id: 711 of 793\n",
      "id: 790 of 793\n",
      "RZUD04.csv\n",
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n",
      "id: 84 of 847\n",
      "id: 168 of 847\n",
      "id: 252 of 847\n",
      "id: 336 of 847\n",
      "id: 420 of 847\n",
      "id: 504 of 847\n",
      "id: 588 of 847\n",
      "id: 672 of 847\n",
      "id: 756 of 847\n",
      "id: 840 of 847\n",
      "RZUE12.csv\n",
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n",
      "id: 70 of 703\n",
      "id: 140 of 703\n",
      "id: 210 of 703\n",
      "id: 280 of 703\n",
      "id: 350 of 703\n",
      "id: 420 of 703\n",
      "id: 490 of 703\n",
      "id: 560 of 703\n",
      "id: 630 of 703\n",
      "id: 700 of 703\n",
      "RZUD09.csv\n",
      "/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/\n",
      "id: 71 of 719\n",
      "id: 142 of 719\n",
      "id: 213 of 719\n",
      "id: 284 of 719\n",
      "id: 355 of 719\n",
      "id: 426 of 719\n"
     ]
    }
   ],
   "source": [
    "# folders = [\"Audios_Jaguas\"]\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    filters = {\"rain_FI\": \"NO\"}\n",
    "    dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                         dataframe_path=f\"Complementary_Files/Audios_Zamuro/{folder}\",\n",
    "                         audio_length=12, ext=\"wav\",\n",
    "                         win_length=1028, filters=filters)\n",
    "    featuring_autoencoders(dataset, f\"{date_format}_rain\", model=model, len_features=None, save=True, identifier=f\"{folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {\"rain_FI\": \"NO\"}\n",
    "dataset = SoundscapeData('media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido/',\n",
    "                     dataframe_path=\"Complementary_Files/zamuro_audios.csv\",\n",
    "                     audio_length=12, ext=\"wav\",\n",
    "                     win_length=1028, filters=filters)\n",
    "\n",
    "len_features=None\n",
    "save=True\n",
    "identifier=None\n",
    "\n",
    "training_loader = DataLoader(dataset, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "\n",
    "training_recorder_list = []\n",
    "training_hour_list = []\n",
    "training_minute_list = []\n",
    "delete_samples = []\n",
    "training_path_samples = []\n",
    "training_samples_list_torch = []\n",
    "\n",
    "if len_features == None:\n",
    "        len_features = len(training_loader)\n",
    "else:\n",
    "    len_features = len_features\n",
    "        \n",
    "batch = int(len_features*0.1)\n",
    "\n",
    "for id in range(len_features):\n",
    "#     if (id+1)%3 == 0:\n",
    "#         break\n",
    "    if (id+1)% batch == 0:\n",
    "        print(f\"id: {id + 1} of {len_features}\")\n",
    "        \n",
    "(originals, reconstructions, encodings, label, loss, path) = testing.reconstruct()\n",
    "#         except:\n",
    "#             print(f\"error id: {id}\")\n",
    "#             delete_samples.append(id)\n",
    "#             continue\n",
    "\n",
    "    #     encodings_size = encodings[0].shape\n",
    "encodings = encodings.to(\"cuda\").detach()\n",
    "encodings = encodings.reshape(encodings.shape[0],\n",
    "                            encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "training_samples_list_torch.append(encodings)\n",
    "label[\"recorder\"]=np.repeat(label[\"recorder\"][0][0],5)\n",
    "training_recorder_list.append(label[\"recorder\"])\n",
    "training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 4\n",
    "hour = 9\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "y = torch.load(f\"temporal_zamuro/Features/AE_labels_{date_format}_rain_NO_RZUA02.csv.pth\",  map_location=torch.device('cpu'))\n",
    "X = torch.load(f\"temporal_zamuro/Features/AE_features_{date_format}_rain_NO_RZUA02.csv.pth\",  map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra = X\n",
    "muestra[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 9\n",
    "hour = 4\n",
    "month = 6\n",
    "folder = \"AE_rain\"\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "y = torch.load(f\"temporal_zamuro/Features/{folder}/AE_labels_{date_format}_rain_NO_RZUA01.pth\",  map_location=torch.device('cpu'))\n",
    "X = torch.load(f\"temporal_zamuro/Features/{folder}/AE_features_{date_format}_rain_NO_RZUA01.pth\",  map_location=torch.device('cpu'))\n",
    "path = torch.load(f\"temporal_zamuro/Features/{folder}/AE_test_path_samples_{date_format}_rain_NO_RZUA01.pth\",  map_location=torch.device('cpu'))\n",
    "path_flat = [item for sublist in path for item in sublist]\n",
    "path_flat = np.asarray(path_flat)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
