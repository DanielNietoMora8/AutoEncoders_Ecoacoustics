{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1a613c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T16:04:40.092443Z",
     "start_time": "2024-04-22T16:04:40.078736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !pip install umap-learn\n",
    "    !pip install umap-learn[plot]\n",
    "    !pip install holoviews\n",
    "\n",
    "    !pip install joypy\n",
    "\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"/media/mirp_ai/Seagate Desktop Drive/Datos Rey Zamuro/Ultrasonido\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1eb0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from Zamuro_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "import random\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "023cc930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_audios_Zamuro = f\"{root}/Zamuro/Complementary_Files/zamuro_audios.csv\"\n",
    "root_recorders_Zamuro = f\"{root}/Zamuro/Complementary_Files/zamuro_recorders.csv\"\n",
    "root_ai_Zamuro = f\"{root}/Zamuro/AI_Caract/AI_Zamuro.csv\"\n",
    "\n",
    "audios = pd.read_csv(root_audios_Zamuro, index_col=0)\n",
    "recorders = pd.read_csv(root_recorders_Zamuro, index_col=0)\n",
    "df_ai = pd.read_csv(root_ai_Zamuro, index_col=0)\n",
    "df_ai.dropna(inplace=True)\n",
    "df_ai.set_index(\"file\",inplace=True, drop=True)\n",
    "df_ai.drop(columns=[\"Date\"], inplace=True)\n",
    "df_ai = df_ai.reset_index(drop=False)\n",
    "df_ai.rename(columns={\"file\":\"y\"}, inplace=True)\n",
    "y = df_ai.pop('y') \n",
    "df_ai['y'] = y \n",
    "df_ai['rain_FI'] = df_ai.index.map(audios['rain_FI'])\n",
    "\n",
    "def combinar_nombre_ubicacion(row):\n",
    "    return f\"{row['field_number_PR']}_{row['Filename']}\"\n",
    "\n",
    "# Aplicando la función a cada fila del DataFrame para crear la nueva columna\n",
    "audios['Filename_'] = audios.apply(combinar_nombre_ubicacion, axis=1)\n",
    "\n",
    "audios.set_index(\"Filename_\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b5e2483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10771/2020597271.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ai[['location', 'day', 'hour']] =df_ai['y'].apply(extract_parts)\n",
      "/tmp/ipykernel_10771/2020597271.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ai['hour_stage'] =df_ai['hour'].apply(define_hour_stage)\n",
      "/tmp/ipykernel_10771/2020597271.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ai['cover'] = df_ai.index.map(audios['cover'])\n"
     ]
    }
   ],
   "source": [
    "def extract_parts(row):\n",
    "    parts = row.split('_')\n",
    "    location = parts[0]\n",
    "    date = parts[1]\n",
    "    time = parts[2].split('.')[0]  # Eliminar la extensión .WAV\n",
    "    day = date[-2:]  # Últimos dos caracteres para el día\n",
    "    hour = time[:2]\n",
    "    return pd.Series([location, day, hour])\n",
    "\n",
    "# Aplicar la función a la columna 'y' y crear nuevas columnas\n",
    "df_ai[['location', 'day', 'hour']] =df_ai['y'].apply(extract_parts)\n",
    "\n",
    "def define_hour_stage(hour):\n",
    "    hour = int(hour)\n",
    "    if 5 <= hour <= 8:\n",
    "        return 'morning'\n",
    "    elif 9 <= hour <= 16:\n",
    "        return 'day'\n",
    "    else:\n",
    "        return 'night'\n",
    "\n",
    "df_ai['hour_stage'] =df_ai['hour'].apply(define_hour_stage)\n",
    "df_ai.set_index(\"y\", inplace=True, drop=False)\n",
    "df_ai['cover'] = df_ai.index.map(audios['cover'])\n",
    "df_ai = df_ai[df_ai['rain_FI'] == 'NO']\n",
    "df_ai = df_ai.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2764d714",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ZCR', 'MEANt', 'VARt', 'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED',\n",
       "       'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction',\n",
       "       'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS',\n",
       "       'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS',\n",
       "       'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy',\n",
       "       'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC',\n",
       "       'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean',\n",
       "       'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon',\n",
       "       'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day = df_ai[df_ai['day'].isin([\"05\"])]\n",
    "df_day.columns[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a2f0341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8043478260869565\n",
      "f1: 0.701019281515238\n",
      "recall 0.6510204081632653\n",
      "Accuracy: 0.8\n",
      "f1: 0.707936507936508\n",
      "recall 0.66196575604002\n",
      "Accuracy: 0.7913209955328654\n",
      "f1: 0.7130842119883525\n",
      "recall 0.6798427607365841\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m clf_rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m y_pred_rf \u001b[38;5;241m=\u001b[39m clf_rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     18\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, y_pred_rf)\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/threading.py:600\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 600\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracies_ai = []\n",
    "f1_scores_ai = []\n",
    "recalls_ai = []\n",
    "df_day={}\n",
    "for i in [\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\",\"13\"]:\n",
    "    df_day = df_ai[df_ai['day'].isin([i])]\n",
    "    X = np.asarray(df_day.iloc[:,0:60])\n",
    "    y = np.asarray(df_day.loc[:,\"cover\"])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "    clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "    clf_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = clf_rf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "    f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"f1:\", f1_score)\n",
    "    print(\"recall\", recall)\n",
    "\n",
    "    accuracies_ai.append(accuracy)\n",
    "    f1_scores_ai.append(f1_score)\n",
    "    recalls_ai.append(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babcee1a",
   "metadata": {},
   "source": [
    "### Acoustic Indices Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174fef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ai = []\n",
    "remove = []\n",
    "s=0\n",
    "for i in range(len(y_3)):\n",
    "    \n",
    "    try:\n",
    "        X_ai.append(ai.loc[y_3[i]])\n",
    "    except:\n",
    "        s+=1\n",
    "        remove.append(y_3[i])\n",
    "for i in range(len(remove)):\n",
    "    y_3.remove(remove[i])\n",
    "X_ai = np.asarray(X_ai)\n",
    "\n",
    "labels_ai = []\n",
    "# audios.set_index(\"Filename\", inplace=True)\n",
    "for i in range(len(y_3)):\n",
    "    labels_ai.append(audios.loc[y_3[i], \"cover\"])\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ai, labels_ai, test_size=0.2,random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy_ai = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "f1_score_ai = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "recall_ai = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy_ai)\n",
    "print(\"f1:\", f1_score_ai)\n",
    "print(\"recall\", recall_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc2d1e",
   "metadata": {},
   "source": [
    "### Autoencoders Features and Labels using independent segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64533d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# audios.set_index(\"Filename\", inplace=True)\n",
    "labels_ae = []\n",
    "for i in range(len(y_4)):\n",
    "    labels_ae.append(audios.loc[y_4[i], \"cover\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_3, labels_ae, test_size=0.2,random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda32a30",
   "metadata": {},
   "source": [
    "### Autoencoders Features and Labels using 5 segments of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e27e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = X_3\n",
    "y_c = y_4\n",
    "\n",
    "X_batch = np.reshape(X_c, (X_c.shape[0]//5,5,X_c.shape[1]))\n",
    "y_path = np.reshape(y_c, (y_c.shape[0]//5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_batch, y_path, test_size=0.2,random_state=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0]*X_test.shape[1], X_test.shape[2])\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_train = y_train.reshape(y_train.shape[0]*y_train.shape[1])\n",
    "y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
    "\n",
    "labels_train = []\n",
    "for i in range(len(y_train)):\n",
    "    labels_train.append(audios.loc[y_train[i], \"cover\"])\n",
    "labels_test = []\n",
    "for i in range(len(y_test)):\n",
    "    labels_test.append(audios.loc[y_test[i], \"cover\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37b9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, labels_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(labels_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b62a25",
   "metadata": {},
   "source": [
    "# Autoencoders Features and Labels using voting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf2 = np.asarray(y_pred_rf)\n",
    "y_pred_rf2 = np.reshape(y_pred_rf2,(y_pred_rf2.shape[0]//5,5))\n",
    "y_test2 = np.asarray(labels_test)\n",
    "y_test2 = np.reshape(y_test2,(y_test2.shape[0]//5,5))\n",
    "\n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "labels_test2 = []\n",
    "labels_pred = []\n",
    "for i in range(len(y_pred_rf2)):\n",
    "    labels_pred.append(most_frequent(list(y_pred_rf2[i])))\n",
    "    labels_test2.append(most_frequent(list(y_test2[i])))\n",
    "accuracy_ae = metrics.accuracy_score(labels_test2, labels_pred)\n",
    "f1_score_ae = metrics.f1_score(labels_test2, labels_pred, average=\"macro\")\n",
    "recall_ae = metrics.recall_score(labels_test2, labels_pred, average=\"macro\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_ae)\n",
    "print(\"f1:\", f1_score_ae)\n",
    "print(\"recall\", recall_ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7020650",
   "metadata": {},
   "source": [
    "# Autoencoders Features and Labels using mean of segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31817518",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_New = np.load(f\"temporal_zamuro/Features/X_ae_norm_new.npy\")\n",
    "y_New = np.load(f\"temporal_zamuro/Features/y_ae_norm_new.npy\")\n",
    "labels_aenew = audios.loc[y_New]\n",
    "labels_aenew = list(labels_aenew[\"cover\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_B =np.asarray(X_2)\n",
    "X_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_New = np.mean(X_B, axis=1)\n",
    "# X_New = X_New[0:len(y_3)]\n",
    "# y_New = y_New[0:len(y_3)]\n",
    "\n",
    "X_New.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb7c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_New, labels_aenew, test_size=0.2,random_state=0)\n",
    "clf_rf = RandomForestClassifier(max_depth=32, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = [f1_score_ai, f1_score_ae, f1_score_vggish] # [ai, AE_norm, AE_PCA, AE_UMAP, VGGISH, VGGISH_PCA, VGGISH_UMAP]\n",
    "accuracy_scores = [accuracy_ai, accuracy_ae, accuracy_vggish]\n",
    "recall_scores = [recall_ai, recall_ae, recall_vggish]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34847a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for F1 scores, recall, and accuracy\n",
    "methods = [\"Acoustic\\nIndices\", \"AE Normalized\", \"vggish\"]\n",
    "\n",
    "# Create an array for the x-axis positions\n",
    "x = np.arange(len(methods))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(11, 6))\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Define professional color palettes\n",
    "f1_color = 'steelblue'  # You can adjust the color as needed\n",
    "recall_color = 'indianred'  # You can adjust the color as needed\n",
    "accuracy_color = 'orange'  # You can adjust the color as needed\n",
    "\n",
    "# Create the bar chart for F1 scores\n",
    "bars_f1 = plt.bar(x - bar_width, f1_scores, bar_width, label='F1 Score', color=f1_color)\n",
    "\n",
    "# Create the bar chart for recall\n",
    "bars_recall = plt.bar(x, recall_scores, bar_width, label='Recall', color=recall_color)\n",
    "\n",
    "# Create the bar chart for accuracy\n",
    "bars_accuracy = plt.bar(x + bar_width, accuracy_scores, bar_width, label='Accuracy', color=accuracy_color)\n",
    "\n",
    "# Set the y-axis limits\n",
    "plt.ylim(0.5, 1)\n",
    "\n",
    "# Set the x-axis labels and their positions\n",
    "plt.xticks(x, methods, fontsize=14)  # Increase label size\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Set the title\n",
    "# plt.title('F1 Score, Recall, and Accuracy Comparison')\n",
    "\n",
    "# Set the legend with increased size\n",
    "plt.legend(fontsize=14)  # Increase legend size\n",
    "\n",
    "# Add values on top of the bars\n",
    "for bar, value in zip(bars_f1, f1_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height()+0.01, f'{value:.3f}', ha='center', va='bottom', fontsize=11, rotation=90)\n",
    "\n",
    "for bar, value in zip(bars_recall, recall_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height()+0.01, f'{value:.3f}', ha='center', va='bottom', fontsize=11, rotation=90)\n",
    "\n",
    "for bar, value in zip(bars_accuracy, accuracy_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height()+0.01, f'{value:.3f}', ha='center', va='bottom', fontsize=11, rotation=90)\n",
    "\n",
    "# Add a legend\n",
    "# plt.legend()\n",
    "\n",
    "# Display the figure\n",
    "\n",
    "# plt.savefig(f\"{root}/Zamuro/temporal_zamuro/zamuro_classification_results/zamuro_classification.pdf\", format=\"pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
