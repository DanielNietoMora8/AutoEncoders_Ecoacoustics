{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"In9UTndxqdMe"},"outputs":[],"source":["if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    from google.colab import drive, output\n","    drive.mount('/content/drive')\n","    import sys\n","    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n","    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n","    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n","    %load_ext autoreload\n","    %autoreload 1\n","    !pip install torchaudio\n","    !pip install umap\n","    !pip install wandb --upgrade\n","    !wandb login\n","    output.clear()\n","\n","else:\n","    print('Not running on CoLab')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JABwOJv4qVAS"},"outputs":[],"source":["# from __future__ import print_function\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# import IPython\n","\n","from six.moves import xrange\n","\n","import umap\n","import datetime\n","import gc\n","\n","from scipy import signal\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import torchaudio.transforms as audio_transform\n","\n","#from ResidualStack import ResidualStack\n","#from Residual import Residual\n","\n","from Jaguas_DataLoader import SoundscapeData\n","from Models import Model\n","from Models import Encoder\n","from Models import Decoder\n","from Models import VectorQuantizer\n","from Models import VectorQuantizerEMA\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = xm.xla_device()\n","\n","from datetime import timedelta\n","import wandb\n","from wandb import AlertLevel\n","\n","torch.cuda.empty_cache()\n","gc.collect()\n","torch.cuda.empty_cache()\n"]},{"cell_type":"markdown","metadata":{"id":"QxU_YNsDqVAZ"},"source":["## Train\n","\n","We use the hyperparameters from the author's code."]},{"cell_type":"code","source":["from scipy.io.wavfile import write\n","\n","class TestModel:\n","\n","    def __init__(self, model, iterator, num_views):\n","        self._model = model\n","        self._iterator = iterator\n","        self.num_views = num_views\n","\n","    def plot_waveform(self, waveform, n_rows=2, directory=None):\n","        fig, axs = plt.subplots(n_rows, figsize=(10, 6))\n","        for i in range(len(waveform)):\n","            axs[i].plot(waveform[i,0])\n","            if directory != None:\n","                scaled = np.int16(waveform[i,0]/np.max(np.abs(waveform[i,0])) * 32767)\n","                write(directory + str(i) + '.wav', 22050, scaled)\n","        plt.show()\n","        \n","        \n","    def waveform_generator(self, spec, n_fft=1028, win_length=1028, base_win=256, plot=False):\n","        spec = spec.cdouble()\n","        spec = spec.to(\"cpu\")\n","        hop_length = int(np.round(base_win/win_length * 172.3))\n","        transformation = audio_transform.InverseSpectrogram(n_fft=n_fft, win_length=win_length)\n","        waveform = transformation(spec)\n","        waveform = waveform.cpu().detach().numpy()\n","        return waveform\n","    \n","    def plot_psd(self, waveform):\n","        for wave in waveform:\n","            plt.psd(wave)\n","\n","    def plot_reconstructions(self, imgs_original, imgs_reconstruction, num_views:int = 8):\n","        output = torch.cat((imgs_original[0:self.num_views], imgs_reconstruction[0:self.num_views]), 0)\n","        img_grid = make_grid(output, nrow=self.num_views, pad_value=20)\n","        fig, ax = plt.subplots(figsize=(20,5))\n","        ax.imshow(img_grid[1,:,:].cpu(), vmin=0, vmax=1)\n","        ax.axis(\"off\")\n","        plt.show()\n","        return fig\n","\n","    def reconstruct(self):\n","        self._model.eval()\n","        (valid_originals, _,_) = next(self._iterator)\n","        valid_originals = torch.reshape(valid_originals, (valid_originals.shape[0] * valid_originals.shape[1], \n","                                                    valid_originals.shape[2], valid_originals.shape[3]))\n","        valid_originals = torch.unsqueeze(valid_originals,1)\n","\n","        valid_originals = valid_originals.to(device)\n","\n","        vq_output_eval = self._model._pre_vq_conv(self._model._encoder(valid_originals))\n","        _, valid_quantize, _, _ = self._model._vq_vae(vq_output_eval)\n","        valid_reconstructions = self._model._decoder(valid_quantize)\n","\n","        recon_error = F.mse_loss(valid_originals, valid_reconstructions)\n","\n","        return valid_originals, valid_reconstructions, recon_error\n","\n","    def run(self, plot=True, wave_return=True, wave_plot=True, directory=None):\n","        wave_original = []\n","        wave_reconstructions = []\n","        originals, reconstructions, error = self.reconstruct() \n","        if plot:\n","            self.plot_reconstructions(originals, reconstructions)\n","        if wave_return:\n","            wave_original = self.waveform_generator(originals)\n","            wave_reconstructions = self.waveform_generator(reconstructions)\n","            if wave_plot:\n","                self.plot_waveform(wave_original, len(wave_original), directory=\"originals\")\n","                self.plot_waveform(wave_reconstructions, len(wave_reconstructions), directory=\"reconstructions\")\n","\n","        return originals, reconstructions, wave_original, wave_reconstructions, error\n","\n","\n","class TrainModel:\n","\n","    def __init__(self, model):\n","        self._model = model\n","\n","    def wandb_init(self, config, keys=[\"audio_length\", \"win_length\", \"batch_size\"]):\n","        try:\n","            run_name = \"VQ_\"\n","            for key in keys:\n","                if key in config.keys():\n","                    run_name = run_name + key + \":\" + str(config[key]) + \"_\"\n","                else:\n","                    run_name = run_name + str(key)\n","\n","            wandb.login()\n","            wandb.finish()\n","            wandb.init(project=\"VQ-VAE-Jaguas\", config=config)\n","            wandb.run.name = run_name\n","            wandb.run.save()\n","            wandb.watch(self._model, F.mse_loss, log=\"all\", log_freq=1)\n","            is_wandb_enable = True         \n","        except Exception as e:\n","            print(e)\n","            is_wandb_enable = False\n","\n","        return is_wandb_enable, run_name\n","\n","    def wandb_logging(self, dict, step=0):\n","        for keys in dict:\n","            wandb.log({keys: dict[keys]}, step=step)\n","\n","\n","    def fordward(self, training_loader, test_loader, config):\n","        iterator = iter(test_loader)\n","        wandb_enable, run_name = self.wandb_init(config)\n","        optimizer = config[\"optimizer\"]\n","        scheduler = config[\"scheduler\"]\n","\n","        train_res_recon_error = []\n","        train_res_perplexity = []\n","        logs = []\n","        best_loss = 10000\n","\n","        for epoch in range(config[\"num_epochs\"]):\n","            iterator_train = iter(training_loader)\n","            for i in xrange(config[\"num_training_updates\"]):\n","                self._model.train()\n","                try:\n","                    (data, _,_) = next(iterator_train)\n","                except Exception as e:\n","                    print(\"error\")\n","                    print(e)\n","                    logs.append(e)\n","                    continue\n","\n","                data = torch.reshape(data, (data.shape[0] * data.shape[1], data.shape[2], data.shape[3]))\n","                data = torch.unsqueeze(data,1)\n","                data = data.to(device)\n","                # print(data.shape)\n","\n","                optimizer.zero_grad()\n","                vq_loss, data_recon, perplexity = self._model(data)\n","                # print(data_recon.shape)\n","                \n","                recon_error = F.mse_loss(data_recon, data) #/ data_variance\n","                loss = recon_error + vq_loss\n","                loss.backward()\n","\n","                optimizer.step()\n","                print(f'epoch: {epoch+1} of {config[\"num_epochs\"]} \\t iteration: {(i+1)} of {config[\"num_training_updates\"]} \\t loss: {np.round(loss.item(),4)} \\t recon_error: {np.round(recon_error.item(),4)} \\t vq_loss: {np.round(vq_loss.item(),4)}')\n","                dict = {\"loss\":loss.item(),\n","                        \"perplexity\":perplexity.item(),\n","                        \"recon_error\": recon_error,\n","                        \"vq_loss\": vq_loss}\n","                step = epoch*config[\"num_training_updates\"] + i\n","                self.wandb_logging(dict, step=step)\n","                                   \n","                if (i+1) % 20 == 0:\n","                    try:\n","                        test_ = TestModel(self._model, iterator, 8)\n","                        #torch.save(model.state_dict(),f'model_{epoch}_{i}.pkl')\n","                        originals, reconstructions, test_error = test_.reconstruct()\n","                        fig = test_.plot_reconstructions(originals, reconstructions, 8)\n","                        images = wandb.Image(fig, caption= f\"recon_error: {np.round(test_error.item(),4)}\")\n","                        self.wandb_logging({\"examples\": images}, step=i)\n","                        \n","                    except Exception as e:\n","                        print(\"error\")\n","                        logs.append(e)\n","                        continue\n","                else:\n","                    pass\n","\n","                if recon_error < 20:\n","                    wandb.alert(\n","                    title='High accuracy',\n","                    text=f'Recon error {recon_error} is lower than 0.5',\n","                    level=AlertLevel.WARN,\n","                    wait_duration=timedelta(minutes=5)\n","                                )\n","                    _time = datetime.datetime.now()       \n","                    torch.save(self._model.state_dict(),f'{run_name}_low_error.pkl')\n","                else:\n","                    pass\n","\n","            scheduler.step()\n","            torch.cuda.empty_cache()\n","            time = datetime.datetime.now()\n","            torch.save(self._model.state_dict(),f'{time.hour}_{time.minute}_{run_name}_{epoch}.pkl')\n","            output.clear()\n","            print(optimizer.state_dict()[\"param_groups\"][0][\"lr\"])\n","\n","        wandb.finish()\n","        return self._model, logs, run_name\n","\n","                \n","\n","\n"],"metadata":{"id":"kxoZkEI0-qvh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9UACcjeqVAZ"},"outputs":[],"source":["root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Jaguas_2018'\n","\n","config = {\n","    \"project\" : \"VQ-VAE-Jaguas\",\n","    \"batch_size\" : 14,\n","    \"num_epochs\": 6,\n","    \"num_hiddens\" : 128,\n","    \"embedding_dim\" : 8,\n","    \"num_embeddings\" : 512,\n","    \"commitment_cost\" : 0.25,\n","    \"decay\" : 0.99,\n","    \"learning_rate\" : 1e-2,\n","    \"dataset\": \"Audios Jaguas\",\n","    \"architecture\": \"VQ-VAE\",\n","}\n","\n","model = Model(config[\"num_hiddens\"],\n","              config[\"num_embeddings\"], config[\"embedding_dim\"], \n","              config[\"commitment_cost\"], config[\"decay\"]).to(device)\n","\n","dataset = SoundscapeData(root_path, audio_length=12, ext=\"wav\", win_length=1028)\n","dataset_train, dataset_test = random_split(dataset,\n","                                           [round(len(dataset)*0.2), len(dataset) - round(len(dataset)*0.2)], \n","                                           generator=torch.Generator().manual_seed(1024))\n","\n","training_loader = DataLoader(dataset_train, batch_size=config[\"batch_size\"], shuffle = True)\n","test_loader = DataLoader(dataset_test, batch_size=config[\"batch_size\"])\n","\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], amsgrad=False)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size = 2, gamma = 0.1 )\n","\n","config[\"optimizer\"] = optimizer\n","config[\"scheduler\"] = scheduler\n","config[\"audio_length\"] = dataset.audio_length\n","config[\"num_training_updates\"] = len(training_loader)\n","config[\"win_length\"] = dataset.win_length\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jInS0IjTqVAa"},"outputs":[],"source":["Training = TrainModel(model)\n","time = datetime.datetime.now()\n","model, logs, run_name = Training.fordward(training_loader, test_loader, config)\n","torch.save(model.state_dict(),f'{time.hour}_{time.minute}_{run_name}.pkl')\n","#np.savetxt(\"corrupted_files.csv\", logs, delimiter=\",\")\n","\n","torch.cuda.memory_summary(device=None, abbreviated=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IL0WeGtiVSha"},"outputs":[],"source":["# wandb.finish()\n","model.load_state_dict(torch.load(f'Models/Best_Model_Embedding_256_VQ_audio_length 12_win_length 1028_batch_size 8__5.pkl', map_location=torch.device('cpu')))"]},{"cell_type":"code","source":[""],"metadata":{"id":"qtGXSygxVv0R"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7_id8rZguQ7g"},"outputs":[],"source":["root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Porce_2019'\n","\n","\n","dataset = SoundscapeData(root_path=root_path, audio_length=12, ext='WAV', win_length=config[\"win_length\"])\n","dataset_train, dataset_test = random_split(dataset,\n","                                          [round(len(dataset)*0.10), len(dataset) - round(len(dataset)*0.10)], \n","                                           generator=torch.Generator().manual_seed(1024))\n","\n","training_loader = DataLoader(dataset_train, batch_size=config[\"batch_size\"], shuffle = False)\n","test_loader = DataLoader(dataset_test, batch_size=config[\"batch_size\"])\n","iterator = iter(test_loader)"]},{"cell_type":"code","source":["spec, record, _ = next(iter(test_loader))"],"metadata":{"id":"8POCP5-vLY_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spec_2 = audio_transform.Spectrogram(n_fft=1028, win_length=1028, window_fn=torch.hamming_window,power=2)(record)"],"metadata":{"id":"zx3veUvuULAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = reconstruction.permute(1,0,2,3)\n","b = a.squeeze(dim=0)\n","b.shape"],"metadata":{"id":"jiqdVEpbmRSj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["b = b.type(torch.complex64).to(\"cpu\")\n","wav = audio_transform.InverseSpectrogram(n_fft=1028, win_length=1028, hop_length=514)(b)"],"metadata":{"id":"aJKTdxXUmxgC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Test = TestModel(model, iterator, 8)\n","originals, reconstruction, wav_ori, wav_recons, error = Test.run(wave_plot=True)\n","a = Test.waveform_generator(originals)\n","b = Test.waveform_generator(reconstruction)\n","waves = [a,b]\n","Test.plot_psd(waves)"],"metadata":{"id":"9T4SbzcU214s"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6EH9JEPaU_V"},"outputs":[],"source":["import torchaudio.transforms as audio_transform\n","reconstruction = reconstruction.cdouble()\n","reconstruction = reconstruction.to(\"cpu\")\n","originals = originals.cdouble()\n","originals = originals.to(\"cpu\")\n","transformation = audio_transform.InverseSpectrogram(n_fft=1025, win_length = 1025)\n","waveform = transformation(reconstruction)\n","waveform_original = transformation(originals)\n","waveform = waveform.cpu().detach().numpy()\n","waveform_original = waveform_original.cpu().detach().numpy()"]},{"cell_type":"code","source":["diff = waveform[0] - waveform_original[0]\n","diff = diff**2\n","plt.psd(waveform_original)\n","plt.psd(waveform)\n","#plt.psd(diff[0])\n","plt.show()"],"metadata":{"id":"EF1EaIJINt6J"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"vq_vae_jp_clustering_wandb.ipynb","provenance":[{"file_id":"1wMLc0TeGV62ac_9fyr69EM2ODYm3ygO4","timestamp":1656687641496}],"private_outputs":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}