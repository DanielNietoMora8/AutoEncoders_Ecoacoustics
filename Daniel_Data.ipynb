{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    # !wandb login\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5Jo5E4cmabyk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "from scipy.spatial import distance\n",
    "from numpy import linalg as LA\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lumrCsRYbMvs"
   },
   "outputs": [],
   "source": [
    "def uncertainity_mean(X_train1,pred,means,covariances,weights,km,numberofdimens):\n",
    "    X_train1[\"pred\"]=pred\n",
    "    meanss=means\n",
    "    weiths=weights\n",
    "    variances=[]\n",
    "    covariancematrix=covariances\n",
    "    for i in covariancematrix: #The diagonal of cov is the variance of each gmm\n",
    "        diag=np.diag(i)\n",
    "        variances.append(diag)\n",
    "    variances=np.array(variances)\n",
    "    countiterations=0\n",
    "    unc=[]\n",
    "    un=[]\n",
    "\n",
    "    sep=[]\n",
    "    for g in range(0,len(meanss)):    ##Frechet distance\n",
    "        for t in range(0,len(meanss)):\n",
    "            if (t==g):\n",
    "                continue\n",
    "            else:\n",
    "                sep.append(frechetDistance(meanss[t],meanss[g],covariancematrix[t],covariancematrix[g]))\n",
    "    separation=np.array(sep)\n",
    "    Dmin=np.array(separation).min()\n",
    "    Dmax=np.array(separation).max()\n",
    "    Sep=(Dmax/Dmin)*(1/separation.sum())\n",
    "\n",
    "    for i in range(0,len(meanss)):    #Uncertainty    ##i run each cluster\n",
    "        cweight=weiths[i]\n",
    "        cmean=meanss[i]\n",
    "        cvar=variances[i]\n",
    "        lim_inf=cmean-(km*cvar)\n",
    "        lim_sup=cmean+(km*cvar)\n",
    "        unc=[]\n",
    "        o=X_train1[X_train1[\"pred\"]==i].iloc[:,:numberofdimens].copy()\n",
    "\n",
    "        for j in range(len(o)): # j run each data\n",
    "            DM=distance.mahalanobis(np.array(o.iloc[j]), cmean, np.linalg.inv(covariancematrix[i]))\n",
    "            varbool=(DM>=km)\n",
    "            varunc=[]\n",
    "            #print(\"varbool\",varbool)\n",
    "            if (varbool):\n",
    "                varunc.append(2*km*DM)\n",
    "            else:\n",
    "                vs=((DM**2)+(km*DM)+(km**2)/2)\n",
    "                varunc.append(vs)\n",
    "        un.append(np.array(varunc))\n",
    "    return np.sum(un)/Sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "q5CMBV6pUcIo"
   },
   "outputs": [],
   "source": [
    "def merguncertain (xtrain,y,Means,covariances,weights,numberofdimens):\n",
    "    X_train11=xtrain\n",
    "    X_train11[\"pred\"]=y\n",
    "    UNIndex=[]\n",
    "    len(Means)\n",
    "    Pairwise=np.ones((len(Means), len(Means)))\n",
    "    labels=[]\n",
    "    for i in range(len(Means)):\n",
    "        labels.append(i)\n",
    "        for j in range(len(Means)):\n",
    "                if (i==j):\n",
    "                    continue\n",
    "                Pairwise[j,i]=(frechetDistance(Means[i],Means[j],covariances[i],covariances[j]))\n",
    "\n",
    "    while len(Pairwise) > 2 :\n",
    "            UNIndex.append(uncertainity_mean(X_train11.iloc[:,:numberofdimens],X_train11[\"pred\"],Means,covariances,weights,1,numberofdimens))\n",
    "\n",
    "            Similar_clusters=np.unravel_index(Pairwise.argmin(),Pairwise.shape)\n",
    "            Similar_clusters_labels=( labels[Similar_clusters[0]],labels[Similar_clusters[1]])\n",
    "\n",
    "            #update Mean\n",
    "            data_size_1=len(X_train11[X_train11[\"pred\"]==Similar_clusters_labels[0]])\n",
    "            data_size_2=len(X_train11[X_train11[\"pred\"]==Similar_clusters_labels[1]])\n",
    "            mean_1=Means[Similar_clusters[0]]\n",
    "            mean_2=Means[Similar_clusters[1]]\n",
    "            new_mean = (data_size_1* mean_1 + data_size_2*mean_2)/(data_size_1 + data_size_2)\n",
    "            Means[Similar_clusters[0]]=new_mean\n",
    "\n",
    "            #Update labels\n",
    "            X_train11[\"pred\"]=X_train11[\"pred\"].replace(Similar_clusters_labels[1], Similar_clusters_labels[0])\n",
    "            #print(X_train11[\"pred\"].unique())\n",
    "            NewCovariance=X_train11[X_train11[\"pred\"]==Similar_clusters_labels[0]].iloc[:,:numberofdimens].cov()\n",
    "            covariances[Similar_clusters[0]]=NewCovariance\n",
    "            weights[Similar_clusters[0]]=weights[Similar_clusters[0]]+weights[Similar_clusters[1]]\n",
    "\n",
    "            updpairwisecolum=[]\n",
    "            for j in range(0,len(Means)):\n",
    "                    updpairwisecolum.append((frechetDistance(Means[Similar_clusters[0]],Means[j],covariances[Similar_clusters[0]],covariances[j])))\n",
    "            #print(updpairwisecolum)\n",
    "            Pairwise[:,Similar_clusters[0]]=updpairwisecolum\n",
    "            Pairwise[Similar_clusters[0],:]=updpairwisecolum\n",
    "\n",
    "            Means= np.delete(Means, (Similar_clusters[1]), axis=0)\n",
    "            weights= np.delete(weights, (Similar_clusters[1]), axis=0)\n",
    "            covariances=np.delete(covariances, (Similar_clusters[1]), axis=0)\n",
    "            labels.remove(Similar_clusters_labels[1])\n",
    "            Pairwise= np.delete(Pairwise, (Similar_clusters[1]), axis=0)\n",
    "            Pairwise= np.delete(Pairwise, (Similar_clusters[1]), axis=1)\n",
    "            np.fill_diagonal(Pairwise, 1)\n",
    "    return UNIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F7SrKoKiyvkP"
   },
   "outputs": [],
   "source": [
    "def frechetDistance(u1,u2,E1,E2):\n",
    "    return (LA.norm(np.absolute(u1-u2)**2))+np.trace(E1+E2-(2*(E1*E2)**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = torch.load(f'{root}/Jaguas/temporal/Features/AE_No_rain_98/AE_features_day_11_hour_21_No_rain_Audios_Jaguas.pth', map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KmM3oDe6UhOt"
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 128: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mroot\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Jaguas/temporal/Features/AE_No_rain_98/AE_features_day_11_hour_21_No_rain_Audios_Jaguas.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:547\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:636\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1965\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 128: invalid start byte"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(f'{root}/Jaguas/temporal/Features/AE_No_rain_98/AE_features_day_11_hour_21_No_rain_Audios_Jaguas.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfJfcKP7UhRG"
   },
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeXg56ASq5pa"
   },
   "source": [
    "## Approach 1: Calculating performance in base of index UF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ms37QYslqC2n"
   },
   "outputs": [],
   "source": [
    "Index=[]\n",
    "liminfierior=2\n",
    "limsuperior=20\n",
    "for i in range(2,20):\n",
    "\n",
    "    X_train111=df.copy()\n",
    "    GM = GaussianMixture(n_components=i, covariance_type=\"full\",random_state=1).fit(X_train111)\n",
    "    X_train111[\"pred\"]=GM.predict(X_train111)\n",
    "    Means=GM.means_\n",
    "    covariances=GM.covariances_\n",
    "    weights=GM.weights_\n",
    "    numberofdimens=X_train111.shape[1]-1\n",
    "    y=X_train111[\"pred\"]\n",
    "    Index.append(uncertainity_mean(X_train111.iloc[:,:numberofdimens],X_train111[\"pred\"],Means,covariances,weights,1,numberofdimens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "z6G-8oV0q4Vd",
    "outputId": "9f060f85-a211-48cd-9ee3-debb9f18a8a2"
   },
   "outputs": [],
   "source": [
    "change=pd.DataFrame(Index,columns=[\"UFindex\"])\n",
    "change[\"ind\"]=np.linspace(2,len(change)+2,len(change))\n",
    "\n",
    "change.plot(\"ind\",[\"UFindex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Y7mEwGRnn-Y",
    "outputId": "d0d40edd-5db5-4d84-ed1d-859dc4ad2c0e"
   },
   "outputs": [],
   "source": [
    "change[\"UFindex\"].argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-y4yVx4dkrQ"
   },
   "source": [
    "## Approach 2: Meging methodology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "IEFl9INY5OU6",
    "outputId": "a166a1bb-5236-4c6b-bdd8-c96955f7375a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df\n",
    "X_train111=df.copy()\n",
    "GM = GaussianMixture(n_components=20, covariance_type=\"full\", random_state=2).fit(X_train111)\n",
    "X_train111[\"pred\"]=GM.predict(X_train111)\n",
    "Means=GM.means_\n",
    "covariances=GM.covariances_\n",
    "weights=GM.weights_\n",
    "y=X_train111[\"pred\"]\n",
    "index=merguncertain (X,y,Means,covariances,weights,X.shape[1])\n",
    "index.reverse()\n",
    "change=pd.DataFrame(index,columns=[\"a\"])\n",
    "change[\"ind\"]=np.linspace(0,len(change),len(change))\n",
    "\n",
    "change.plot(\"ind\",[\"a\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggCZKnZcDt71"
   },
   "outputs": [],
   "source": [
    "\n",
    "change=change.iloc[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0tmChDa-9gH",
    "outputId": "16fc5166-d4f9-4614-ca31-96a2b331b8e4"
   },
   "outputs": [],
   "source": [
    "\n",
    "recomended=change[\"a\"].argmin()+2\n",
    "GMM_test= GaussianMixture(n_components=recomended, covariance_type=\"full\",random_state=0).fit(X)\n",
    "predy=GMM_test.predict(X)\n",
    "recomended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUW99_1oQucl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df=pd.read_csv('/content/drive/MyDrive/Doctorado/2023/Agosto/Daniel Nieto/X_PCA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "rrHTT_58fk97",
    "outputId": "bade3366-ff02-4f62-827f-23f5e8dcc8da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.8023357, 2.850008 , 2.9287684, ..., 0.       , 1.3797376,\n",
       "        2.0243452],\n",
       "       [2.651719 , 2.6033316, 2.5175917, ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [2.9937844, 2.8752031, 2.693827 , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [1.8581482, 1.7233287, 0.2887252, ..., 3.987761 , 3.9876847,\n",
       "        3.9883995],\n",
       "       [1.4634185, 1.654854 , 1.2146444, ..., 3.995119 , 3.9517536,\n",
       "        3.9799807],\n",
       "       [1.5723217, 0.       , 1.4459665, ..., 3.9850056, 3.993206 ,\n",
       "        3.9871602]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6CsrxeCQucl"
   },
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d7V7HYvQucm"
   },
   "source": [
    "## Approach 1: Calculating performance in base of index UF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KqydUu55Qucm"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m X_train111\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      7\u001b[0m GM \u001b[38;5;241m=\u001b[39m GaussianMixture(n_components\u001b[38;5;241m=\u001b[39mi, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X_train111)\n\u001b[0;32m----> 8\u001b[0m X_train111[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39mGM\u001b[38;5;241m.\u001b[39mpredict(X_train111)\n\u001b[1;32m      9\u001b[0m Means\u001b[38;5;241m=\u001b[39mGM\u001b[38;5;241m.\u001b[39mmeans_\n\u001b[1;32m     10\u001b[0m covariances\u001b[38;5;241m=\u001b[39mGM\u001b[38;5;241m.\u001b[39mcovariances_\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "Index=[]\n",
    "liminfierior=2\n",
    "limsuperior=20\n",
    "for i in range(2,20):\n",
    "\n",
    "    X_train111=df.numpy().copy()\n",
    "    GM = GaussianMixture(n_components=i, covariance_type=\"full\",random_state=1).fit(X_train111)\n",
    "    X_train111[\"pred\"]=GM.predict(X_train111)\n",
    "    Means=GM.means_\n",
    "    covariances=GM.covariances_\n",
    "    weights=GM.weights_\n",
    "    numberofdimens=X_train111.shape[1]-1\n",
    "    y=X_train111[\"pred\"]\n",
    "    Index.append(uncertainity_mean(X_train111.iloc[:,:numberofdimens],X_train111[\"pred\"],Means,covariances,weights,1,numberofdimens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "_uQmyJEiQucm",
    "outputId": "5253a288-0b2d-429a-f1fa-28f1f376bc4b"
   },
   "outputs": [],
   "source": [
    "change=pd.DataFrame(Index,columns=[\"UFindex\"])\n",
    "change[\"ind\"]=np.linspace(2,len(change)+2,len(change))\n",
    "\n",
    "change.plot(\"ind\",[\"UFindex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjM66A5WQucn",
    "outputId": "6ea69e08-65d9-4f4a-dcdc-1641522d9c39"
   },
   "outputs": [],
   "source": [
    "change[\"UFindex\"].argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCPX1F0gQucn"
   },
   "source": [
    "## Approach 2: Meging methodology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63nCam9JQucn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=df\n",
    "X_train111=df.numpy().copy()\n",
    "GM = GaussianMixture(n_components=20, covariance_type=\"full\", random_state=2).fit(X_train111)\n",
    "X_train111[\"pred\"]=GM.predict(X_train111)\n",
    "Means=GM.means_\n",
    "covariances=GM.covariances_\n",
    "weights=GM.weights_\n",
    "y=X_train111[\"pred\"]\n",
    "index=merguncertain (X,y,Means,covariances,weights,X.shape[1])\n",
    "\n",
    "index.reverse()\n",
    "change=pd.DataFrame(index,columns=[\"a\"])\n",
    "change[\"ind\"]=np.linspace(0,len(change),len(change))\n",
    "\n",
    "change.plot(\"ind\",[\"a\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "qpzgh0tTHaHQ",
    "outputId": "938d8432-8190-4d62-f9ba-8268b63ec8ec"
   },
   "outputs": [],
   "source": [
    "change.plot(\"ind\",[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePOmQq7GQucn"
   },
   "outputs": [],
   "source": [
    "\n",
    "change=change.iloc[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVYrb9NlQuco",
    "outputId": "ad057da3-df6c-428f-cca0-23bffa6e3e55"
   },
   "outputs": [],
   "source": [
    "\n",
    "recomended=change[\"a\"].argmin()+2\n",
    "GMM_test= GaussianMixture(n_components=recomended, covariance_type=\"full\",random_state=0).fit(X)\n",
    "predy=GMM_test.predict(X)\n",
    "recomended"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
