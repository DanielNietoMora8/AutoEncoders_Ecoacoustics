{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36603,
     "status": "ok",
     "timestamp": 1678389399232,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "KwQ8Zp3llyi-",
    "is_executing": true,
    "outputId": "fd97b0c2-58fc-4afe-b939-c9890c909c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    !pip install umap-learn\n",
    "    !pip install umap-learn[plot]\n",
    "    !pip install holoviews\n",
    "\n",
    "    !pip install joypy\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n",
    "    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Results')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Figures')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Result')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics/Jaguas\"\n",
    "    root_path = \"media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3008,
     "status": "ok",
     "timestamp": 1678389402237,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ZeYXtNUUhRWh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from Jaguas_DataLoader_rainless import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "import random\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cMG_87FKb26h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84820, 5184)\n"
     ]
    }
   ],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 11\n",
    "hour = 21\n",
    "month = 6\n",
    "folder = \"AE_No_rain_98\"\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "\n",
    "# model_name = f\"{root}/temporal/models/model_{model_type}_{identifier}_{date_format}_final.pth\"\n",
    "# config = torch.load(f'temporal/configs/config_{model_type}_{identifier}_{date_format}.pth', map_location=torch.device('cpu'))\n",
    "# model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n",
    "# model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))\n",
    "\n",
    "# y = torch.load(f\"temporal/Features/{folder}/AE_labels_{date_format}_No_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "X = torch.load(f\"temporal/Features/{folder}/AE_features_{date_format}_No_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "X = np.asarray(X)\n",
    "y_path = torch.load(f\"temporal/Features/{folder}/AE_test_path_samples_{date_format}_No_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "path_flat = [item for sublist in y_path for item in sublist]\n",
    "path_flat = np.asarray(path_flat)\n",
    "print(X.shape)\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "# Normalizer_ = Normalizer().fit(X)\n",
    "# X_norm = Normalizer_.transform(X)\n",
    "# PCA_ = PCA(n_components=60).fit(X_norm)\n",
    "# X_PCA = PCA_.transform(X_norm)\n",
    "# # X_TSNE = TSNE(n_components=60, learning_rate=\"auto\", init='random', random_state=0).fit_transform(X_PCA)\n",
    "# reducer = umap.UMAP(min_dist=0.9, n_components=60)\n",
    "# X_UMAP = reducer.fit_transform(X_norm)\n",
    "# X_batch = np.reshape(X_UMAP, (X_UMAP.shape[0]//5,5,X_UMAP.shape[1]))\n",
    "# # X_UMAP_Norm = Normalizer().fit_transform(X_UMAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_audios = f\"{root}/Complementary_Files/Audios_Jaguas/Audios_Jaguas.csv\"\n",
    "root_recorders = f\"{root}/Complementary_Files/df_grabadoras_reg.csv\"\n",
    "root_clusters = f\"{root}/temporal/clusters\"\n",
    "root_ai = f\"{root}/Complementary_Files/Acoustic_Indices/AI_Jaguas.csv\"\n",
    "root_vggish = f\"{root}/vggish/Features_vggish\"\n",
    "ecological_integrity = f\"{root}/Complementary_Files/Indice_Integridad_Ecologica.xlsx\"\n",
    "\n",
    "audios = pd.read_csv(root_audios, index_col=0)\n",
    "recorders = pd.read_csv(root_recorders, sep=\";\")\n",
    "ei  = pd.read_excel(ecological_integrity)\n",
    "ai = pd.read_csv(root_ai)\n",
    "ai.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "ai.drop(columns=[\"Date\"], inplace=True)\n",
    "ai.dropna(inplace=True)\n",
    "\n",
    "ai.set_index(\"file\",inplace=True, drop=True)\n",
    "audios.set_index(\"Filename\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGISH Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vgg = torch.load(f\"{root_vggish}/vggish_features.pth\")\n",
    "y_vgg = torch.load(f\"{root_vggish}/vggish_filenames.pth\")\n",
    "\n",
    "y_vgg = [i.split('/')[6:8] for i in y_vgg]\n",
    "\n",
    "for i in range(len(y_vgg)):\n",
    "    y_vgg[i] = f\"{y_vgg[i][0]}\"\n",
    "\n",
    "\n",
    "X_add = []\n",
    "for i in range(len(X_vgg)):\n",
    "    if(X_vgg[i].shape == torch.Size([62, 128])):\n",
    "        X_add.append(i)\n",
    "        \n",
    "X_vgg2 = []\n",
    "y_vgg2 = []\n",
    "for i, value in enumerate(X_add):\n",
    "    X_vgg2.append(X_vgg[value])\n",
    "    y_vgg2.append(y_vgg[value])\n",
    "X_vgg2 = torch.stack(X_vgg2)\n",
    "X_vgg2 = X_vgg2.numpy()\n",
    "X_vgg2 = X_vgg2.reshape(X_vgg2.shape[0], X_vgg2.shape[1]*X_vgg2.shape[2])\n",
    "\n",
    "df_vgg = pd.DataFrame(X_vgg2)\n",
    "df_vgg[\"y\"] = y_vgg2\n",
    "df_vgg\n",
    "df_vgg.set_index(\"y\", inplace=True, drop=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7927</th>\n",
       "      <th>7928</th>\n",
       "      <th>7929</th>\n",
       "      <th>7930</th>\n",
       "      <th>7931</th>\n",
       "      <th>7932</th>\n",
       "      <th>7933</th>\n",
       "      <th>7934</th>\n",
       "      <th>7935</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G03_20180511_120000.wav</th>\n",
       "      <td>151.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G03_20180511_120000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G03_20180511_121600.wav</th>\n",
       "      <td>154.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G03_20180511_121600.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G03_20180511_123200.wav</th>\n",
       "      <td>152.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G03_20180511_123200.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G03_20180511_124800.wav</th>\n",
       "      <td>155.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G03_20180511_124800.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G03_20180511_130400.wav</th>\n",
       "      <td>153.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G03_20180511_130400.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G58_20180704_070000.wav</th>\n",
       "      <td>153.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G58_20180704_070000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G58_20180704_064500.wav</th>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G58_20180704_064500.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G58_20180704_071500.wav</th>\n",
       "      <td>151.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G58_20180704_071500.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G58_20180704_073000.wav</th>\n",
       "      <td>152.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G58_20180704_073000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G58_20180704_074500.wav</th>\n",
       "      <td>156.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>G58_20180704_074500.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20067 rows × 7937 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0     1      2     3      4     5      6     7  \\\n",
       "y                                                                             \n",
       "G03_20180511_120000.wav  151.0   9.0  176.0  53.0  213.0  81.0  138.0  81.0   \n",
       "G03_20180511_121600.wav  154.0   8.0  168.0  64.0  198.0  90.0  103.0  81.0   \n",
       "G03_20180511_123200.wav  152.0  10.0  180.0  58.0  210.0  81.0  127.0  85.0   \n",
       "G03_20180511_124800.wav  155.0   9.0  169.0  62.0  198.0  78.0  115.0  81.0   \n",
       "G03_20180511_130400.wav  153.0   8.0  169.0  64.0  198.0  79.0  108.0  85.0   \n",
       "...                        ...   ...    ...   ...    ...   ...    ...   ...   \n",
       "G58_20180704_070000.wav  153.0   9.0  162.0  40.0  225.0  84.0  135.0  68.0   \n",
       "G58_20180704_064500.wav  149.0   1.0  168.0  59.0  169.0  41.0   95.0  33.0   \n",
       "G58_20180704_071500.wav  151.0  11.0  148.0  58.0  215.0  68.0  108.0  93.0   \n",
       "G58_20180704_073000.wav  152.0   7.0  160.0  60.0  179.0  39.0  127.0  36.0   \n",
       "G58_20180704_074500.wav  156.0  10.0  166.0  79.0  184.0  38.0  148.0  66.0   \n",
       "\n",
       "                             8      9  ...   7927   7928   7929   7930   7931  \\\n",
       "y                                      ...                                      \n",
       "G03_20180511_120000.wav  218.0  243.0  ...  255.0   85.0  185.0   59.0  116.0   \n",
       "G03_20180511_121600.wav  208.0  215.0  ...  255.0  120.0  221.0  156.0  118.0   \n",
       "G03_20180511_123200.wav  212.0  245.0  ...  255.0  140.0  207.0   98.0  123.0   \n",
       "G03_20180511_124800.wav  205.0  233.0  ...  255.0   50.0  127.0   85.0  102.0   \n",
       "G03_20180511_130400.wav  204.0  223.0  ...  255.0  234.0  113.0  249.0   78.0   \n",
       "...                        ...    ...  ...    ...    ...    ...    ...    ...   \n",
       "G58_20180704_070000.wav  236.0  224.0  ...  255.0  142.0    0.0   73.0  154.0   \n",
       "G58_20180704_064500.wav  242.0  249.0  ...  255.0  180.0  178.0  143.0  210.0   \n",
       "G58_20180704_071500.wav  171.0  197.0  ...  255.0  166.0    0.0   82.0  115.0   \n",
       "G58_20180704_073000.wav  229.0  226.0  ...  255.0   67.0   14.0   12.0   77.0   \n",
       "G58_20180704_074500.wav  202.0  194.0  ...  255.0  126.0    0.0   75.0  205.0   \n",
       "\n",
       "                          7932   7933   7934   7935                        y  \n",
       "y                                                                             \n",
       "G03_20180511_120000.wav  255.0    0.0   52.0  255.0  G03_20180511_120000.wav  \n",
       "G03_20180511_121600.wav  255.0    0.0   54.0  255.0  G03_20180511_121600.wav  \n",
       "G03_20180511_123200.wav  255.0    0.0    1.0  255.0  G03_20180511_123200.wav  \n",
       "G03_20180511_124800.wav  243.0    0.0   86.0  255.0  G03_20180511_124800.wav  \n",
       "G03_20180511_130400.wav  255.0    0.0    0.0  255.0  G03_20180511_130400.wav  \n",
       "...                        ...    ...    ...    ...                      ...  \n",
       "G58_20180704_070000.wav   65.0  213.0  255.0  255.0  G58_20180704_070000.wav  \n",
       "G58_20180704_064500.wav  255.0    0.0  246.0  255.0  G58_20180704_064500.wav  \n",
       "G58_20180704_071500.wav  128.0    0.0  195.0  255.0  G58_20180704_071500.wav  \n",
       "G58_20180704_073000.wav  175.0   95.0  110.0  255.0  G58_20180704_073000.wav  \n",
       "G58_20180704_074500.wav   81.0  150.0  255.0  255.0  G58_20180704_074500.wav  \n",
       "\n",
       "[20067 rows x 7937 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_ae \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mX_vgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m())  \u001b[38;5;66;03m# Convertir tensor a NumPy antes de DataFrame\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Agregar la columna 'y' con los nombres de archivo\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_ae[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_vgg\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "df_ae = pd.DataFrame(X_vgg.numpy())  # Convertir tensor a NumPy antes de DataFrame\n",
    "\n",
    "# Agregar la columna 'y' con los nombres de archivo\n",
    "df_ae[\"y\"] = y_vgg  # Asignar la lista de nombres al final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vgg = torch.load(f\"{root_vggish}/vggish_features.pth\")\n",
    "y_vgg = torch.load(f\"{root_vggish}/vggish_filenames.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8459946792787467\n",
      "f1: 0.7714564127766039\n",
      "recall 0.7411086123604864\n"
     ]
    }
   ],
   "source": [
    "X_vgg = torch.load(f\"{root_vggish}/vggish_features.pth\")\n",
    "y_vgg = torch.load(f\"{root_vggish}/vggish_filenames.pth\")\n",
    "\n",
    "y_vgg2 = [i.split('/')[6] for i in y_vgg]\n",
    "X_vgg2 = X_vgg\n",
    "X_vgg3 = []\n",
    "remove = []\n",
    "remove_idx = []\n",
    "keep_idx = []\n",
    "for i in range(len(y_vgg2)):\n",
    "    #a[i] = X_vgg2[i]\n",
    "    if y_vgg2[i] not in y_3:\n",
    "        remove.append(y_vgg2[i])\n",
    "        remove_idx.append(X_vgg2[i])\n",
    "    else:\n",
    "        keep_idx.append(i)\n",
    "for i in range(len(remove)): \n",
    "    y_vgg2.remove(remove[i])\n",
    "\n",
    "for i in keep_idx:\n",
    "    X_vgg3.append(X_vgg2[i])\n",
    "    \n",
    "X_vgg4 = np.zeros([16911,62,128])\n",
    "for i in range (len(X_vgg3)):\n",
    "    X_vgg4[i] = X_vgg3[i].numpy()\n",
    "X_vgg4 = X_vgg4.reshape(X_vgg4.shape[0], X_vgg4.shape[1]*X_vgg4.shape[2])\n",
    "    \n",
    "labels = []\n",
    "for i in range(len(y_vgg2)):\n",
    "    labels.append(audios.loc[y_vgg2[i], \"Habitat\"])\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, labels_train, labels_test = train_test_split(X_vgg4, labels, test_size=0.2,random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=16, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, labels_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(labels_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Indices Features and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 1: Using all audios (included rainfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8631235898721484\n",
      "f1: 0.8074462457042182\n",
      "recall 0.77855832467982\n"
     ]
    }
   ],
   "source": [
    "labels_ai2 = []\n",
    "for i in range(len(labels_ai)):\n",
    "    labels_ai2.append(audios.loc[labels_ai[i], \"Habitat\"])\n",
    "X_ai = ai\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ai, labels_ai2, test_size=0.2,random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=16, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 2: Using audios without rainfall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8737806680461129\n",
      "f1: 0.8195986374058009\n",
      "recall 0.7905498415666719\n"
     ]
    }
   ],
   "source": [
    "y_ = np.asarray(y_path)\n",
    "y_2 = y_[:,0]\n",
    "for i in range(len(y_2)):\n",
    "    y_2[i] = y_2[i][0:-2] \n",
    "y_3 = list(y_2)\n",
    "\n",
    "X_ai = []\n",
    "remove = []\n",
    "for i in range(len(y_3)):\n",
    "    try:\n",
    "        X_ai.append(ai.loc[y_3[i]])\n",
    "#         print(i, \" \", np.asarray(np.min(X_ai)))\n",
    "    except:\n",
    "        remove.append(y_3[i])\n",
    "for i in range(len(remove)):\n",
    "    y_3.remove(remove[i])\n",
    "X_ai = np.asarray(X_ai)\n",
    "\n",
    "labels_ai = []\n",
    "# audios.set_index(\"Filename\", inplace=True)\n",
    "for i in range(len(y_3)):\n",
    "    labels_ai.append(audios.loc[y_3[i], \"Habitat\"])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ai, labels_ai, test_size=0.2,random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=16, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(y_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders Features and Labels using independent segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# audios.set_index(\"Filename\", inplace=True)\n",
    "labels = []\n",
    "for i in range(len(path_flat)):\n",
    "    labels.append(audios.loc[path_flat[i][0:-2], \"Habitat\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders Features and Labels using 5 segments of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = X_scaled\n",
    "print(X_c.shape)\n",
    "y_c = (path_flat)\n",
    "\n",
    "# for i in range(len(y_c)):\n",
    "#     split = y_c[i].split(\"_\")[0:3]\n",
    "#     y_c[i] = f\"{split[0]}_{split[1]}_{split[2]}\"\n",
    "remove_2 = []\n",
    "counter = 0\n",
    "for i in range(len(remove)):\n",
    "    for j in range(1,6):\n",
    "        counter+=1\n",
    "        a = np.where(y_c == f\"{remove[i]}_{j}\")\n",
    "        remove_2.append(a[0][0])\n",
    "#         y_c.remove(f\"{remove[i]}_{j}\")\n",
    "#         X_c = np.delete(X_c, i, axis=0)\n",
    "\n",
    "y_c = np.delete(y_c, remove_2, 0)\n",
    "X_c = np.delete(X_c, remove_2,0)\n",
    "\n",
    "X_batch = np.reshape(X_c, (X_c.shape[0]//5,5,X_c.shape[1]))\n",
    "y_path = np.reshape(y_c, (y_c.shape[0]//5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_batch, y_path, test_size=0.2,random_state=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0]*X_test.shape[1], X_test.shape[2])\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_train = y_train.reshape(y_train.shape[0]*y_train.shape[1])\n",
    "y_test = y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
    "\n",
    "labels_train = []\n",
    "for i in range(len(y_train)):\n",
    "    labels_train.append(audios.loc[y_train[i][0:-2], \"Habitat\"])\n",
    "labels_test = []\n",
    "for i in range(len(y_test)):\n",
    "    labels_test.append(audios.loc[y_test[i][0:-2], \"Habitat\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders Features and Labels using voting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=16, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, labels_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(labels_test, y_pred_rf)\n",
    "f1_score = metrics.f1_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "recall = metrics.recall_score(labels_test, y_pred_rf, average=\"macro\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf2 = np.asarray(y_pred_rf)\n",
    "y_pred_rf2 = np.reshape(y_pred_rf2,(y_pred_rf2.shape[0]//5,5))\n",
    "y_test2 = np.asarray(labels_test)\n",
    "y_test2 = np.reshape(y_test2,(y_test2.shape[0]//5,5))\n",
    "\n",
    "def most_frequent(List):\n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "labels_test2 = []\n",
    "labels_pred = []\n",
    "for i in range(len(y_pred_rf2)):\n",
    "    labels_pred.append(most_frequent(list(y_pred_rf2[i])))\n",
    "    labels_test2.append(most_frequent(list(y_test2[i])))\n",
    "accuracy = metrics.accuracy_score(labels_test2, labels_pred)\n",
    "f1_score = metrics.f1_score(labels_test2, labels_pred, average=\"macro\")\n",
    "recall = metrics.recall_score(labels_test2, labels_pred, average=\"macro\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"f1:\", f1_score)\n",
    "print(\"recall\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(100), random_state=0)\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = clf_mlp.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"f1:\",metrics.f1_score(y_test, y_pred_mlp, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_scores = [] # [ai, AE_norm, AE_PCA, AE_UMAP, VGGISH, VGGISH_PCA, VGGISH_UMAP]\n",
    "# accuracies = []\n",
    "# recalls = []\n",
    "UMAP_scores = []\n",
    "UMAP_scores.append({\"f1\":f1_score, \"acc\": accuracy, \"recall\": recall})\n",
    "f1_scores.append(f1_score)\n",
    "accuracies.append(accuracy)\n",
    "recalls.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"f1_scores_fair\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(f1_scores, fp)\n",
    "    \n",
    "with open(\"accuracies_fair\", \"wb\") as fp2:   #Pickling\n",
    "    pickle.dump(accuracies, fp2)\n",
    "    \n",
    "with open(\"recalls_fair\", \"wb\") as fp3:   #Pickling\n",
    "    pickle.dump(recalls, fp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = pd.read_pickle(f\"{root}/temporal/classification_results/f1_scores_fair\")\n",
    "accuracy_scores = pd.read_pickle(f\"{root}/temporal/classification_results/accuracies_fair\")\n",
    "recall_scores = pd.read_pickle(f\"{root}/temporal/classification_results/recalls_fair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for F1 scores, recall, and accuracy\n",
    "methods = [\"Acoustic\\nIndices\", \"AE Normalized\", \"AE PCA\", \"AE UMAP\", \"vggish\"]\n",
    "\n",
    "# Create an array for the x-axis positions\n",
    "x = np.arange(len(methods))\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(11, 6))\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Define professional color palettes\n",
    "f1_color = 'steelblue'  # You can adjust the color as needed\n",
    "recall_color = 'indianred'  # You can adjust the color as needed\n",
    "accuracy_color = 'orange'  # You can adjust the color as needed\n",
    "\n",
    "# Create the bar chart for F1 scores\n",
    "bars_f1 = plt.bar(x - bar_width, f1_scores, bar_width, label='F1 Score', color=f1_color)\n",
    "\n",
    "# Create the bar chart for recall\n",
    "bars_recall = plt.bar(x, recall_scores, bar_width, label='Recall', color=recall_color)\n",
    "\n",
    "# Create the bar chart for accuracy\n",
    "bars_accuracy = plt.bar(x + bar_width, accuracy_scores, bar_width, label='Accuracy', color=accuracy_color)\n",
    "\n",
    "# Set the y-axis limits\n",
    "plt.ylim(0.5, 1)\n",
    "\n",
    "# Set the x-axis labels and their positions\n",
    "plt.xticks(x, methods, fontsize=14)  # Increase label size\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Score')\n",
    "\n",
    "# Set the title\n",
    "plt.title('F1 Score, Recall, and Accuracy Comparison')\n",
    "\n",
    "# Set the legend with increased size\n",
    "plt.legend(fontsize=14)  # Increase legend size\n",
    "\n",
    "# Add values on top of the bars\n",
    "for bar, value in zip(bars_f1, f1_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height()+0.01, f'{value:.3f}', ha='center', va='bottom', fontsize=11, rotation=90)\n",
    "\n",
    "for bar, value in zip(bars_recall, recall_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height()+0.01, f'{value:.3f}', ha='center', va='bottom', fontsize=11, rotation=90)\n",
    "\n",
    "for bar, value in zip(bars_accuracy, accuracy_scores):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height()+0.01, f'{value:.3f}', ha='center', va='bottom', fontsize=11, rotation=90)\n",
    "\n",
    "# Add a legend\n",
    "# plt.legend()\n",
    "\n",
    "# Display the figure\n",
    "\n",
    "plt.savefig(f\"{root}/temporal/classification_results/calssification_fair_2.pdf\", format=\"pdf\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "15FiCdrQdIiLbRJdrnLgeGSWmPZR-eIZZ",
     "timestamp": 1668314866472
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
