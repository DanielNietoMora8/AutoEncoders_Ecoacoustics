{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48e781f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T23:41:31.401432057Z",
     "start_time": "2023-10-06T23:41:31.358226256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7897669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid\n",
    "from Jaguas_DataLoader_rainless import SoundscapeData\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443dd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_generator():\n",
    "    def __init__(self, root_clusters, root_audios, root_recorders, n_clusters_index = 0):\n",
    "        self.n_clusters_index = n_clusters_index\n",
    "        self.cluster_names = os.listdir(f\"{root_clusters}\")\n",
    "        self.torch_clusters = torch.load(f\"{root_clusters}/{self.cluster_names[n_clusters_index]}\")\n",
    "        self.dataframe_clusters = pd.DataFrame(self.torch_clusters)\n",
    "        self.dataframe_clusters = self.dataframe_clusters.transpose()\n",
    "        self.dataframe_audios = pd.read_csv(f\"{root_audios}\", index_col=0)\n",
    "        self.dataframe_recorders = pd.read_csv(f\"{root_recorders}\",sep = \";\", index_col = \"Recorder\")\n",
    "        self.df_clusters_len = len(self.dataframe_clusters)\n",
    "        self.df_recorders_len = len(self.dataframe_recorders)\n",
    "        self.n_clusters = np.arange(len(self.torch_clusters))\n",
    "        \n",
    "        for i in self.n_clusters:\n",
    "            self.dataframe_audios[f\"Cluster {i}\"] = 0\n",
    "        self.dataframe_audios.set_index(\"Filename\", drop=False, inplace=True)\n",
    "        for i in self.n_clusters:\n",
    "            counts = self.dataframe_clusters[i].value_counts()\n",
    "            c_index = counts.index\n",
    "            c_value = counts.values\n",
    "            for j in range(len(counts)):\n",
    "                self.dataframe_audios.loc[c_index[j], f\"Cluster {i}\"] = c_value[j]\n",
    "\n",
    "        self.dataframe_audios[\"Cluster Sum\"] = self.dataframe_audios.loc[:,\"Cluster 0\": f\"Cluster {len(self.n_clusters)-1}\"].sum(axis=1)\n",
    "        self.dataframe_audios = self.dataframe_audios[self.dataframe_audios[\"Cluster Sum\"]!=0]\n",
    "        self.dataframe_audios.set_index(pd.Index(range(0,len(self.dataframe_audios))), inplace=True)\n",
    "\n",
    "\n",
    "    def show_clusters(self, keyword=None, plot=True):\n",
    "        cluster_names = []\n",
    "        index = []\n",
    "        if keyword != None:\n",
    "            for i in range(len(self.cluster_names)):\n",
    "                if keyword in self.cluster_names[i]:\n",
    "                    cluster_names.append(self.cluster_names[i])\n",
    "                    index.append(i)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            for i in range(len(self.cluster_names)):\n",
    "                    cluster_names.append(self.cluster_names[i])\n",
    "                    index.append(i)\n",
    "                    \n",
    "        if plot==True:\n",
    "            for i in range(len(cluster_names)):\n",
    "                print(f\"{index[i]}: {cluster_names[i]}\")\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        return cluster_names, index\n",
    "\n",
    "    def init_clusters(self):\n",
    "        for cluster in self.n_clusters:\n",
    "            self.dataframe_recorders[f\"Cluster {cluster}\"] = 0\n",
    "    \n",
    "#     def create_clusters(self, count_cluster=False):\n",
    "#         self.init_clusters()\n",
    "#         for cluster in self.n_clusters:\n",
    "#             for i in range(self.df_clusters_len):  \n",
    "#                 if self.dataframe_clusters.iloc[i][cluster] != None:\n",
    "#                     self.dataframe_recorders.loc[self.dataframe_clusters.iloc[i][cluster].split(\"_\")[0], f\"Cluster {cluster}\"] +=1\n",
    "#                 else:\n",
    "#                     pass\n",
    "#         if count_cluster == True:\n",
    "#             self.count_cluster_data()\n",
    "#         else:\n",
    "#             pass\n",
    "    \n",
    "    def create_clusters_v2(self, count_cluster=False):\n",
    "        self.init_clusters()\n",
    "        for cluster in self.n_clusters:\n",
    "            for i in range(len(self.dataframe_audios)): \n",
    "                self.dataframe_recorders.loc[self.dataframe_audios.loc[i, \"Filename\"].split(\"_\")[0], f\"Cluster {cluster}\"] += self.dataframe_audios.loc[i, f\"Cluster {cluster}\"]\n",
    "        if count_cluster == True:\n",
    "            self.count_cluster_data()\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def count_cluster_data(self):\n",
    "        clusters = [f\"Cluster {i}\" for i in range(0, len(self.n_clusters))]\n",
    "        self.dataframe_recorders[\"Total_Clustering_Audios\"] = self.dataframe_recorders[clusters].sum(axis=1)\n",
    "    \n",
    "    def GLM_dataframe(self):\n",
    "        GLM = self.dataframe_recorders.copy()\n",
    "        columns = [f\"Cluster {i}\" for i in range(0, len(self.n_clusters))]\n",
    "        columns.append(\"Total_Clustering_Audios\")\n",
    "        GLM = GLM[columns]\n",
    "        for cluster in range(len(columns[0:-1])):\n",
    "            for recorder in range(self.df_recorders_len):\n",
    "                GLM.iloc[recorder, cluster] = GLM.iloc[recorder, cluster]/GLM.iloc[recorder, -1]\n",
    "        return GLM\n",
    "    \n",
    "    def regions(self):\n",
    "        dataframe_audios_regions = self.dataframe_audios.copy()\n",
    "        dataframe_audios_regions[\"Region\"] = 0\n",
    "        for audio in range(len(dataframe_audios_regions)):   \n",
    "            dataframe_audios_regions.loc[audio,\"Region\"] = self.dataframe_recorders.loc[dataframe_audios_regions.loc[audio, \"Recorder\"]].loc[\"Region\"]\n",
    "        return dataframe_audios_regions\n",
    "    \n",
    "    def recorders(self):\n",
    "        return self.dataframe_recorders\n",
    "    \n",
    "    def audios(self):\n",
    "        return self.dataframe_audios\n",
    "    \n",
    "    def clusters(self):\n",
    "        return self.dataframe_clusters\n",
    "    \n",
    "    def save(self, root_save=None):\n",
    "        if root_save != None:\n",
    "            os.makedirs(f\"{self.root_save}/dataframes\", exist_ok=True)\n",
    "            self.dataframe_recorders.to_csv(f\"{self.root_save}/dataframes/dataframe_{self.cluster_names[self.n_clusters_index]}_recorders.csv\")\n",
    "            self.dataframe_audios.to_csv(f\"{self.root_save}/dataframes/dataframe_{self.cluster_names[self.n_clusters_index]}_audios.csv\") \n",
    "            \n",
    "        else:\n",
    "            self.dataframe_recorders.to_csv(f\"{self.cluster_names[sel.n_clusters_index]}_recorders.csv\")\n",
    "            self.dataframe_audios.to_csv(f\"{self.cluster_names[sel.n_clusters_index]}_audios.csv\")\n",
    "            \n",
    "class df_results:\n",
    "    def __init__(self, df_base, trials, df_EI = None):\n",
    "        self.df_base = df_base\n",
    "#         self.r, self.index = self.df_base.show_clusters(plot=False)\n",
    "        self.df_EI = df_EI\n",
    "        self.df_clusters_EI = df_base\n",
    "        self.n_clusters = 0\n",
    "        self.trials = trials\n",
    "        self.colors_list = [[\"brown\", \"darkcyan\", \"purple\", \"forestgreen\", \"goldenrod\", \"dimgray\", \"firebrick\", \"lightseagreen\", \"darkolivegreen\", \"blueviolet\", \"darkgreen\", \"orangered\", \"deepskyblue\", \"indigo\", \"black\", \"darkorange\"],\n",
    "                            [\"crimson\", \"firebrick\", \"orangered\", \"coral\", \"peachpuff\", \"darkslategray\", \"teal\", \"dodgerblue\", \"deepskyblue\", \"skyblue\"]]\n",
    "        self.colors = self.colors_list[0]\n",
    "    def colors(self, palette=0):\n",
    "        self.colors = self.colors_list[palette]\n",
    "        return self.colors\n",
    "        \n",
    "    def random_color_generator(self):\n",
    "        colors = []\n",
    "        for i in range(n_clusters):\n",
    "            random_color = random.choice(list(mcolors.CSS4_COLORS.keys()))\n",
    "            while(random_color in colors):\n",
    "                random_color = random.choice(list(mcolors.CSS4_COLORS.keys()))\n",
    "            colors.append(random_color)\n",
    "        return colors\n",
    "    \n",
    "    def create_EI(self):\n",
    "        self.df_clusters_EI[\"Mean\"] = self.df_EI[\"Mean\"]\n",
    "        self.df_clusters_EI[\"Sum\"] = self.df_EI[\"Sum\"]\n",
    "        self.df_clusters_EI[\"Max\"] = self.df_EI[\"Max\"]\n",
    "        self.df_clusters_EI[\"Min\"] = self.df_EI[\"Min\"]\n",
    "        self.n_clusters = len(self.df_clusters_EI.iloc[0])-5\n",
    "        \n",
    "    def plot_bars(self, root=\"\", title=None):\n",
    "        columns = [f\"Cluster {i}\" for i in range(0, self.n_clusters)]\n",
    "        Bar_GLM = self.df_clusters_EI[columns]\n",
    "        Bar_GLM[\"Mean\"] = self.df_EI[\"Mean\"]\n",
    "        # Bar_GLM.index.names = recorders.index\n",
    "        Bar_GLM = Bar_GLM.sort_values(by=[\"Mean\"])\n",
    "        Bar_GLM2=Bar_GLM.drop(columns=[\"Mean\"], inplace=False)\n",
    "        ax=Bar_GLM2.plot(kind='bar', stacked=True, color=self.colors)\n",
    "        plt.title(f\"{title}\")\n",
    "        Bar_GLM[\"Mean\"].plot(ax=ax, color=\"black\")\n",
    "        plt.savefig(f\"{root}.pdf\",format=\"pdf\")\n",
    "        \n",
    "    def GLM(self,y_data=\"Mean\"):\n",
    "        GLM = self.df_clusters_EI.copy()\n",
    "        X= GLM[[f\"Cluster {i}\" for i in range(len(GLM.columns)-6)]]\n",
    "        X = X.to_numpy()\n",
    "        y = GLM[y_data]\n",
    "        y = y.to_numpy()\n",
    "        gamma_model = sm.GLM(y, X, family=sm.families.Gamma())\n",
    "        gamma_results = gamma_model.fit()\n",
    "        r2 = gamma_results.pseudo_rsquared()\n",
    "        return gamma_results, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f076e",
   "metadata": {},
   "source": [
    "## Feature Dataframes Organization for fair classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130d787a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df_ai.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_ai \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdf_ai.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_ae_unflat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_ae_unflat.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m df_vgg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_vgg.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/DANM/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_ai.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_ai = pd.read_csv(\"df_ai.csv\")\n",
    "df_ae_unflat = pd.read_csv(\"df_ae_unflat.csv\")\n",
    "df_vgg = pd.read_csv(\"df_vgg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df475ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai.set_index(\"y\", inplace=True)\n",
    "df_vgg.set_index(\"y\", inplace=True)\n",
    "df_ae_unflat.set_index(\"y\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b622db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_comunes = df_ai.index.intersection(df_ae_unflat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fb8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai = df_ai.loc[indices_comunes].sort_index()\n",
    "df_ae_unflat = df_ae_unflat.loc[indices_comunes].sort_index()\n",
    "df_vgg = df_vgg.loc[indices_comunes].sort_index() # -> se verifico que los Ã­ndices comunes son iguales para vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f46245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai.to_csv(\"New_df_ai.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ae_unflat.to_csv(\"New_df_ae_unflat.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab95b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vgg.to_csv(\"New_df_vgg.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d870e5",
   "metadata": {},
   "source": [
    "# GLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9426e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_audios = f\"{root}/Jaguas/Complementary_Files/Audios_Jaguas/Audios_Jaguas.csv\"\n",
    "root_recorders = f\"{root}/Jaguas/Complementary_Files/df_grabadoras_reg.csv\"\n",
    "root_clusters = f\"{root}/Jaguas/temporal/clusters\"\n",
    "ecological_integrity = f\"{root}/Jaguas/Complementary_Files/Indice_Integridad_Ecologica.xlsx\"\n",
    "df_EI = pd.read_excel(ecological_integrity)\n",
    "df_EI.rename(columns={\"Sitio\":\"Recorder\"}, inplace=True)\n",
    "df_EI.set_index(\"Recorder\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00540bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_646672/3847344411.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  dataframe.dataframe_audios = dataframe.dataframe_audios[dataframe.dataframe_audios.Time>\"17:00\"][dataframe.dataframe_audios.Time<\"24:00\"]\n"
     ]
    }
   ],
   "source": [
    "dataframe = df_generator(root_clusters, root_audios, root_recorders, \n",
    "                         n_clusters_index=20)\n",
    "dataframe.dataframe_audios = dataframe.dataframe_audios[dataframe.dataframe_audios.Time>\"17:00\"][dataframe.dataframe_audios.Time<\"24:00\"]\n",
    "dataframe.dataframe_audios.reset_index(inplace=True)\n",
    "dataframe.create_clusters_v2(count_cluster=True)\n",
    "GLM = GLM = dataframe.GLM_dataframe()\n",
    "GLM[\"Mean\"] = df_EI[\"Mean\"]\n",
    "GLM[\"Sum\"] = df_EI[\"Sum\"]\n",
    "GLM[\"Max\"] = df_EI[\"Max\"]\n",
    "GLM[\"Min\"] = df_EI[\"Min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79687c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r, index = dataframe.show_clusters(\"_AE_\")\n",
    "print(r, index)\n",
    "trials_3 = [19, 26, 18, 11]\n",
    "trials_5 = [2, 0, 1, 8]\n",
    "trials_10 = [9, 16, 20, 7]\n",
    "trials_15 = [14, 4, 22, 25]\n",
    "trials = [trials_3, trials_5, trials_10, trials_15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f630118",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = df_generator(root_clusters, root_audios, root_recorders, \n",
    "                         n_clusters_index=20)\n",
    "dataframe.dataframe_audios = dataframe.dataframe_audios[dataframe.dataframe_audios.Time>\"05:00\"][dataframe.dataframe_audios.Time<\"08:00\"]\n",
    "#         dataframe.dataframe_audios = dataframe.dataframe_audios.drop(aux.index)\n",
    "dataframe.dataframe_audios.reset_index(inplace=True)\n",
    "dataframe.create_clusters_v2(count_cluster=True)\n",
    "GLM = dataframe.GLM_dataframe()\n",
    "results = df_results(GLM, trials, df_EI)\n",
    "results.create_EI()\n",
    "results.plot_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b12ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "r, index = dataframe.show_clusters(plot=False)\n",
    "trials_3 = [19, 26, 18, 11]\n",
    "trials_5 = [2, 0, 1, 8]\n",
    "trials_10 = [9, 16, 20, 7]\n",
    "trials_15 = [14, 4, 22, 25]\n",
    "trials = [trials_3, trials_5, trials_10, trials_15]\n",
    "horas = [(5, 8), (8, 17), (17, 5)]\n",
    "for trial in trials:\n",
    "    for i, t in enumerate(trial):\n",
    "        dataframe = df_generator(root_clusters, root_audios, root_recorders, \n",
    "                         n_clusters_index=t)\n",
    "        dataframe.dataframe_audios = dataframe.dataframe_audios[dataframe.dataframe_audios.Time>\"05:00\"][dataframe.dataframe_audios.Time<\"08:00\"]\n",
    "#         dataframe.dataframe_audios = dataframe.dataframe_audios.drop(aux.index)\n",
    "        dataframe.dataframe_audios.reset_index(inplace=True)\n",
    "        dataframe.create_clusters_v2(count_cluster=True)\n",
    "        GLM = dataframe.GLM_dataframe()\n",
    "        results = df_results(GLM, trials, df_EI)\n",
    "        results.create_EI()\n",
    "        results.plot_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd05f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = folium.Map(location=[6.3828, -75.0157], zoom_start=12)\n",
    "\n",
    "puntos = df[['latitude_IG', 'longitud_IG', 'number_files_FI']].values.tolist()\n",
    "valores = df[\"number_files_FI\"].tolist()\n",
    "HeatMap(puntos, radius=35, ).add_to(mapa)\n",
    "mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872643f5",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "%matplotlib qt\n",
    "r, index = dataframe.show_clusters(plot=False)\n",
    "trials_3 = [19, 26, 18, 11]\n",
    "trials_5 = [2, 0, 1, 8]\n",
    "trials_10 = [9, 16, 20, 7]\n",
    "trials_15 = [14, 4, 22, 25]\n",
    "trials = [trials_3, trials_5, trials_10, trials_15]\n",
    "horas = [(5, 8), (8, 17), (17, 5)]\n",
    "for trial in trials:\n",
    "    for i, t in enumerate(trial):\n",
    "        dataframe = df_generator(root_clusters, root_audios, root_recorders, \n",
    "                         n_clusters_index=t)\n",
    "        dataframe.dataframe_audios = dataframe.dataframe_audios[dataframe.dataframe_audios.Time>\"05:00\"][dataframe.dataframe_audios.Time<\"08:00\"]\n",
    "#         dataframe.dataframe_audios = dataframe.dataframe_audios.drop(aux.index)\n",
    "        dataframe.dataframe_audios.reset_index(inplace=True)\n",
    "        dataframe.create_clusters_v2(count_cluster=True)\n",
    "        GLM = dataframe.GLM_dataframe()\n",
    "        GLM[\"Mean\"] = df_EI[\"Mean\"]\n",
    "        GLM[\"Sum\"] = df_EI[\"Sum\"]\n",
    "        GLM[\"Max\"] = df_EI[\"Max\"]\n",
    "        GLM[\"Min\"] = df_EI[\"Min\"]\n",
    "        n_clusters = len(GLM.iloc[0])-5\n",
    "        columns = [f\"Cluster {i}\" for i in range(0, n_clusters)]\n",
    "        Bar_GLM = GLM[columns]\n",
    "        Bar_GLM[\"Mean\"] = df_EI[\"Mean\"]\n",
    "        # Bar_GLM.index.names = recorders.index\n",
    "        Bar_GLM = Bar_GLM.sort_values(by=[\"Mean\"])\n",
    "        Bar_GLM2=Bar_GLM.drop(columns=[\"Mean\"], inplace=False)\n",
    "        ax=Bar_GLM2.plot(kind='bar', stacked=True, color=colors_list)\n",
    "        plt.title(f\"{r[trial[i]]}_dawn\")\n",
    "        Bar_GLM[\"Mean\"].plot(ax=ax, color=\"black\")\n",
    "        plt.savefig(f\"{root}/Jaguas/temporal/ei_results/dawn/{r[trial[i]]}_dawn.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca295765",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "ax=Bar_GLM2.plot(kind='bar', stacked=True, color=colors_list)\n",
    "Bar_GLM[\"Mean\"].plot(ax=ax, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c19bb",
   "metadata": {},
   "source": [
    "# Using StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_results.pseudo_rsquared()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_index = [27, 10, 6, 23]\n",
    "UMAP_index = [3, 12, 5, 21]\n",
    "TSNE_index = [29, 15, 17, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ac2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r2_PCA)\n",
    "plt.plot(r2_UMAP)\n",
    "plt.plot(r2_TSNE)\n",
    "plt.legend([\"PCA\", \"UMAP\", \"TSNE\"])\n",
    "plt.xticks((0,1,2,3),(\"3\", \"5\", \"10\", \"15\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r2_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6011f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "r2_PCA = []\n",
    "trials = TSNE_index;\n",
    "for index in trials:\n",
    "    dataframe = df_generator(root_clusters, root_audios, root_recorders, \n",
    "                         n_clusters_index=index)\n",
    "    dataframe.create_clusters(count_cluster=True)\n",
    "    GLM = dataframe.GLM_dataframe()\n",
    "#     GLM = GLM.reset_index().set_index(np.arange(len(GLM)))\n",
    "    GLM[\"Mean\"] = df_EI[\"Mean\"]\n",
    "    GLM[\"Sum\"] = df_EI[\"Sum\"]\n",
    "    GLM[\"Max\"] = df_EI[\"Max\"]\n",
    "    GLM[\"Min\"] = df_EI[\"Min\"]\n",
    "    X= GLM[[f\"Cluster {i}\" for i in range(len(GLM.columns)-6)]]\n",
    "    X = X.to_numpy()\n",
    "    y = GLM[\"Mean\"]\n",
    "    y = y.to_numpy()\n",
    "    gamma_model = sm.GLM(y, X, family=sm.families.Gamma())\n",
    "    gamma_results = gamma_model.fit()\n",
    "    r2_PCA.append(gamma_results.pseudo_rsquared())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96246a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "X= GLM[[f\"Cluster {i}\" for i in range(len(GLM.columns)-6)]]\n",
    "X = X.to_numpy()\n",
    "y = GLM[\"Mean\"]\n",
    "y = y.to_numpy()\n",
    "gamma_model = sm.GLM(y, X, family=sm.families.Gamma())\n",
    "gamma_results = gamma_model.fit()\n",
    "print(gamma_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443a560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "data = sm.datasets.scotland.load()\n",
    "data.exog = sm.add_constant(data.exog)\n",
    "gamma_model = sm.GLM(data.endog, data.exog, family=sm.families.Gamma())\n",
    "gamma_results = gamma_model.fit()\n",
    "print(gamma_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dfbfbf",
   "metadata": {},
   "source": [
    "# SK-Learn example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.PoissonRegressor()\n",
    "X = [[1, 2], [2, 3], [3, 4], [4, 3]]\n",
    "y = [12, 17, 22, 21]\n",
    "clf.fit(X, y)\n",
    "clf.score(X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
