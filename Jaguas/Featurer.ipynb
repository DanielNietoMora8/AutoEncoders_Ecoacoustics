{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18052,
     "status": "ok",
     "timestamp": 1678388233869,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "2OLjDqbgadV7",
    "outputId": "a38c57aa-e4dd-46fe-aca2-9e6bd6d0cd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    # !wandb login\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\"\n",
    "    root_path = \"media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4523,
     "status": "ok",
     "timestamp": 1678388238390,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ucIGvQ7GczZb",
    "outputId": "0bdf55db-463b-4047-8259-f7dc96b407f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio.transforms as audio_transform\n",
    "\n",
    "from Jaguas_DataLoader_rainless import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "print(device)\n",
    "\n",
    "from datetime import timedelta\n",
    "import wandb\n",
    "from wandb import AlertLevel\n",
    "\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1678388246582,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "qemaBluJa22A",
    "outputId": "30519d6b-ea58-4423-cb89-b2c5ffb7d854"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root_path = \"ConservacionBiologicaIA/Datos/Jaguas_2018\"\n",
    "day = 27\n",
    "hour = 19\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "model_name = f\"{root}/Jaguas/temporal/models/model_AE_batch_size_14_num_hiddens_64__{date_format}_final.pth\"\n",
    "config = torch.load(f'{root}/Jaguas/temporal/configs/config_AE_batch_size_14_num_hiddens_64__day_{day}_hour_{hour}.pth', map_location=torch.device('cpu'))\n",
    "model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n",
    "# dataset_test = torch.load(f'temporal/datasets/dataset_test_ae_jaguas_9_70%.pth')\n",
    "# dataset_train = torch.load(f'temporal/datasets/dataset_train_ae_jaguas_9_70%.pth')\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folders = os.listdir(f\"/{root_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G03_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 45 of 456\n",
      "id: 90 of 456\n",
      "id: 135 of 456\n",
      "id: 180 of 456\n",
      "id: 225 of 456\n",
      "id: 270 of 456\n",
      "id: 315 of 456\n",
      "id: 360 of 456\n",
      "id: 405 of 456\n",
      "id: 450 of 456\n",
      "G04_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 32 of 326\n",
      "id: 64 of 326\n",
      "id: 96 of 326\n",
      "id: 128 of 326\n",
      "id: 160 of 326\n",
      "id: 192 of 326\n",
      "id: 224 of 326\n",
      "id: 256 of 326\n",
      "id: 288 of 326\n",
      "id: 320 of 326\n",
      "G06_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 70 of 709\n",
      "id: 140 of 709\n",
      "id: 210 of 709\n",
      "id: 280 of 709\n",
      "id: 350 of 709\n",
      "id: 420 of 709\n",
      "id: 490 of 709\n",
      "id: 560 of 709\n",
      "id: 630 of 709\n",
      "id: 700 of 709\n",
      "G07_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 50 of 504\n",
      "id: 100 of 504\n",
      "id: 150 of 504\n",
      "id: 200 of 504\n",
      "id: 250 of 504\n",
      "id: 300 of 504\n",
      "id: 350 of 504\n",
      "id: 400 of 504\n",
      "id: 450 of 504\n",
      "id: 500 of 504\n",
      "G08_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 48 of 484\n",
      "id: 96 of 484\n",
      "id: 144 of 484\n",
      "id: 192 of 484\n",
      "id: 240 of 484\n",
      "id: 288 of 484\n",
      "id: 336 of 484\n",
      "id: 384 of 484\n",
      "id: 432 of 484\n",
      "id: 480 of 484\n",
      "G09_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 71 of 714\n",
      "id: 142 of 714\n",
      "id: 213 of 714\n",
      "id: 284 of 714\n",
      "id: 355 of 714\n",
      "id: 426 of 714\n",
      "id: 497 of 714\n",
      "id: 568 of 714\n",
      "id: 639 of 714\n",
      "id: 710 of 714\n",
      "G13_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 53 of 539\n",
      "id: 106 of 539\n",
      "id: 159 of 539\n",
      "id: 212 of 539\n",
      "id: 265 of 539\n",
      "id: 318 of 539\n",
      "id: 371 of 539\n",
      "id: 424 of 539\n",
      "id: 477 of 539\n",
      "id: 530 of 539\n",
      "G15_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 71 of 714\n",
      "id: 142 of 714\n",
      "id: 213 of 714\n",
      "id: 284 of 714\n",
      "id: 355 of 714\n",
      "id: 426 of 714\n",
      "id: 497 of 714\n",
      "id: 568 of 714\n",
      "id: 639 of 714\n",
      "id: 710 of 714\n",
      "G17_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 73 of 730\n",
      "id: 146 of 730\n",
      "id: 219 of 730\n",
      "id: 292 of 730\n",
      "id: 365 of 730\n",
      "id: 438 of 730\n",
      "id: 511 of 730\n",
      "id: 584 of 730\n",
      "id: 657 of 730\n",
      "id: 730 of 730\n",
      "G19_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 74 of 741\n",
      "id: 148 of 741\n",
      "id: 222 of 741\n",
      "id: 296 of 741\n",
      "id: 370 of 741\n",
      "id: 444 of 741\n",
      "id: 518 of 741\n",
      "id: 592 of 741\n",
      "id: 666 of 741\n",
      "id: 740 of 741\n",
      "G23_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 46 of 463\n",
      "id: 92 of 463\n",
      "id: 138 of 463\n",
      "id: 184 of 463\n",
      "id: 230 of 463\n",
      "id: 276 of 463\n",
      "id: 322 of 463\n",
      "id: 368 of 463\n",
      "id: 414 of 463\n",
      "id: 460 of 463\n",
      "G24_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 43 of 437\n",
      "id: 86 of 437\n",
      "id: 129 of 437\n",
      "id: 172 of 437\n",
      "id: 215 of 437\n",
      "id: 258 of 437\n",
      "id: 301 of 437\n",
      "id: 344 of 437\n",
      "id: 387 of 437\n",
      "id: 430 of 437\n",
      "G25_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 62 of 623\n",
      "id: 124 of 623\n",
      "id: 186 of 623\n",
      "id: 248 of 623\n",
      "id: 310 of 623\n",
      "id: 372 of 623\n",
      "id: 434 of 623\n",
      "id: 496 of 623\n",
      "id: 558 of 623\n",
      "id: 620 of 623\n",
      "G27_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 53 of 534\n",
      "id: 106 of 534\n",
      "id: 159 of 534\n",
      "id: 212 of 534\n",
      "id: 265 of 534\n",
      "id: 318 of 534\n",
      "id: 371 of 534\n",
      "id: 424 of 534\n",
      "id: 477 of 534\n",
      "id: 530 of 534\n",
      "G28_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 53 of 531\n",
      "id: 106 of 531\n",
      "id: 159 of 531\n",
      "id: 212 of 531\n",
      "id: 265 of 531\n",
      "id: 318 of 531\n",
      "id: 371 of 531\n",
      "id: 424 of 531\n",
      "id: 477 of 531\n",
      "id: 530 of 531\n",
      "G29_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 53 of 534\n",
      "id: 106 of 534\n",
      "id: 159 of 534\n",
      "id: 212 of 534\n",
      "id: 265 of 534\n",
      "id: 318 of 534\n",
      "id: 371 of 534\n",
      "id: 424 of 534\n",
      "id: 477 of 534\n",
      "id: 530 of 534\n",
      "G34_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 60 of 608\n",
      "id: 120 of 608\n",
      "id: 180 of 608\n",
      "id: 240 of 608\n",
      "id: 300 of 608\n",
      "id: 360 of 608\n",
      "id: 420 of 608\n",
      "id: 480 of 608\n",
      "id: 540 of 608\n",
      "id: 600 of 608\n",
      "G35_m\n",
      "/media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\n",
      "id: 60 of 606\n"
     ]
    }
   ],
   "source": [
    "# folders = [\"Audios_Jaguas\"]\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    filters = {\"Intensity_Category\": \"No_rain\"}\n",
    "    dataset = SoundscapeData(root_path, dataframe_path=f\"Complementary_Files/Audios_Jaguas/{folder[0:3]}.csv\",\n",
    "                             audio_length=12, ext=\"wav\",\n",
    "                             win_length=1028, filters=filters)\n",
    "    featuring_autoencoders(dataset, date_format, model=model, len_features=None, save=True, identifier=f\"{folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jPCv40Ugk0I",
    "outputId": "b093c1e1-5419-407e-a180-ab158e8f79ba"
   },
   "outputs": [],
   "source": [
    "def featuring_autoencoders(dataset, date_format, model, len_features=None, save=True, identifier=None):\n",
    "    training_loader = DataLoader(dataset, batch_size=1)\n",
    "    # test_loader = DataLoader(dataset_test, batch_size=1)\n",
    "    iterator = iter(training_loader)\n",
    "    testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "    # encodings_size = encodings[0].shape\n",
    "\n",
    "    training_recorder_list = []\n",
    "    training_hour_list = []\n",
    "    training_minute_list = []\n",
    "    delete_samples = []\n",
    "    training_path_samples = []\n",
    "    training_samples_list_torch = []\n",
    "    \n",
    "    if len_features == None:\n",
    "        len_features = len(training_loader)\n",
    "    else:\n",
    "        len_features = len_features\n",
    "        \n",
    "    batch = int(len_features*0.1)\n",
    "    \n",
    "    for id in range(len_features):\n",
    "    #     if (id+1)%3 == 0:\n",
    "    #         break\n",
    "        if (id+1)% batch == 0:\n",
    "            print(f\"id: {id + 1} of {len_features}\")\n",
    "        try:\n",
    "            originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "        except:\n",
    "            print(f\"error id: {id}\")\n",
    "            delete_samples.append(id)\n",
    "            continue\n",
    "\n",
    "    #     encodings_size = encodings[0].shape\n",
    "        encodings = encodings.to(\"cuda\").detach()\n",
    "        encodings = encodings.reshape(encodings.shape[0],\n",
    "                                    encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "        encoding = encodings.squeeze(dim=0)\n",
    "        training_samples_list_torch.append(encodings)\n",
    "        training_recorder_list.append(label[\"recorder\"].reshape(label[\"recorder\"].shape[0]*label[\"recorder\"].shape[1]))\n",
    "        training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "        training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "\n",
    "\n",
    "        path = np.asarray(path)\n",
    "        path = np.repeat(path, 5)\n",
    "        training_path_samples.append(path)\n",
    "\n",
    "    training_recorder_list = torch.cat(training_recorder_list,dim=0)\n",
    "    training_hour_list = torch.cat(training_hour_list,dim=0)\n",
    "    training_minute_list = torch.cat(training_minute_list,dim=0)\n",
    "    training_samples_list_torch = torch.cat(training_samples_list_torch, dim=0)\n",
    "    \n",
    "    if save == True:\n",
    "    \n",
    "        if \"filters\" in dataset.kwargs.keys():\n",
    "            for value in dataset.filters.values():\n",
    "                date_format = f\"{date_format}_{value}\" \n",
    "\n",
    "        if identifier != None:\n",
    "            date_format = f\"{date_format}_{identifier}\"\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        torch.save(training_path_samples, f\"temporal/Features/test_path_samples_{date_format}.pth\")\n",
    "        torch.save(training_samples_list_torch, f\"temporal/Features/test_samples_list_torch_{date_format}.pth\")\n",
    "        training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "        torch.save(training_labels_list, f\"temporal/Features/test_labels_list_{date_format}.pth\")\n",
    "        torch.save(delete_samples, f\"temporal/Features/test_corrupted_samples_list_{date_format}.pth\")\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "error",
     "timestamp": 1678388483545,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "SvnFOiVpq63a",
    "outputId": "58f9d9b0-d822-4f3b-c8d2-6e801391f3b2"
   },
   "outputs": [],
   "source": [
    "training_loader = DataLoader(dataset, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "encodings[0].shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
