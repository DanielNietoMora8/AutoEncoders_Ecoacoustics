{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64780,
     "status": "ok",
     "timestamp": 1677243791963,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "-tHkzPEe4HId",
    "outputId": "fc928a2f-dc57-4678-c7d0-dc122dc2a724"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on colab\n",
      "/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install -U encodec\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    !pip install joypy\n",
    "    # !wandb login\n",
    "    !pip install umap-learn\n",
    "    !pip install umap-learn[plot]\n",
    "    !pip install holoviews\n",
    "    !pip install -U ipykernel\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n",
    "    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/Jaguas_2018')\n",
    "\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20364,
     "status": "ok",
     "timestamp": 1677243812320,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "yfGsxwZ9mJop",
    "outputId": "3494a43a-223e-46bb-bbd5-0df055744874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio\n",
    "import torchaudio\n",
    "import torch\n",
    "import joypy\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Modules.Utils import plot_spectrogram\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Results')\n",
    "sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Figures')\n",
    "sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Result')\n",
    "root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Jaguas_2018/'\n",
    "\n",
    "folders = os.listdir(root_path)\n",
    "files=[]\n",
    "for i in range(len(folders)):\n",
    "    path_aux = \"{}/{}\".format(root_path, folders[i])\n",
    "    files += list(Path(path_aux).rglob(\"*.{}\".format(\"wav\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1440,
     "status": "ok",
     "timestamp": 1677243813727,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "hJ7QO8IO5FVc"
   },
   "outputs": [],
   "source": [
    "model = EncodecModel.encodec_model_24khz()\n",
    "model.set_target_bandwidth(6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1677243813728,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "mNOwKjx34Xgz"
   },
   "outputs": [],
   "source": [
    "# wav, sr = torchaudio.load(str(files[0]))\n",
    "# wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n",
    "# wav = wav.unsqueeze(0)\n",
    "# wav.shape\n",
    "# with torch.no_grad():\n",
    "#     encoded_frames = model.encode(wav)\n",
    "#     encoder = model.encoder(wav)\n",
    "# codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)  # [B, n_q, T]\n",
    "# encodings = torch.reshape(codes,(codes.shape[0], codes.shape[1]*codes.shape[2]))\n",
    "# decodings = torch.reshape(encodings,(encodings.shape[0], 8, 4500))\n",
    "# with torch.no_grad():    \n",
    "#     decoded_frames = model.decode(encoded_frames)\n",
    "\n",
    "# spec_original = torchaudio.transforms.Spectrogram(window_fn=torch.hamming_window,\n",
    "#                                             power=2,\n",
    "#                                             normalized=False)(wav[0])\n",
    "\n",
    "# spec_reconstruction = torchaudio.transforms.Spectrogram(window_fn=torch.hamming_window,\n",
    "#                                             power=2,\n",
    "#                                             normalized=False)(decoded_frames[0])\n",
    "# decodings2 = [(decodings, None)]\n",
    "\n",
    "# final = model.decode(decodings2)\n",
    "# spec_reconstruction = torchaudio.transforms.Spectrogram(window_fn=torch.hamming_window,\n",
    "#                                             power=2,\n",
    "#                                             normalized=False)(final[0])\n",
    "# plot_spectrogram(spec_reconstruction[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1677243814616,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "4Mc7Gb3WKxmA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "dataset_test = torch.load(f'{root}/temporal/dataset_test_ae_jaguas_new.pth')\n",
    "dataset_train = torch.load(f'{root}/temporal/dataset_train_ae_jaguas_new.pth')\n",
    "training_loader = DataLoader(dataset_train, batch_size=1)\n",
    "test_loader = DataLoader(dataset_test, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "\n",
    "# training_recorder_list = []\n",
    "# training_hour_list = []\n",
    "# training_minute_list = []\n",
    "# delete_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1677243814617,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "LpgJLySBUhFE"
   },
   "outputs": [],
   "source": [
    "# a,b,c = next(iterator)\n",
    "# b = b.unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     codes = model.encoder(b)\n",
    "# training_samples_list_torch = torch.ones(len(dataset_train), codes.shape[1]*codes.shape[2]).to(\"cuda\")\n",
    "# print(training_samples_list_torch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677243814618,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "_p804yQX2_Im"
   },
   "outputs": [],
   "source": [
    "# f = model.quantizer.encode(codes, model.sample_rate)\n",
    "# f = f.transpose(0,1)\n",
    "# f = f.transpose(0,1)\n",
    "# emb = model.quantizer.decode(f)\n",
    "# out = model.decoder(emb)\n",
    "# spec_ = torchaudio.transforms.Spectrogram(window_fn=torch.hamming_window,\n",
    "#                                             power=2,\n",
    "#                                             normalized=False)(out[0])\n",
    "# plot_spectrogram(spec_[0].detach().numpy())\n",
    "\n",
    "# print(emb.shape)\n",
    "# plt.figure(figsize=(24,24))\n",
    "# plt.imshow(f.transpose(0,1)[0])\n",
    "# plt.figure(figsize=(24,24))\n",
    "# plt.imshow(codes[0])\n",
    "# f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1677243814619,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "BxzXQs7IcmGO"
   },
   "outputs": [],
   "source": [
    "# for id, item in enumerate(dataset_train):\n",
    "#     if (id+1)% 5 == 0:\n",
    "#         print(\"entro\")\n",
    "#         break\n",
    "#     if id% 500 == 0:\n",
    "#         print(f\"id: {id + 1} of {len(dataset_train)}\")\n",
    "#     try:\n",
    "#         spec, wav, label = next(iterator)\n",
    "#     except:\n",
    "#         print(f\"iterator broken in index {id}\")\n",
    "#         continue\n",
    "#     wav = wav.unsqueeze(0)\n",
    "#     with torch.no_grad():\n",
    "#         codes = model.encoder(wav)\n",
    "#     print(codes.shape)\n",
    "#     encodings = torch.reshape(codes,(codes.shape[0], codes.shape[1]*codes.shape[2]))\n",
    "#     print(encodings.shape)\n",
    "#     training_samples_list_torch[id] = encodings[0]\n",
    "#     training_recorder_list.append(label[\"recorder\"])\n",
    "#     training_hour_list.append(label[\"hour\"])\n",
    "#     training_minute_list.append(label[\"minute\"])\n",
    "\n",
    "# print(f\"------------------------------------\\n{id}\\nProcess finished\\nSaving data\\n------------------------------------\")\n",
    "# torch.save(training_samples_list_torch, \"training_samples_list_torch_encodec_feats.pth\")\n",
    "# torch.save(training_recorder_list, \"training_recorder_list_encodec_feats.pth\")\n",
    "# torch.save(training_hour_list, \"training_hour_list_encodec_feats.pth\")\n",
    "# torch.save(training_minute_list, \"training_minute_list_encodec_feats.pth\")\n",
    "# training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "# torch.save(training_labels_list, \"training_labels_list_encodec_feats.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1677243814620,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "TvkpBj0R9ZKf"
   },
   "outputs": [],
   "source": [
    "# a,b,c = next(iterator)\n",
    "# wav=b.unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     encoded_frames = model.encode(wav)\n",
    "# codes = torch.cat([encoded[0] for encoded in encoded_frames], dim=-1)  # [B, n_q, T]\n",
    "# encodings = torch.reshape(codes,(codes.shape[0], codes.shape[1]*codes.shape[2]))\n",
    "# with torch.no_grad():    \n",
    "#     decoded_frames = model.decode(encoded_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1677243814621,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "xH41EuOGHAaj"
   },
   "outputs": [],
   "source": [
    "# spec_original = torchaudio.transforms.Spectrogram(window_fn=torch.hamming_window,\n",
    "#                                             power=2,\n",
    "#                                             normalized=False)(wav[0])\n",
    "\n",
    "# spec_reconstruction = torchaudio.transforms.Spectrogram(window_fn=torch.hamming_window,\n",
    "#                                             power=2,\n",
    "#                                             normalized=False)(decoded_frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1677243814622,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "4JrOgURdKsBy"
   },
   "outputs": [],
   "source": [
    "# plot_spectrogram(spec_original[0],  title= \"Original\")\n",
    "# plot_spectrogram(spec_reconstruction[0], title=\"Reconstruction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sePTWQ51J68w"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "y = torch.load(\"Features/training_labels_list_encodec_feats.pth\",  map_location=torch.device('cpu'))\n",
    "X = torch.load(\"Features/training_samples_list_torch_encodec_feats.pth\",  map_location=torch.device('cpu'))\n",
    "X = X[0:6000]\n",
    "y[\"recorder\"] = y[\"recorder\"][0:6000]\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "from sklearn.manifold import TSNE\n",
    "# X_n = X\n",
    "X_scaled = scaler.transform(X)\n",
    "# X_TSNE = TSNE(n_components=2, learning_rate=\"auto\", init='random', random_state=0).fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJb0miHmCfGq"
   },
   "source": [
    "## **Traditional clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hXhfknkgChqU"
   },
   "outputs": [],
   "source": [
    "# Batch methods\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Single methods\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZZImGs5AknH"
   },
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# def plot_spectrogram(spec, title=None, ylabel: str = 'freq_bin', aspect='auto', xmax=None, **kwargs):\n",
    "#     plt.subplot(kwargs[\"numx_plots\"], kwargs[\"numy_plots\"], kwargs[\"i\"]+1)\n",
    "#     # print(axs.shape)\n",
    "#     plt.set_title(title or 'Spectrogram (db)')\n",
    "#     # axs[kwargs[\"i\"]].set_ylabel(ylabel)\n",
    "#     # axs[kwargs[\"i\"]].set_xlabel('frame')\n",
    "#     plt.set_axis_off()\n",
    "#     plt.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect, cmap=\"inferno\")\n",
    "#     if xmax:\n",
    "#         plt.set_xlim((0, xmax))\n",
    "#     plt.xticks(())\n",
    "#     plt.yticks(())\n",
    "#     # fig.colorbar(im, ax=axs)\n",
    "#     # plt.show(block=False)\n",
    "#     # fig.savefig(\"try2\", bbox_inches='tight', transparent=True, pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry3d4qHbJ7xD"
   },
   "outputs": [],
   "source": [
    "from logging import raiseExceptions\n",
    "def plot_silhouette( X, cluster_labels, n_clusters, silhouette_avg, method, extra=\"\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-1, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0,\n",
    "                    0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "    print(\"Ya debio plotear\")\n",
    "    plt.savefig(f\"Clustering_Results_Encodec/{method}/Figures/Silhouette_plot_{n_clusters}.pdf\", format=\"pdf\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_centroids(cluster_centers, method, extra=\"\"):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i, spec in enumerate(cluster_centers):\n",
    "        print(spec.shape)\n",
    "        codes = np.reshape(spec,(128, 827))\n",
    "        \n",
    "        try:\n",
    "            codes = codes.astype(np.float32)\n",
    "            codes = torch.from_numpy(codes)\n",
    "            codes = codes.unsqueeze(dim=0)\n",
    "        except:\n",
    "            codes = codes.unsqueeze(dim=0)\n",
    "\n",
    "        encoding = model.quantizer.encode(codes, model.sample_rate)\n",
    "        encoding = encoding.transpose(0,1)\n",
    "        enc = encoding.transpose(0,1)\n",
    "        emb = model.quantizer.decode(enc)\n",
    "        out = model.decoder(emb)\n",
    "\n",
    "        \n",
    "        spec_ = torchaudio.transforms.Spectrogram(window_fn=torch.hamming_window,\n",
    "                                            power=2,\n",
    "                                            normalized=False)(out[0])\n",
    "        plot_spectrogram(spec_[0].detach().numpy(), numx_plots=6, numy_plots=6, i=i)\n",
    "        # plt.subplot(6, 6, i + 1)\n",
    "        # # plt.imshow(decodings[:,:], origin=\"lower\", cmap=\"viridis\")\n",
    "        # plt.xticks(())\n",
    "        # plt.yticks(())\n",
    "    n_cluster = len(cluster_centers)\n",
    "    plt.show()\n",
    "    return out\n",
    "    plt.savefig(f\"Clustering_Results_Encodec/{method}/Figures/Centroids_plot_{n_cluster}_{extra}.pdf\", format=\"pdf\")\n",
    "    plt.show()\n",
    "\n",
    "import math\n",
    "\n",
    "def num_rows_cols(num_elements):\n",
    "    num_rows = int(math.sqrt(num_elements))\n",
    "    num_cols = (num_elements + num_rows - 1) // num_rows\n",
    "    return (num_rows, num_cols)\n",
    "\n",
    "def get_row_col(pos, cols):\n",
    "    row = pos // cols\n",
    "    col = pos % cols\n",
    "    return row, col\n",
    "\n",
    "class Clustering_Results:\n",
    "    def __init__(self, model, y, y_label=\"hour\", hist_library=\"plt\"):\n",
    "        self._labels_cluster = None\n",
    "        self._n_labels = None\n",
    "        self._hist_library = hist_library\n",
    "        self._label = y_label\n",
    "        self._model = model\n",
    "        self._n_clusters = len(set(model.labels_))\n",
    "        self.y = y\n",
    "        self._y = self.converter(y[self._label])\n",
    "        self._n_labels = set(self._y)\n",
    "\n",
    "    def converter(self, var):\n",
    "        aux = []\n",
    "        for i in range(len(var)):\n",
    "            aux.append(var[i].item())\n",
    "        return np.array(aux)\n",
    "\n",
    "    def one_cluster_eval(self, cluster):\n",
    "        index = np.where(self._model.labels_ == cluster)\n",
    "        index = list(index[0])\n",
    "        self._labels_cluster = self._y[index]\n",
    "        return self._labels_cluster\n",
    "\n",
    "    def joyplot(self):\n",
    "        size_x = 8\n",
    "        size_y = 6\n",
    "        joy_vars = [\"hour\", \"recorder\"]\n",
    "        for cluster in range(self._n_clusters):\n",
    "            y_aux = []\n",
    "            labels_cluster = []\n",
    "            for i, label in enumerate(joy_vars):\n",
    "                y_aux.append(self.converter(self.y[label]))\n",
    "                index = np.where(self._model.labels_ == cluster)\n",
    "                index = list(index[0])\n",
    "                labels_cluster.append(y_aux[i][index])\n",
    "            df = pd.DataFrame({'recorder':labels_cluster[0], \"hour\":labels_cluster[1]})\n",
    "            joypy.joyplot(df, by=\"hour\", column=\"recorder\", range_style='own', \n",
    "                            grid=\"y\", hist=False, linewidth=1, legend=False, figsize=(size_x,size_y),\n",
    "                            title=f\"Cluster {cluster} \\nLabels distribution along recorders using recorders as rows\",\n",
    "                            colormap=cm.autumn_r, fade=False)\n",
    "            joypy.joyplot(df, by=\"recorder\", column=\"hour\", range_style='own', \n",
    "                                grid=\"y\", hist=False, linewidth=1, legend=False, figsize=(size_x,size_y),\n",
    "                                title=f\"Cluster {cluster} \\nLabels distribution along recorders using hours as rows\",\n",
    "                                colormap=cm.autumn_r)\n",
    "            plt.show()\n",
    "            \n",
    "\n",
    "\n",
    "    def histograms(self, method=None):\n",
    "        bins = list(self._n_labels)\n",
    "        num_rows, num_cols = num_rows_cols(self._n_clusters)\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(14, 14))\n",
    "        if self._n_clusters <= 3:\n",
    "                axes = np.expand_dims(axes,0)\n",
    "                fig.set_figheight(6)\n",
    "                fig.set_figwidth(12)\n",
    "                if self._n_clusters == 1:\n",
    "                    axes = np.expand_dims(axes,0)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "        for hist in range(self._n_clusters):\n",
    "            aux = self.one_cluster_eval(hist)\n",
    "            ax_0, ax_1 = get_row_col(hist, num_cols)\n",
    "            if self._hist_library == \"plt\":\n",
    "                axes[ax_0][ax_1].hist(aux, histtype=\"bar\",\n",
    "                                      color=\"paleturquoise\", cumulative=False,\n",
    "                                      edgecolor='black', \n",
    "                                      linewidth=1.2, bins=bins, stacked=False)\n",
    "                axes[ax_0][ax_1].set_title(f\"Cluster: {hist}\", size=16)\n",
    "            elif self._hist_library == \"sns\":\n",
    "                sns.distplot(aux,bins=np.arange(aux.min(), aux.max()+1),\n",
    "                             hist_kws=dict(edgecolor=\"black\", linewidth=1), \n",
    "                             ax=axes[ax_0, ax_1])\n",
    "                axes[ax_0][ax_1].set_title(f\"Cluster: {hist}\", size=16)              \n",
    "            else:\n",
    "                raise Exception(f\"Library {self._hist_library} unused\")\n",
    "        if method != None:\n",
    "            plt.savefig(f\"Clustering_Results_Encodec/{method}/Figures/Centroids_plot_{n_cluster}_{extra}.pdf\", format=\"pdf\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Jj0kjaxxfFg"
   },
   "outputs": [],
   "source": [
    "prueba = np.random.rand(3, 105856)\n",
    "#prueba = torch.rand(3, 105856)\n",
    "print(type(prueba))\n",
    "decodings = plot_centroids(prueba,\"Kmeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D62Apeoj9jn8"
   },
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68Jz_szzOux7"
   },
   "outputs": [],
   "source": [
    "clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30]\n",
    "mean = X.mean()\n",
    "std = X.std()\n",
    "silhouette_score_Kmeans = []\n",
    "for id, n_cluster in enumerate(clusters):\n",
    "    Kmeans = KMeans(n_clusters=n_cluster, random_state=0).fit(X_scaled)\n",
    "    silhouette_score_Kmeans.append(metrics.silhouette_score(X_scaled, Kmeans.labels_))\n",
    "    plot_silhouette(X_scaled, Kmeans.labels_, Kmeans.n_clusters, silhouette_score_Kmeans[id], \"Kmeans\")\n",
    "    cluster_centers = scaler.inverse_transform(Kmeans.cluster_centers_)\n",
    "    print(cluster_centers.shape)\n",
    "    plot_centroids(cluster_centers, \"Kmeans\")\n",
    "    Kmeans_Results = Clustering_Results(Kmeans, y, y_label=\"hour\", hist_library=\"plt\")\n",
    "    Kmeans_Results.histograms()\n",
    "    Kmeans_Results.joyplot()\n",
    "with open(f\"Clustering_Results_Encodec/Kmeans/Results/silhouette_n-clusters_{Kmeans.n_clusters}\", \"wb\") as file:\n",
    "    pkl.dump(silhouette_score_Kmeans, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VESIKUNXTKz1"
   },
   "outputs": [],
   "source": [
    "!pip install joypy\n",
    "import joypy\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "Kmeans = KMeans(n_clusters=8, random_state=0).fit(X_scaled)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "Kmeans_Results = Clustering_Results(Kmeans, y, y_label=\"recorder\", hist_library=\"plt\")\n",
    "Kmeans_Results.joyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQPntBq6UMxL"
   },
   "outputs": [],
   "source": [
    "def converter(var):\n",
    "        aux = []\n",
    "        for i in range(len(var)):\n",
    "            aux.append(var[i].item())\n",
    "        return np.array(aux)\n",
    "y_n = converter(y[\"hour\"])[0:6000]\n",
    "y_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4OjVnWuTdsW"
   },
   "outputs": [],
   "source": [
    "X_n = X.numpy()\n",
    "X_ = [X_n, X_scaled, X_TSNE]\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "for enum, x in enumerate(X_):\n",
    "    sns.jointplot(x=X_[enum][:,0], y= X_[enum][:,1], hue=y_n[0:6000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWNKwc-iUaAb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPTj+CQJPl0Js0qrKVHRq2B",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
