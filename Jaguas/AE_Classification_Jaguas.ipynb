{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36603,
     "status": "ok",
     "timestamp": 1678389399232,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "KwQ8Zp3llyi-",
    "is_executing": true,
    "outputId": "fd97b0c2-58fc-4afe-b939-c9890c909c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MIRP\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    # !wandb login\n",
    "    !pip install umap-learn\n",
    "    !pip install umap-learn[plot]\n",
    "    !pip install holoviews\n",
    "    !pip install -U ipykernel\n",
    "    !pip install joypy\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n",
    "    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Results')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Figures')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Result')\n",
    "elif \"zmqshell\" in str(get_ipython()):\n",
    "    print(\"Running on MIRP\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics/Jaguas\"\n",
    "    root_path = \"media/mirp_ai/Seagate Desktop Drive/Jaguas_2018\"\n",
    "else:\n",
    "    import pathlib\n",
    "    temp = pathlib.PosixPath\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n",
    "    print(\"Running local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3008,
     "status": "ok",
     "timestamp": 1678389402237,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ZeYXtNUUhRWh"
   },
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import gc\n",
    "import pandas as pd\n",
    "import joypy\n",
    "\n",
    "from scipy import signal\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler as Normalizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio.transforms as audio_transform\n",
    "\n",
    "\n",
    "#from ResidualStack import ResidualStack\n",
    "#from Residual import Residual\n",
    "\n",
    "from Jaguas_DataLoader_rainless import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "\n",
    "from datetime import timedelta\n",
    "import wandb\n",
    "from wandb import AlertLevel\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import pickle as pkl\n",
    "\n",
    "import random\n",
    "def _set_seed(seed: int):\n",
    "    \"\"\"\n",
    "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
    "    installed).\n",
    " \n",
    "    Args:\n",
    "        seed (:obj:`int`): The seed to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # ^^ safe to call this function even if cuda is not available\n",
    "_set_seed(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMG_87FKb26h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84820, 5184])\n"
     ]
    }
   ],
   "source": [
    "model_type = \"AE\"\n",
    "identifier = \"batch_size_14_num_hiddens_64_\"\n",
    "day = 11\n",
    "hour = 21\n",
    "month = 6\n",
    "folder = \"AE_No_rain_98\"\n",
    "date_format = f\"day_{day}_hour_{hour}\"\n",
    "\n",
    "model_name = f\"{root}/temporal/models/model_{model_type}_{identifier}_{date_format}_final.pth\"\n",
    "config = torch.load(f'temporal/configs/config_{model_type}_{identifier}_{date_format}.pth', map_location=torch.device('cpu'))\n",
    "model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n",
    "# dataset_test = torch.load(f'temporal/datasets/dataset_test_ae_jaguas_9_70%.pth')\n",
    "# dataset_train = torch.load(f'temporal/datasets/dataset_train_ae_jaguas_9_70%.pth')\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))\n",
    "\n",
    "y = torch.load(f\"temporal/Features/{folder}/AE_labels_{date_format}_No_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "X = torch.load(f\"temporal/Features/{folder}/AE_features_{date_format}_No_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "X_batch = torch.reshape(X, (16964,5,5184))\n",
    "y_path = torch.load(f\"temporal/Features/{folder}/AE_test_path_samples_{date_format}_No_rain_Audios_Jaguas.pth\",  map_location=torch.device('cpu'))\n",
    "path_flat = [item for sublist in y_path for item in sublist]\n",
    "path_flat = np.asarray(path_flat)\n",
    "print(X.shape)\n",
    "y[\"recorder\"]\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "Normalizer_ = Normalizer().fit(X)\n",
    "X_norm = Normalizer_.transform(X)\n",
    "PCA_ = PCA(n_components=60).fit(X_norm)\n",
    "X_PCA = PCA_.transform(X_norm)\n",
    "# X_TSNE = TSNE(n_components=2, learning_rate=\"auto\", init='random', random_state=0).fit_transform(X_PCA)\n",
    "reducer = umap.UMAP(min_dist=0.9, n_components=60)\n",
    "X_UMAP = reducer.fit_transform(X_scaled)\n",
    "# X_UMAP_Norm = Normalizer().fit_transform(X_UMAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_audios = f\"{root}/Complementary_Files/Audios_Jaguas/Audios_Jaguas.csv\"\n",
    "root_recorders = f\"{root}/Complementary_Files/df_grabadoras_reg.csv\"\n",
    "root_clusters = f\"{root}/temporal/clusters\"\n",
    "root_ai = f\"{root}/Complementary_Files/Acoustic_Indices/AI_Jaguas.csv\"\n",
    "ecological_integrity = f\"{root}/Complementary_Files/Indice_Integridad_Ecologica.xlsx\"\n",
    "\n",
    "audios = pd.read_csv(root_audios, index_col=0)\n",
    "recorders = pd.read_csv(root_recorders)\n",
    "ei  = pd.read_excel(ecological_integrity)\n",
    "ai = pd.read_csv(root_ai)\n",
    "ai.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "ai.drop(columns=[\"Date\"], inplace=True)\n",
    "ai.dropna(inplace=True)\n",
    "\n",
    "ai.set_index(\"file\",inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_ = np.asarray(y_path)\n",
    "y_2 = y_[:,0]\n",
    "for i in range(len(y_2)):\n",
    "    y_2[i] = y_2[i][0:-2] \n",
    "y_3 = list(y_2)\n",
    "\n",
    "X_ai = []\n",
    "remove = []\n",
    "for i in range(len(y_3)):\n",
    "    try:\n",
    "        X_ai.append(ai.loc[y_3[i]])\n",
    "#         print(i, \" \", np.asarray(np.min(X_ai)))\n",
    "    except:\n",
    "        remove.append(y_3[i])\n",
    "for i in range(len(remove)):\n",
    "    y_3.remove(remove[i])\n",
    "X_ai = np.asarray(X_ai)\n",
    "\n",
    "labels_ai = []\n",
    "audios.set_index(\"Filename\", inplace=True)\n",
    "for i in range(len(y_3)):\n",
    "    labels_ai.append(audios.loc[y_3[i], \"Habitat\"])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ai, labels_ai, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 75921\n",
    "(X[i]==f[i//5][i%5]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(path_flat)):\n",
    "    labels.append(p.loc[path_flat[i], \"Habitat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, labels, test_size=0.2,random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "clf_svm = svm.SVC(kernel='rbf') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8737806680461129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "clf_rf = RandomForestClassifier(max_depth=16, random_state=0, n_jobs=-1)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7336683417085427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirp_ai/anaconda3/envs/DANM/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(10), random_state=0)\n",
    "clf_mlp.fit(X_train, y_train)\n",
    "y_pred_mlp = clf_mlp.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_mlp))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "15FiCdrQdIiLbRJdrnLgeGSWmPZR-eIZZ",
     "timestamp": 1668314866472
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
