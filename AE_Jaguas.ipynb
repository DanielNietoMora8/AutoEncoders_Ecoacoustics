{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18601,"status":"ok","timestamp":1668485684040,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"KwQ8Zp3llyi-","outputId":"9a65afab-00cb-42c9-9a95-ee81ef2334f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","    import sys\n","    from google.colab import drive, output\n","    drive.mount('/content/drive')\n","    !pip install torchaudio\n","    !pip install wandb --upgrade\n","    !wandb login\n","    # !pip install umap-learn\n","    output.clear()\n","    %load_ext autoreload\n","    %autoreload 1\n","    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n","    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n","    #sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Results')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Results/Figures')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Clustering_Result')\n","else:\n","    \"Running local\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8499,"status":"ok","timestamp":1668485692531,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"ZeYXtNUUhRWh","outputId":"f40ffc33-d32b-4d6b-bf39-b00a4f0c44e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielnieto\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["# from __future__ import print_function\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from six.moves import xrange\n","import datetime\n","import gc\n","\n","from scipy import signal\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import torchaudio.transforms as audio_transform\n","\n","#from ResidualStack import ResidualStack\n","#from Residual import Residual\n","\n","from Jaguas_DataLoader import SoundscapeData\n","from Models import ConvAE as AE\n","from AE_training_functions import TestModel, TrainModel\n","from AE_Clustering import AE_Clustering \n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = xm.xla_device()\n","print(device)\n","\n","from datetime import timedelta\n","import wandb\n","from wandb import AlertLevel\n","\n","wandb.login()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cMG_87FKb26h","executionInfo":{"status":"ok","timestamp":1668485703860,"user_tz":300,"elapsed":11332,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}}},"outputs":[],"source":["root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Jaguas_2018'\n","\n","\n","dataset = SoundscapeData(root_path, audio_length=12, ext=\"wav\", win_length=1028)\n","dataset_train, dataset_test = random_split(dataset,\n","                                           [round(len(dataset)*0.3), len(dataset) - round(len(dataset)*0.3)], \n","                                           generator=torch.Generator().manual_seed(1024))\n","\n","config = {\n","    \"project\" : \"AE-Jaguas\",\n","    \"audio_length\": dataset.audio_length,\n","    \"batch_size\" : 14*4,\n","    \"num_epochs\": 5,\n","    \"num_hiddens\" : 64,\n","    \"gamma_lr\" : 0.1,\n","    \"learning_rate\" : 1e-3,\n","    \"dataset\" : \"Audios Jaguas\",\n","    \"architecture\": \"AE\",\n","    \"win_length\" : dataset.win_length\n","}\n","\n","torch.save(dataset_test, \"temporal/dataset_test_ae_jaguas_new\")\n","torch.save(dataset_train, \"temporal/dataset_train_ae_jaguas_new\")\n","training_loader = DataLoader(dataset_train, batch_size=config[\"batch_size\"])\n","test_loader = DataLoader(dataset_test, batch_size=config[\"batch_size\"])\n","\n","\n","model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], amsgrad=False)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size = 6, gamma = config[\"gamma_lr\"] )\n","\n","config[\"optimizer\"] = optimizer\n","config[\"scheduler\"] = scheduler\n","config[\"num_training_updates\"] = len(training_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":763},"id":"6YtKCwnNnDYP","outputId":"7d08dc9f-1dac-42ad-a1b8-cb046a9106d3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/wandb/run-20221115_041503-36rolrwl</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/danielnieto/AE-Jaguas/runs/36rolrwl\" target=\"_blank\">balmy-sound-220</a></strong> to <a href=\"https://wandb.ai/danielnieto/AE-Jaguas\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"]},{"output_type":"stream","name":"stdout","text":["encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 1 of 430 \t loss: 0.219\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 2 of 430 \t loss: 0.2175\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 3 of 430 \t loss: 0.2179\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 4 of 430 \t loss: 0.2178\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 5 of 430 \t loss: 0.2175\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 6 of 430 \t loss: 0.2159\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 7 of 430 \t loss: 0.2721\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 8 of 430 \t loss: 0.2157\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 9 of 430 \t loss: 0.2136\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 10 of 430 \t loss: 0.213\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 11 of 430 \t loss: 0.213\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 12 of 430 \t loss: 0.2133\n","encoder_shape:  torch.Size([14, 64, 9, 9])\n","decoder_shape:  torch.Size([14, 1, 515, 515])\n","epoch: 1 of 5 \t iteration: 13 of 430 \t loss: 0.3974\n"]}],"source":["Training = TrainModel(model)\n","model, logs, run_name = Training.fordward(training_loader, test_loader, config)\n","time = datetime.datetime.now()\n","torch.save(model.state_dict(),f'{run_name}_day_{time.day}_hour_{time.hour}_final.pth')\n","torch.save(config,f'config_{run_name}_day_{time.day}_hour_{time.hour}.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w5sjhlDScl3G"},"outputs":[],"source":["dataset_test = torch.load(f'temporal/dataset_test_ae_jaguas')\n","dataset_train = torch.load(f'temporal/dataset_train_ae_jaguas')\n","model.load_state_dict(torch.load(f'Models/AE_batch_size_14_num_hiddens_64__day_4_hour_1_epoch_3.pkl', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mBePtMUv5MD7"},"outputs":[],"source":["# root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Porce_2019'\n","\n","\n","# dataset = SoundscapeData(root_path, audio_length=12, ext=\"WAV\", win_length=1028)\n","# dataset_train, dataset_test = random_split(dataset,\n","#                                            [round(len(dataset)*0.7), len(dataset) - round(len(dataset)*0.7)], \n","#                                            generator=torch.Generator().manual_seed(1024))\n","# Dataset_train = DataLoader(dataset_train, batch_size=54, shuffle=True)\n","# Dataset = DataLoader(dataset_test, batch_size=54, shuffle=True)\n","\n","training_loader = DataLoader(dataset_train, batch_size=100)\n","test_loader = DataLoader(dataset_test, batch_size=100)\n","iterator = iter(test_loader)\n","testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fWREIMjnUf9x"},"outputs":[],"source":["originals, reconstructions, encodings, label, loss= testing.run()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFQvOLxb7Ytc"},"outputs":[],"source":["wav_origin=testing.waveform_generator(spec=originals)\n","print(wav_origin[0:1])\n","wav_origin = np.interp(wav_origin, (wav_origin.min(), wav_origin.max()), (-1, +1))\n","print(wav_origin[0:1])\n","wav_recons=testing.waveform_generator(spec=reconstructions)\n","wav_recons= np.interp(wav_recons, (wav_recons.min(), wav_recons.max()), (-1, +1))\n","testing.plot_psd(wav_origin[0:4],2)\n","testing.plot_psd(wav_origin[10:14],2)\n","#testing.plot_psd(wav_origin[18:22],2)\n","plt.savefig(\"original_psd.pdf\")\n","plt.figure()\n","testing.plot_psd(wav_recons[0:4],2)\n","testing.plot_psd(wav_recons[10:14],2)\n","#testing.plot_psd(wav_recons[18:22],2)\n","plt.savefig(\"recon_psd.pdf\")\n","wav_diff = wav_origin-wav_recons\n","plt.figure()\n","testing.plot_psd(wav_diff,4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBEMoCDtUhDZ"},"outputs":[],"source":["wav_origin=testing.waveform_generator(spec=originals)\n","print(wav_origin[0:1])\n","wav_origin = np.interp(wav_origin, (wav_origin.min(), wav_origin.max()), (-1, +1))\n","print(wav_origin[0:1])\n","wav_recons=testing.waveform_generator(spec=reconstructions)\n","wav_recons= np.interp(wav_recons, (wav_recons.min(), wav_recons.max()), (-1, +1))\n","testing.plot_psd(wav_origin,2)\n","plt.savefig(\"original_psd.pdf\")\n","plt.figure()\n","testing.plot_psd(wav_recons,2)\n","plt.savefig(\"recon_psd.pdf\")\n","wav_diff = wav_origin-wav_recons\n","plt.figure()\n","testing.plot_psd(wav_diff,4)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0E_jW1OyNlm"},"outputs":[],"source":["plt.plot(wav_origin[12,0])\n","plt.plot(wav_recons[12,0], color='red', alpha = 0.4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUNZFPQNmhEj"},"outputs":[],"source":["clusters = [14, 9, 8, 7, 6, 5, 2]\n","for n_cluster in clusters:\n","    print(f\"current cluster: {n_cluster}\")\n","    iterator_Dataset = iter(training_loader)\n","    testing = TestModel(model, iterator_Dataset, device=torch.device(\"cuda\"))\n","    Clustering = AE_Clustering(testing, training_loader, n_clusters=n_cluster)\n","    kmeans = Clustering.fordward()\n","    Clustering.plot_centroids()\n","    plt.savefig(f\"Clustering_Results/Figures/Clustering_centroids_{n_cluster}.pdf\", format=\"pdf\")\n","    output.clear()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs-21vU9cBBT"},"outputs":[],"source":["Clustering.plot_centroids()\n","plt.savefig(f\"Clustering_Results/Figures/Clustering_centroids_TSNE_7.pdf\", format=\"pdf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"68wxgeupqxBv"},"outputs":[],"source":["encodings_size = [64,9,9]\n","plt.figure(figsize=(18, 18))\n","model.to(\"cpu\")\n","for i, spec in enumerate(kmeans.cluster_centers_):\n","    encodings = spec.reshape(encodings_size)\n","    encodings = torch.tensor(encodings).float()\n","    decodings = model.decoder(encodings).detach().numpy()\n","    plt.subplot(9, 9, i + 1)\n","    plt.imshow(decodings[0,:,:], cmap=\"inferno\", interpolation=\"nearest\",vmin=0, vmax=0.02)\n","    plt.xticks(())\n","    plt.yticks(())\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyPsF1DdkizYCOltjHfJuq+u"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}