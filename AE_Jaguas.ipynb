{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AE_Jaguas.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNzTLW3ZIoALpAntHCCS21y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9ayLoOoUd0cR","executionInfo":{"status":"ok","timestamp":1658117772006,"user_tz":300,"elapsed":15041,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}}},"outputs":[],"source":["from google.colab import drive, output\n","drive.mount('/content/drive')\n","import sys\n","%cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n","#sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n","#sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n","sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n","sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n","sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n","%load_ext autoreload\n","%autoreload 1\n","!pip install torchaudio\n","!pip install wandb --upgrade\n","!wandb login\n","output.clear()"]},{"cell_type":"code","source":["# from __future__ import print_function\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","import numpy as np\n","# import IPython\n","\n","from six.moves import xrange\n","\n","import datetime\n","import gc\n","\n","from scipy import signal\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import torchaudio.transforms as audio_transform\n","\n","#from ResidualStack import ResidualStack\n","#from Residual import Residual\n","\n","from Jaguas_DataLoader import SoundscapeData\n","from Models import ConvAE as AE\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = xm.xla_device()\n","print(device)\n","\n","from datetime import timedelta\n","import wandb\n","from wandb import AlertLevel\n","\n","wandb.login()"],"metadata":{"id":"ZeYXtNUUhRWh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658117792642,"user_tz":300,"elapsed":20641,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}},"outputId":"c9b512c8-0019-460e-c281-fbfa0a1c3af8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n","  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"]},{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielnieto\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Jaguas_2018'\n","\n","\n","dataset = SoundscapeData(root_path, audio_length=12, ext=\"wav\", win_length=1028)\n","dataset_train, dataset_test = random_split(dataset,\n","                                           [round(len(dataset)*0.2), len(dataset) - round(len(dataset)*0.2)], \n","                                           generator=torch.Generator().manual_seed(1024))\n","\n","config = {\n","    \"project\" : \"AE-Jaguas\",\n","    \"audio_length\": dataset.audio_length,\n","    \"batch_size\" : 8,\n","    \"num_epochs\": 6,\n","    \"num_hiddens\" : 32,\n","    \"gamma_lr\" : 0.1,\n","    \"learning_rate\" : 1e-2,\n","    \"dataset\" : \"Audios Jaguas\",\n","    \"architecture\": \"AE\",\n","    \"win_length\" : dataset.win_length\n","}\n","\n","training_loader = DataLoader(dataset_train, batch_size=config[\"batch_size\"])\n","test_loader = DataLoader(dataset_test, batch_size=config[\"batch_size\"])\n","\n","\n","model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], amsgrad=False)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size = 2, gamma = 0.1 )\n","\n","config[\"optimizer\"] = optimizer\n","config[\"scheduler\"] = scheduler\n","config[\"num_training_updates\"] = len(training_loader)"],"metadata":{"id":"cMG_87FKb26h","executionInfo":{"status":"ok","timestamp":1658117794417,"user_tz":300,"elapsed":1781,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from scipy.io.wavfile import write\n","\n","class TestModel:\n","\n","    def __init__(self, model, iterator, num_views):\n","        self._model = model\n","        self._iterator = iterator\n","        self.num_views = num_views\n","\n","    def plot_waveform(self, waveform, n_rows=2, directory=None):\n","        fig, axs = plt.subplots(n_rows, figsize=(10, 6), constrained_layout=True)\n","        for i in range(len(waveform)):\n","            axs[i].plot(waveform[i,0])\n","            if directory != None:\n","                scaled = np.int16(waveform[i,0]/np.max(np.abs(waveform[i,0])) * 32767)\n","                write(directory + str(i) + '.wav', 22050, scaled)\n","        plt.show()\n","        \n","        \n","    def waveform_generator(self, spec, n_fft=512, win_length=512, audio_length=59, base_win=256, plot=False):\n","        spec = spec.cdouble()\n","        spec = spec.to(\"cpu\")\n","        hop_length = int(np.round(base_win/win_length * 172.3))\n","        transformation = audio_transform.InverseSpectrogram(n_fft=n_fft, win_length=win_length)\n","        waveform = transformation(spec)\n","        waveform = waveform.cpu().detach().numpy()\n","        return waveform\n","    \n","    def plot_psd(self, waveform):\n","        for wave in waveform:\n","            plt.psd(wave)\n","\n","    def plot_reconstructions(self, imgs_original, imgs_reconstruction, num_views:int = 8):\n","        output = torch.cat((imgs_original[0:self.num_views], imgs_reconstruction[0:self.num_views]), 0)\n","        img_grid = make_grid(output, nrow=self.num_views, pad_value=20)\n","        fig, ax = plt.subplots(figsize=(20,5))\n","        ax.imshow(img_grid[1,:,:].cpu(), vmin=0, vmax=1)\n","        ax.axis(\"off\")\n","        plt.show()\n","        return fig\n","\n","    def reconstruct(self):\n","        self._model.eval()\n","        (valid_originals, _,_) = next(self._iterator)\n","        valid_originals = torch.reshape(valid_originals, (valid_originals.shape[0] * valid_originals.shape[1], \n","                                                    valid_originals.shape[2], valid_originals.shape[3]))\n","        valid_originals = torch.unsqueeze(valid_originals,1)\n","\n","        valid_originals = valid_originals.to(device)\n","\n","        valid_reconstructions = self._model(valid_originals)\n","\n","        BCE = F.mse_loss(valid_reconstructions, valid_originals)\n","        loss = BCE\n","\n","        return valid_originals, valid_reconstructions, loss\n","\n","    def run(self, plot=True, wave_return=True, wave_plot=True, directory=None):\n","        wave_original = []\n","        wave_reconstructions = []\n","        originals, reconstructions, error = self.reconstruct() \n","        if plot:\n","            self.plot_reconstructions(originals, reconstructions)\n","        if wave_return:\n","            wave_original = self.waveform_generator(originals)\n","            wave_reconstructions = self.waveform_generator(reconstructions)\n","            if wave_plot:\n","                self.plot_waveform(wave_original, len(wave_original), directory=\"originals\")\n","                self.plot_waveform(wave_reconstructions, len(wave_reconstructions), directory=\"reconstructions\")\n","\n","\n","        return originals, reconstructions, error\n","\n","\n","class TrainModel:\n","\n","    def __init__(self, model):\n","        self._model = model\n","\n","    def wandb_init(self, config, keys=[\"audio_length\", \"win_length\", \"batch_size\"]):\n","        try:\n","            run_name = \"AE_\"\n","            for key in keys:\n","                if key in config.keys():\n","                    run_name = run_name + key + \":\" + str(config[key]) + \"_\"\n","                else:\n","                    run_name = run_name + str(key)\n","\n","            wandb.login()\n","            wandb.finish()\n","            wandb.init(project=\"AE-Jaguas\", config=config)\n","            wandb.run.name = run_name\n","            wandb.run.save()\n","            wandb.watch(self._model, F.mse_loss, log=\"all\", log_freq=1)\n","            is_wandb_enable = True         \n","        except Exception as e:\n","            print(e)\n","            is_wandb_enable = False\n","\n","        return is_wandb_enable, run_name\n","\n","    def wandb_logging(self, dict):\n","        for keys in dict:\n","            wandb.log({keys: dict[keys]})\n","\n","\n","    def fordward(self, training_loader, test_loader, config):\n","        iterator = iter(test_loader)\n","        wandb_enable, run_name = self.wandb_init(config)\n","        optimizer = config[\"optimizer\"]\n","        scheduler = config[\"scheduler\"]\n","\n","        train_res_recon_error = []\n","        train_res_perplexity = []\n","        logs = []\n","        best_loss = 10000\n","\n","        for epoch in range(config[\"num_epochs\"]):\n","            iterator_train = iter(training_loader)\n","            for i in xrange(config[\"num_training_updates\"]):\n","                self._model.train()\n","                try:\n","                    (data, _,_) = next(iterator_train)\n","                except Exception as e:\n","                    print(\"error\")\n","                    print(e)\n","                    logs.append(e)\n","                    continue\n","\n","                data = torch.reshape(data, (data.shape[0] * data.shape[1], data.shape[2], data.shape[3]))\n","                data = torch.unsqueeze(data,1)\n","                data = data.to(device)\n","\n","                optimizer.zero_grad()\n","                data_recon = self._model(data)\n","\n","                loss = F.mse_loss(data_recon, data)\n","                loss.backward()\n","\n","                optimizer.step()\n","                print(f'epoch: {epoch+1} of {config[\"num_epochs\"]} \\t iteration: {(i+1)} of {config[\"num_training_updates\"]} \\t loss: {np.round(loss.item(),4)}')\n","                dict = {\"loss\":loss.item()}\n","                self.wandb_logging(dict)\n","                                \n","                \n","                if (i+1) % 20 == 0:\n","                    try:\n","                        test_ = TestModel(self._model, iterator, 8)\n","                        #torch.save(model.state_dict(),f'model_{epoch}_{i}.pkl')\n","                        originals, reconstructions, test_error = test_.reconstruct()\n","                        fig = test_.plot_reconstructions(originals, reconstructions, 8)\n","                        images = wandb.Image(fig, caption= f\"recon_error: {np.round(test_error.item(),4)}\")\n","                        self.wandb_logging({\"examples\": images})\n","                        \n","                    except Exception as e:\n","                        print(\"error\")\n","                        logs.append(e)\n","                        continue\n","                else:\n","                    pass\n","\n","                if loss < 30:\n","                    wandb.alert(\n","                    title='High accuracy',\n","                    text=f'Recon error {loss} is lower than 0.5',\n","                    level=AlertLevel.WARN,\n","                    wait_duration=timedelta(minutes=5)\n","                                )        \n","                    torch.save(model.state_dict(),f'{run_name}_low_error.pkl')\n","                else:\n","                    pass\n","            \n","            scheduler.step()\n","            torch.cuda.empty_cache()\n","            time = datetime.datetime.now()\n","            torch.save(self._model.state_dict(),f'{time.hour}_{time.minute}_{run_name}_{epoch}.pkl')\n","            output.clear()\n","            print(optimizer.state_dict()[\"param_groups\"][0][\"lr\"])\n","\n","        wandb.finish()\n","        return self._model, logs, run_name"],"metadata":{"id":"MPQR_aIPcZ7-","executionInfo":{"status":"ok","timestamp":1658117794699,"user_tz":300,"elapsed":285,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["Training = TrainModel(model)\n","time = datetime.datetime.now()\n","model, logs, run_name = Training.fordward(training_loader, test_loader, config)\n","torch.save(model.state_dict(),f'{time.hour}_{time.minute}_{run_name}.pkl')\n","torch.save(model.state_dict(),f'{run_name}.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6YtKCwnNnDYP","executionInfo":{"status":"error","timestamp":1658117888699,"user_tz":300,"elapsed":94002,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}},"outputId":"3b449556-325f-47b6-b6a3-3bfb445468db"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.21"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/wandb/run-20220718_041636-1aq4pssh</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/danielnieto/AE-Jaguas/runs/1aq4pssh\" target=\"_blank\">trim-jazz-154</a></strong> to <a href=\"https://wandb.ai/danielnieto/AE-Jaguas\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 1 of 502 \t loss: 2679.6958\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 2 of 502 \t loss: 2586.1777\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 3 of 502 \t loss: 2639.6812\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 4 of 502 \t loss: 2328.24\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 5 of 502 \t loss: 2775.7886\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 6 of 502 \t loss: 3190.8325\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 7 of 502 \t loss: 2670.0789\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 8 of 502 \t loss: 2954.3682\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 9 of 502 \t loss: 2372.272\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 10 of 502 \t loss: 2888.2771\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 11 of 502 \t loss: 2175.7781\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 12 of 502 \t loss: 2658.6887\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 13 of 502 \t loss: 2758.7732\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 14 of 502 \t loss: 2424.1804\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 15 of 502 \t loss: 2235.5979\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 16 of 502 \t loss: 2607.2913\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 17 of 502 \t loss: 2514.031\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 18 of 502 \t loss: 3173.9165\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 19 of 502 \t loss: 2256.5793\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 20 of 502 \t loss: 2963.5745\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 21 of 502 \t loss: 2471.0674\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 22 of 502 \t loss: 2707.5762\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 23 of 502 \t loss: 2771.4131\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 24 of 502 \t loss: 2333.562\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 25 of 502 \t loss: 2272.1812\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 26 of 502 \t loss: 2689.9001\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 27 of 502 \t loss: 2883.8372\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 28 of 502 \t loss: 2826.2527\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 29 of 502 \t loss: 2601.0522\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 30 of 502 \t loss: 2314.0933\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 31 of 502 \t loss: 2499.969\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 32 of 502 \t loss: 2048.1206\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 33 of 502 \t loss: 2723.4326\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 34 of 502 \t loss: 2482.7419\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 35 of 502 \t loss: 2111.8567\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 36 of 502 \t loss: 2780.0588\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 37 of 502 \t loss: 2402.2917\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 38 of 502 \t loss: 1947.4187\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 39 of 502 \t loss: 2440.5081\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 40 of 502 \t loss: 2500.0276\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 41 of 502 \t loss: 2301.7771\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 42 of 502 \t loss: 2331.6873\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 43 of 502 \t loss: 2710.7878\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 44 of 502 \t loss: 2537.6465\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 45 of 502 \t loss: 2470.9448\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 46 of 502 \t loss: 2600.9702\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 47 of 502 \t loss: 2126.0784\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 48 of 502 \t loss: 3006.7061\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 49 of 502 \t loss: 2544.46\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","encoder_shape:  torch.Size([32, 32, 63, 63])\n","epoch: 1 of 6 \t iteration: 50 of 502 \t loss: 2444.2939\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n","torch.Size([4, 515, 515])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e08ee697d596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfordward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{time.hour}_{time.minute}_{run_name}.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{run_name}.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-950000b53f81>\u001b[0m in \u001b[0;36mfordward\u001b[0;34m(self, training_loader, test_loader, config)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Jaguas_DataLoader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \"\"\"\n\u001b[1;32m     59\u001b[0m         \u001b[0mpath_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mresampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m22050\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0maudio_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mresampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/backend/sox_io_backend.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     ret = torch.ops.torchaudio.sox_io_load_audio_file(\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[""],"metadata":{"id":"w5sjhlDScl3G","executionInfo":{"status":"aborted","timestamp":1658117888697,"user_tz":300,"elapsed":186,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}}},"execution_count":null,"outputs":[]}]}