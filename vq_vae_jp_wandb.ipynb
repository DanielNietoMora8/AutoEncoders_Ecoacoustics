{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11835,"status":"ok","timestamp":1649828880142,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"In9UTndxqdMe"},"outputs":[],"source":["from google.colab import drive, output\n","drive.mount('/content/drive')\n","import sys\n","%cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n","#sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/data')\n","#sys.path.append('/content/drive/MyDrive/Deep Learning/AutoEncoders/Project/VQVAE_Working/models')\n","sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n","sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n","sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n","%load_ext autoreload\n","%autoreload 1\n","!pip install torchaudio\n","!pip install wandb --upgrade\n","!wandb login\n","output.clear()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10954,"status":"ok","timestamp":1649828891092,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"JABwOJv4qVAS","outputId":"a18b69e4-0373-458b-f90e-d06367584692"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielnieto\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["from __future__ import print_function\n","import os\n","import sys\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from six.moves import xrange\n","\n","#import umap\n","import wandb\n","import torch\n","torch.cuda.empty_cache()\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","from scipy import signal\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","from torch.utils.data import random_split\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import torch.nn.functional as F\n","\n","#from ResidualStack import ResidualStack\n","#from Residual import Residual\n","\n","from Jaguas_DataLoader import SoundscapeData\n","from Models import Model\n","from Models import Encoder\n","from Models import Decoder\n","from Models import VectorQuantizer\n","from Models import VectorQuantizerEMA\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = xm.xla_device()\n","print(device)\n","\n","from datetime import timedelta\n","import wandb\n","from wandb import AlertLevel\n","\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"QxU_YNsDqVAZ"},"source":["## Train\n","\n","We use the hyperparameters from the author's code:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"elapsed":13092,"status":"ok","timestamp":1649828904178,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"S9UACcjeqVAZ","outputId":"3aae8371-ef58-4845-cfbf-61d8c3a3c6c4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.14"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/wandb/run-20220413_054816-15mxi2ul</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/danielnieto/VQ-VAE-Jaguas/runs/15mxi2ul\" target=\"_blank\">icy-snow-127</a></strong> to <a href=\"https://wandb.ai/danielnieto/VQ-VAE-Jaguas\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":3}],"source":["root_path = '/content/drive/Shareddrives/ConservacionBiologicaIA/Datos/Jaguas_2018'\n","\n","\n","dataset = SoundscapeData(root_path, 1, \"wav\")\n","dataset_train, dataset_test = random_split(dataset,\n","                                           [round(len(dataset)*0.10), len(dataset) - round(len(dataset)*0.10)], \n","                                           generator=torch.Generator().manual_seed(1024))\n","\n","config = {\n","    \"batch_size\" : 32,\n","    \"num_epochs\": 15,\n","    \"num_training_updates\" : len(dataset_train),\n","    \"num_hiddens\" : 64,\n","    \"embedding_dim\" : 128,\n","    \"num_embeddings\" : 64,\n","    \"commitment_cost\" : 0.25,\n","    \"decay\" : 0.99,\n","    \"learning_rate\" : 1e-3,\n","    \"dataset\": \"Audios Jaguas\",\n","    \"architecture\": \"VQ-VAE\",\n","}\n","\n","training_loader = DataLoader(dataset_train, batch_size=config[\"batch_size\"])\n","test_loader = DataLoader(dataset_test, batch_size=config[\"batch_size\"])\n","\n","\n","model = Model(config[\"num_hiddens\"],\n","              config[\"num_embeddings\"], config[\"embedding_dim\"], \n","              config[\"commitment_cost\"], config[\"decay\"]).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"], amsgrad=False)\n","\n","\n","wandb.finish()\n","wandb.init(project=\"VQ-VAE-Jaguas\", config=config)\n","wandb.watch(model)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1007,"status":"ok","timestamp":1649828905179,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"-kcUIKsdyRsq"},"outputs":[],"source":["def testModel(model, iterator):\n","    model.eval()\n","    (valid_originals, _,_) = next( iterator)\n","    valid_originals = torch.reshape(valid_originals, (valid_originals.shape[0] * valid_originals.shape[1], \n","                                                  valid_originals.shape[2], valid_originals.shape[3]))\n","    valid_originals = torch.unsqueeze(valid_originals,1)\n","\n","    valid_originals = valid_originals.to(device)\n","\n","    vq_output_eval = model._pre_vq_conv(model._encoder(valid_originals))\n","    _, valid_quantize, _, _ = model._vq_vae(vq_output_eval)\n","    valid_reconstructions = model._decoder(valid_quantize)\n","    output =  torch.cat((valid_originals[0:8], valid_reconstructions[0:8]), 0)\n","    img_grid = make_grid(output,nrow= 8,pad_value=20)\n","\n","    recon_error = F.mse_loss(valid_originals, valid_reconstructions)\n","\n","    fig, ax = plt.subplots(figsize=(20,5))\n","    ax.imshow(img_grid[1,:,:].cpu(), vmin=0,vmax=1)\n","    ax.axis(\"off\")\n","    plt.show()\n","    return fig, recon_error\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jInS0IjTqVAa","outputId":"6466d84e-2aa1-482e-d50f-2eb0aa5c71c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 1 of 2007 \t loss: 86.1518 \t recon_error: 85.9712 \t vq_loss: 0.1806\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 2 of 2007 \t loss: 85.9721 \t recon_error: 85.9712 \t vq_loss: 0.0009\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 3 of 2007 \t loss: 85.9718 \t recon_error: 85.9712 \t vq_loss: 0.0006\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 4 of 2007 \t loss: 85.9715 \t recon_error: 85.9712 \t vq_loss: 0.0003\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 5 of 2007 \t loss: 85.9691 \t recon_error: 85.9689 \t vq_loss: 0.0002\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 6 of 2007 \t loss: 85.9575 \t recon_error: 85.9573 \t vq_loss: 0.0002\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 7 of 2007 \t loss: 85.941 \t recon_error: 85.9404 \t vq_loss: 0.0006\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 8 of 2007 \t loss: 85.9148 \t recon_error: 85.9129 \t vq_loss: 0.0019\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 9 of 2007 \t loss: 85.8974 \t recon_error: 85.8914 \t vq_loss: 0.006\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 10 of 2007 \t loss: 86.0895 \t recon_error: 86.0822 \t vq_loss: 0.0073\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 11 of 2007 \t loss: 85.7786 \t recon_error: 85.7753 \t vq_loss: 0.0033\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 12 of 2007 \t loss: 85.7429 \t recon_error: 85.7408 \t vq_loss: 0.002\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 13 of 2007 \t loss: 85.8037 \t recon_error: 85.8023 \t vq_loss: 0.0014\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 14 of 2007 \t loss: 85.8506 \t recon_error: 85.8493 \t vq_loss: 0.0012\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 15 of 2007 \t loss: 85.8788 \t recon_error: 85.8776 \t vq_loss: 0.0011\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 16 of 2007 \t loss: 85.8914 \t recon_error: 85.8903 \t vq_loss: 0.0012\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 17 of 2007 \t loss: 85.8931 \t recon_error: 85.8918 \t vq_loss: 0.0013\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 18 of 2007 \t loss: 85.8847 \t recon_error: 85.8831 \t vq_loss: 0.0015\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 19 of 2007 \t loss: 85.8665 \t recon_error: 85.8646 \t vq_loss: 0.0019\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 20 of 2007 \t loss: 85.8413 \t recon_error: 85.8388 \t vq_loss: 0.0025\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 21 of 2007 \t loss: 85.7999 \t recon_error: 85.7963 \t vq_loss: 0.0037\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 22 of 2007 \t loss: 85.7552 \t recon_error: 85.7493 \t vq_loss: 0.0059\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 23 of 2007 \t loss: 85.7123 \t recon_error: 85.7016 \t vq_loss: 0.0107\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 24 of 2007 \t loss: 85.7135 \t recon_error: 85.6924 \t vq_loss: 0.0211\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 25 of 2007 \t loss: 85.769 \t recon_error: 85.7272 \t vq_loss: 0.0418\n","torch.Size([1888, 1, 129, 129])\n","epoch: 0 of 15 \t iteration: 26 of 2007 \t loss: 85.815 \t recon_error: 85.7483 \t vq_loss: 0.0667\n","torch.Size([1888, 1, 129, 129])\n"]}],"source":["model.train()\n","train_res_recon_error = []\n","train_res_perplexity = []\n","iterator = iter(test_loader)\n","wandb.watch(model, F.mse_loss, log=\"all\", log_freq=1)\n","error_files = []\n","\n","for epoch in range(config[\"num_epochs\"]):\n","  for i in xrange(config[\"num_training_updates\"]):\n","      model.train()\n","      try:\n","         (data, _,_) = next(iter(training_loader))\n","      except:\n","        error_files.append[i]\n","        continue\n","          \n","      data = torch.reshape(data, (data.shape[0] * data.shape[1], data.shape[2], data.shape[3]))\n","      data = torch.unsqueeze(data,1)\n","      data = data.to(device)\n","      \n","      \n","      optimizer.zero_grad()\n","      vq_loss, data_recon, perplexity = model(data)\n","      print(data_recon.shape)\n","      \n","      recon_error = F.mse_loss(data_recon, data) #/ data_variance\n","      loss = recon_error + vq_loss\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      wandb.log({\"loss\":loss.item(),\n","                 \"perplexity\":perplexity.item(),\n","                 \"recon_error\": recon_error,\n","                 \"vq_loss\": vq_loss})\n","      print(f'epoch: {epoch} of {config[\"num_epochs\"]} \\t iteration: {(i+1)} of {config[\"num_training_updates\"]} \\t loss: {np.round(loss.item(),4)} \\t recon_error: {np.round(recon_error.item(),4)} \\t vq_loss: {np.round(vq_loss.item(),4)}')\n","      # torch.cuda.empty_cache()\n","      # import gc\n","      # gc.collect()\n","      # torch.cuda.empty_cache()\n","      \n","      if (i+1) % 100 == 0:\n","        #torch.save(model.state_dict(),f'model_{epoch}_{i}.pkl')\n","        fig, test_error = testModel(model, iterator)\n","        images = wandb.Image(fig, caption= f\"recon_error: {np.round(test_error.item(),4)}\")\n","        wandb.log({\"examples\": images})\n","        #wandb.log({\"config\": config})\n","\n","      if recon_error < 0.8:\n","        wandb.alert(\n","          title='High accuracy',\n","          text=f'Recon error {recon_error} is lower than .5',\n","          level=AlertLevel.WARN,\n","          wait_duration=timedelta(minutes=5)\n","                    )\n","        torch.save(model.state_dict(),f'model_{epoch}_{i}.pkl')\n","                  \n","wandb.finish()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlcghc1e_B6s"},"outputs":[],"source":["torch.cuda.memory_summary(device=None, abbreviated=False)\n","torch.save(model.state_dict(),f'model_{epoch}_{i}.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IL0WeGtiVSha"},"outputs":[],"source":["model.load_state_dict(torch.load('model_1_12999_5s.pkl', map_location=torch.device('cpu')))"]},{"cell_type":"markdown","metadata":{"id":"1evswH8XqVAb"},"source":["## Plot Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1sHhv1vSqVAb"},"outputs":[],"source":["train_res_recon_error_smooth = savgol_filter(train_res_recon_error, 201, 7)\n","train_res_perplexity_smooth = savgol_filter(train_res_perplexity, 201, 7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQ-jj2x4qVAb"},"outputs":[],"source":["f = plt.figure(figsize=(16,8))\n","ax = f.add_subplot(1,2,1)\n","ax.plot(train_res_recon_error_smooth)\n","ax.set_yscale('log')\n","ax.set_title('Smoothed NMSE.')\n","ax.set_xlabel('iteration')\n","\n","ax = f.add_subplot(1,2,2)\n","ax.plot(train_res_perplexity_smooth)\n","ax.set_title('Smoothed Average codebook usage (perplexity).')\n","ax.set_xlabel('iteration')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZF47bSqJzZi"},"outputs":[],"source":["model.eval()\n","validation_loader = training_loader\n","(valid_originals, _,_,_) = next(iter(validation_loader),30000)"]},{"cell_type":"markdown","metadata":{"id":"3FOI5ZMQqVAb"},"source":["## View Reconstructions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3wn0zzb1qVAb"},"outputs":[],"source":["model.eval()\n","validation_loader = training_loader\n","(valid_originals, _,_,_) = next(iter(validation_loader),3000)\n","valid_originals = torch.reshape(valid_originals, (valid_originals.shape[0] * valid_originals.shape[1], valid_originals.shape[2], valid_originals.shape[3]))\n","valid_originals = torch.unsqueeze(valid_originals,1)\n","\n","print(valid_originals.shape)\n","\n","\n","\n","valid_originals = valid_originals.to(device)\n","\n","vq_output_eval = model._pre_vq_conv(model._encoder(valid_originals))\n","_, valid_quantize, _, _ = model._vq_vae(vq_output_eval)\n","valid_reconstructions = model._decoder(valid_quantize)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb9ZC7vlEo9W"},"outputs":[],"source":["def showTensor(tensor, dim):\n","    return tensor[dim,:,:,:].cpu().detach().numpy()[0,:,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zkiwi4qAc6j8"},"outputs":[],"source":["plt.figure(figsize=(40,40))\n","\n","plt.subplot(5,2,1)\n","plt.imshow(showTensor(valid_originals,0),vmin=0,vmax=0.7)\n","plt.subplot(5,2,2)\n","plt.imshow(showTensor(valid_reconstructions,0),vmin=0,vmax=0.7)\n","plt.subplot(5,2,3)\n","plt.imshow(showTensor(valid_originals,1),vmin=0,vmax=0.7)\n","plt.subplot(5,2,4)\n","plt.imshow(showTensor(valid_reconstructions,1),vmin=0,vmax=0.7)\n","plt.subplot(5,2,5)\n","plt.imshow(showTensor(valid_originals,2),vmin=0,vmax=0.7)\n","plt.subplot(5,2,6)\n","plt.imshow(showTensor(valid_reconstructions,2),vmin=0,vmax=0.7)\n","plt.subplot(5,2,7)\n","plt.imshow(showTensor(valid_originals,3),vmin=0,vmax=0.7)\n","plt.subplot(5,2,8)\n","plt.imshow(showTensor(valid_reconstructions,3),vmin=0,vmax=0.7)\n","plt.subplot(5,2,9)\n","plt.imshow(showTensor(valid_originals,4),vmin=0,vmax=0.7)\n","plt.subplot(5,2,10)\n","plt.imshow(showTensor(valid_reconstructions,4),vmin=0,vmax=0.7)\n","#plt.savefig(\"VQVAE_Sin_Residual.pdf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AukONRlcqVAc"},"outputs":[],"source":["(train_originals, _,_,_) = next(iter(training_loader))\n","train_originals = train_originals.to(device)\n","_, train_reconstructions, _, _ = model._vq_vae(train_originals)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GL7sIFROqVAc"},"outputs":[],"source":["def show(img):\n","    npimg = img.numpy()\n","    fig = plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","    fig.axes.get_xaxis().set_visible(False)\n","    fig.axes.get_yaxis().set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EhjMrl4UqVAc"},"outputs":[],"source":["show(make_grid(valid_reconstructions.cpu().data)+0.5, )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5fVnxxFqVAc"},"outputs":[],"source":["show(make_grid(valid_originals.cpu()+0.5))"]},{"cell_type":"markdown","metadata":{"id":"-DIk0rXfqVAc"},"source":["## View Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iRwMhoYzqVAd"},"outputs":[],"source":["proj = umap.UMAP(n_neighbors=3,\n","                 min_dist=0.1,\n","                 metric='cosine').fit_transform(model._vq_vae._embedding.weight.data.cpu())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AIjfS0-_qVAd"},"outputs":[],"source":["plt.scatter(proj[:,0], proj[:,1], alpha=0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SLZaKySqVAd"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"vq_vae_jp_wandb.ipynb","provenance":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}