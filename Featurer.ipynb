{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18052,"status":"ok","timestamp":1678388233869,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"2OLjDqbgadV7","outputId":"a38c57aa-e4dd-46fe-aca2-9e6bd6d0cd65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on colab\n","/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\n"]}],"source":["if 'google.colab' in str(get_ipython()):\n","    import sys\n","    from google.colab import drive, output\n","    drive.mount('/content/drive')\n","    !pip install torchaudio\n","    !pip install wandb --upgrade\n","    # !wandb login\n","    # !pip install umap-learn\n","    output.clear()\n","    print(\"Running on colab\")\n","    %load_ext autoreload\n","    %autoreload 1\n","    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n","    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n","    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n","else:\n","    print(\"Running local\")\n","    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\""]},{"cell_type":"code","source":["str(get_ipython())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"VFeyGVCOvHL2","executionInfo":{"status":"ok","timestamp":1678388274161,"user_tz":300,"elapsed":175,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}},"outputId":"b5805625-2de3-4319-d74d-c6f5ac257e11"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<google.colab._shell.Shell object at 0x7f46babce940>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4523,"status":"ok","timestamp":1678388238390,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"ucIGvQ7GczZb","outputId":"0bdf55db-463b-4047-8259-f7dc96b407f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["# from __future__ import print_function\n","# from __future__ import print_function\n","import os\n","import numpy as np\n","\n","from six.moves import xrange\n","import datetime\n","import gc\n","\n","from scipy import signal\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import random_split\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid\n","import torchaudio.transforms as audio_transform\n","\n","#from ResidualStack import ResidualStack\n","#from Residual import Residual\n","\n","from Jaguas_DataLoader import SoundscapeData\n","from Models import ConvAE as AE\n","from AE_training_functions import TestModel, TrainModel\n","from AE_Clustering import AE_Clustering \n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = xm.xla_device()\n","print(device)\n","\n","from datetime import timedelta\n","import wandb\n","from wandb import AlertLevel\n","\n","# wandb.login()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8199,"status":"ok","timestamp":1678388246582,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"},"user_tz":300},"id":"qemaBluJa22A","outputId":"30519d6b-ea58-4423-cb89-b2c5ffb7d854"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":3}],"source":["# root_path = \"ConservacionBiologicaIA/Datos/Jaguas_2018\"\n","model_name = f\"{root}/temporal/models/model_AE_batch_size_14_num_hiddens_64__day_9_hour_4_final.pth\"\n","config = torch.load(f'temporal/configs/config_AE_batch_size_14_num_hiddens_64__day_9_hour_4.pth', map_location=torch.device('cpu'))\n","model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n","dataset_test = torch.load(f'temporal/datasets/dataset_test_ae_jaguas_9_70%.pth')\n","dataset_train = torch.load(f'temporal/datasets/dataset_train_ae_jaguas_9_70%.pth')\n","model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8fck5_upr5vE","executionInfo":{"status":"ok","timestamp":1678388246583,"user_tz":300,"elapsed":9,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}}},"outputs":[],"source":["# training_loader = DataLoader(dataset_train, batch_size=1)\n","# test_loader = DataLoader(dataset_test, batch_size=1)\n","# iterator = iter(training_loader)\n","# testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n","# originals, reconstructions, encodings, label, loss = testing.reconstruct()\n","# encodings_size = encodings[0].shape\n","\n","# training_recorder_list = []\n","# training_hour_list = []\n","# training_minute_list = []\n","# delete_samples = []\n","\n","# for id, item in enumerate(dataset_train):\n","#     if id% 50 == 0:\n","#         print(f\"id: {id + 1} of {len(dataset_train)}\")\n","#     model.to(\"cuda\")\n","#     try:\n","#         originals, reconstructions, encodings, label, loss = testing.reconstruct()\n","#     except:\n","#         print(f\"error id: {id}\")\n","#         delete_samples.append(id)\n","#         continue\n","#     # training_samples_list.append(encodings)\n","#     training_recorder_list.append(label[\"recorder\"])\n","#     training_hour_list.append(label[\"hour\"])\n","#     training_minute_list.append(label[\"minute\"])\n","\n","# torch.save(training_recorder_list, \"training_recorder_list.pth\")\n","# torch.save(training_hour_list, \"training_hour_list.pth\")\n","# torch.save(training_minute_list, \"training_minute_list.pth\")\n","# training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n","# torch.save(training_labels_list, \"training_labels_list.pth\")\n","# torch.save(delete_samples, \"corrupted_samples_list.pth\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"id":"SvnFOiVpq63a","executionInfo":{"status":"error","timestamp":1678388483545,"user_tz":300,"elapsed":200,"user":{"displayName":"DANIEL ALEXIS NIETO MORA","userId":"09305600849699039845"}},"outputId":"58f9d9b0-d822-4f3b-c8d2-6e801391f3b2"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-7a4252e92951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moriginals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/AE_training_functions.py\u001b[0m in \u001b[0;36mreconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mvalid_originals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         valid_originals = torch.reshape(valid_originals, (valid_originals.shape[0] * valid_originals.shape[1]\n\u001b[1;32m     98\u001b[0m                                                           \u001b[0;34m*\u001b[0m \u001b[0mvalid_originals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_originals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Jaguas_DataLoader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m                  \"second\": np.repeat(second, self.original_length//self.audio_length)}\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mresampling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m22050\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0maudio_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mresampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchaudio/backend/sox_io_backend.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_fallback_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchaudio/io/_compat.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(src, frame_offset, num_frames, convert, channels_first, format)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m ) -> Tuple[torch.Tensor, int]:\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg_StreamReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to open the input \"/media/mirp_ai/DATA1/Jaguas_2018/G19_m/G19_20180520_022400.wav\" (No such file or directory)."]}],"source":["training_loader = DataLoader(dataset_train, batch_size=1)\n","iterator = iter(training_loader)\n","testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n","originals, reconstructions, encodings, label, loss, path = testing.reconstruct()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6H8eJRJq63a","outputId":"3ef5c6dd-bc39-4616-dc96-bec98b5ce6cd"},"outputs":[{"data":{"text/plain":["tensor([19, 19, 19, 19, 19, 52, 52, 52, 52, 52, 24, 24, 24, 24, 24])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["label[\"recorder\"].reshape(label[\"recorder\"].shape[0]*label[\"recorder\"].shape[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6jPCv40Ugk0I","outputId":"b093c1e1-5419-407e-a180-ab158e8f79ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["id: 1 of 14047\n","id: 501 of 14047\n","id: 1001 of 14047\n","id: 1501 of 14047\n","id: 2001 of 14047\n"]}],"source":["training_loader = DataLoader(dataset_train, batch_size=1)\n","test_loader = DataLoader(dataset_test, batch_size=1)\n","iterator = iter(training_loader)\n","testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n","encodings_size = encodings[0].shape\n","\n","training_recorder_list = []\n","training_hour_list = []\n","training_minute_list = []\n","delete_samples = []\n","training_path_samples = []\n","training_samples_list_torch = torch.ones(len(dataset_train), 5184).to(\"cuda\")\n","\n","for id, item in enumerate(dataset_train):\n","    if id% 500 == 0:\n","        print(f\"id: {id + 1} of {len(dataset_train)}\")\n","    model.to(\"cuda\")\n","    try:\n","        originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n","    except:\n","        print(f\"error id: {id}\")\n","        delete_samples.append(id)\n","        continue\n","\n","    encodings_size = encodings[0].shape\n","    encodings = encodings.to(\"cuda\").detach()\n","    encodings = encodings.reshape(encodings.shape[0],\n","                                encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n","    encoding = encodings.squeeze(dim=0)\n","    # training_samples_list.append(encodings)\n","    training_samples_list_torch[id] = encodings\n","    training_recorder_list.append(label[\"recorder\"].reshape(label[\"recorder\"].shape[0]*label[\"recorder\"].shape[1]))\n","    training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n","    training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n","    \n","    path = \n","    training_path_samples.append()\n","\n","torch.save(training_samples_list_torch, \"Features/training_samples_list_torch_70%.pth\")\n","torch.save(training_recorder_list, \"Features/training_recorder_list_70%.pth\")\n","torch.save(training_hour_list, \"Features/training_hour_list_70%.pth\")\n","torch.save(training_minute_list, \"Features/training_minute_list_70%.pth\")\n","training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n","torch.save(training_labels_list, \"Features/training_labels_list_70%.pth\")\n","torch.save(delete_samples, \"Features/corrupted_samples_list_70%.pth\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}