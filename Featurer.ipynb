{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18052,
     "status": "ok",
     "timestamp": 1678388233869,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "2OLjDqbgadV7",
    "outputId": "a38c57aa-e4dd-46fe-aca2-9e6bd6d0cd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    # !wandb login\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4523,
     "status": "ok",
     "timestamp": 1678388238390,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ucIGvQ7GczZb",
    "outputId": "0bdf55db-463b-4047-8259-f7dc96b407f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import xrange\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio.transforms as audio_transform\n",
    "\n",
    "#from ResidualStack import ResidualStack\n",
    "#from Residual import Residual\n",
    "\n",
    "from Jaguas_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "print(device)\n",
    "\n",
    "from datetime import timedelta\n",
    "import wandb\n",
    "from wandb import AlertLevel\n",
    "\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8199,
     "status": "ok",
     "timestamp": 1678388246582,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "qemaBluJa22A",
    "outputId": "30519d6b-ea58-4423-cb89-b2c5ffb7d854"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root_path = \"ConservacionBiologicaIA/Datos/Jaguas_2018\"\n",
    "model_name = f\"{root}/temporal/models/model_AE_batch_size_14_num_hiddens_64__day_9_hour_4_final.pth\"\n",
    "config = torch.load(f'temporal/configs/config_AE_batch_size_14_num_hiddens_64__day_9_hour_4.pth', map_location=torch.device('cpu'))\n",
    "model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n",
    "dataset_test = torch.load(f'temporal/datasets/dataset_test_ae_jaguas_9_70%.pth')\n",
    "dataset_train = torch.load(f'temporal/datasets/dataset_train_ae_jaguas_9_70%.pth')\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "error",
     "timestamp": 1678388483545,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "SvnFOiVpq63a",
    "outputId": "58f9d9b0-d822-4f3b-c8d2-6e801391f3b2"
   },
   "outputs": [],
   "source": [
    "training_loader = DataLoader(dataset_train, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "originals, reconstructions, encodings, label, loss, path = testing.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jPCv40Ugk0I",
    "outputId": "b093c1e1-5419-407e-a180-ab158e8f79ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 500 of 6020\n",
      "id: 1000 of 6020\n",
      "id: 1500 of 6020\n",
      "error id: 1842\n",
      "id: 2000 of 6020\n",
      "id: 2500 of 6020\n",
      "id: 3000 of 6020\n",
      "id: 3500 of 6020\n",
      "id: 4000 of 6020\n",
      "id: 4500 of 6020\n",
      "id: 5000 of 6020\n",
      "id: 5500 of 6020\n",
      "id: 6000 of 6020\n"
     ]
    }
   ],
   "source": [
    "from six.moves import xrange\n",
    "training_loader = DataLoader(dataset_train, batch_size=1)\n",
    "test_loader = DataLoader(dataset_test, batch_size=1)\n",
    "iterator = iter(test_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "encodings_size = encodings[0].shape\n",
    "\n",
    "training_recorder_list = []\n",
    "training_hour_list = []\n",
    "training_minute_list = []\n",
    "delete_samples = []\n",
    "training_path_samples = []\n",
    "training_samples_list_torch = []\n",
    "for id in xrange(len(test_loader)):\n",
    "#     if (id+1)%3 == 0:\n",
    "#         break\n",
    "    if (id+1)% 500 == 0:\n",
    "        print(f\"id: {id + 1} of {len(dataset_test)}\")\n",
    "    try:\n",
    "        originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "    except:\n",
    "        print(f\"error id: {id}\")\n",
    "        delete_samples.append(id)\n",
    "        continue\n",
    "\n",
    "    encodings_size = encodings[0].shape\n",
    "    encodings = encodings.to(\"cuda\").detach()\n",
    "    encodings = encodings.reshape(encodings.shape[0],\n",
    "                                encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "    encoding = encodings.squeeze(dim=0)\n",
    "    training_samples_list_torch.append(encodings)\n",
    "    training_recorder_list.append(label[\"recorder\"].reshape(label[\"recorder\"].shape[0]*label[\"recorder\"].shape[1]))\n",
    "    training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "    training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "    \n",
    "    \n",
    "    path = np.asarray(path)\n",
    "    path = np.repeat(path, 5)\n",
    "    training_path_samples.append(path)\n",
    "\n",
    "training_recorder_list = torch.cat(training_recorder_list,dim=0)\n",
    "training_hour_list = torch.cat(training_hour_list,dim=0)\n",
    "training_minute_list = torch.cat(training_minute_list,dim=0)\n",
    "training_samples_list_torch = torch.cat(training_samples_list_torch, dim=0)\n",
    "\n",
    "torch.save(training_path_samples, \"Features/test_path_samples.pth\")\n",
    "torch.save(training_samples_list_torch, \"Features/test_samples_list_torch_70%.pth\")\n",
    "torch.save(training_recorder_list, \"Features/test_recorder_list_70%.pth\")\n",
    "torch.save(training_hour_list, \"Features/test_hour_list_70%.pth\")\n",
    "torch.save(training_minute_list, \"Features/test_minute_list_70%.pth\")\n",
    "training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "torch.save(training_labels_list, \"Features/test_labels_list_70%.pth\")\n",
    "torch.save(delete_samples, \"Features/test_corrupted_samples_list_70%.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14048"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat(training_path_samples)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
