{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25668,
     "status": "ok",
     "timestamp": 1668985790347,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "2OLjDqbgadV7",
    "outputId": "3044f889-e976-42e3-f311-fb5f2acc4114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    import sys\n",
    "    from google.colab import drive, output\n",
    "    drive.mount('/content/drive')\n",
    "    !pip install torchaudio\n",
    "    !pip install wandb --upgrade\n",
    "    !wandb login\n",
    "    # !pip install umap-learn\n",
    "    output.clear()\n",
    "    print(\"Running on colab\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 1\n",
    "    %cd '/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project'\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Dataloader')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Models')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Modules')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/temporal')\n",
    "    sys.path.append('/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project/Extra_and_Unused')\n",
    "    root = \"/content/drive/MyDrive/PhD_Thesis_Experiments/DeepLearning/AutoEncoders/Project\"\n",
    "else:\n",
    "    print(\"Running local\")\n",
    "    root = \"/home/mirp_ai/Documents/Daniel_Nieto/PhD/AutoEncoders_Ecoacoustics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1668985790347,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "ucIGvQ7GczZb",
    "outputId": "6033772d-375b-45cd-9236-84ed9ee52921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielnieto\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "# from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import xrange\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torchaudio.transforms as audio_transform\n",
    "\n",
    "#from ResidualStack import ResidualStack\n",
    "#from Residual import Residual\n",
    "\n",
    "from Jaguas_DataLoader import SoundscapeData\n",
    "from Models import ConvAE as AE\n",
    "from AE_training_functions import TestModel, TrainModel\n",
    "from AE_Clustering import AE_Clustering \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = xm.xla_device()\n",
    "print(device)\n",
    "\n",
    "from datetime import timedelta\n",
    "import wandb\n",
    "from wandb import AlertLevel\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1668985792370,
     "user": {
      "displayName": "DANIEL ALEXIS NIETO MORA",
      "userId": "09305600849699039845"
     },
     "user_tz": 300
    },
    "id": "qemaBluJa22A",
    "outputId": "526ed5a7-96b8-4efa-f59e-166ebe7df31f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root_path = \"ConservacionBiologicaIA/Datos/Jaguas_2018\"\n",
    "model_name = f\"{root}/temporal/models/model_AE_batch_size_14_num_hiddens_64__day_9_hour_4_final.pth\"\n",
    "config = torch.load(f'temporal/configs/config_AE_batch_size_14_num_hiddens_64__day_9_hour_4.pth', map_location=torch.device('cpu'))\n",
    "model = AE(num_hiddens=config[\"num_hiddens\"]).to(device)\n",
    "dataset_test = torch.load(f'temporal/datasets/dataset_test_ae_jaguas_9_70%.pth')\n",
    "dataset_train = torch.load(f'temporal/datasets/dataset_train_ae_jaguas_9_70%.pth')\n",
    "model.load_state_dict(torch.load(f'{model_name}', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8fck5_upr5vE"
   },
   "outputs": [],
   "source": [
    "# training_loader = DataLoader(dataset_train, batch_size=1)\n",
    "# test_loader = DataLoader(dataset_test, batch_size=1)\n",
    "# iterator = iter(training_loader)\n",
    "# testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "# originals, reconstructions, encodings, label, loss = testing.reconstruct()\n",
    "# encodings_size = encodings[0].shape\n",
    "\n",
    "# training_recorder_list = []\n",
    "# training_hour_list = []\n",
    "# training_minute_list = []\n",
    "# delete_samples = []\n",
    "\n",
    "# for id, item in enumerate(dataset_train):\n",
    "#     if id% 50 == 0:\n",
    "#         print(f\"id: {id + 1} of {len(dataset_train)}\")\n",
    "#     model.to(\"cuda\")\n",
    "#     try:\n",
    "#         originals, reconstructions, encodings, label, loss = testing.reconstruct()\n",
    "#     except:\n",
    "#         print(f\"error id: {id}\")\n",
    "#         delete_samples.append(id)\n",
    "#         continue\n",
    "#     # training_samples_list.append(encodings)\n",
    "#     training_recorder_list.append(label[\"recorder\"])\n",
    "#     training_hour_list.append(label[\"hour\"])\n",
    "#     training_minute_list.append(label[\"minute\"])\n",
    "\n",
    "# torch.save(training_recorder_list, \"training_recorder_list.pth\")\n",
    "# torch.save(training_hour_list, \"training_hour_list.pth\")\n",
    "# torch.save(training_minute_list, \"training_minute_list.pth\")\n",
    "# training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "# torch.save(training_labels_list, \"training_labels_list.pth\")\n",
    "# torch.save(delete_samples, \"corrupted_samples_list.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(dataset_train, batch_size=3)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "originals, reconstructions, encodings, label, loss, path = testing.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 19, 19, 19, 19, 52, 52, 52, 52, 52, 24, 24, 24, 24, 24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[\"recorder\"].reshape(label[\"recorder\"].shape[0]*label[\"recorder\"].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jPCv40Ugk0I",
    "outputId": "b093c1e1-5419-407e-a180-ab158e8f79ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1 of 14047\n",
      "id: 501 of 14047\n",
      "id: 1001 of 14047\n",
      "id: 1501 of 14047\n",
      "id: 2001 of 14047\n"
     ]
    }
   ],
   "source": [
    "training_loader = DataLoader(dataset_train, batch_size=1)\n",
    "test_loader = DataLoader(dataset_test, batch_size=1)\n",
    "iterator = iter(training_loader)\n",
    "testing = TestModel(model, iterator, device=torch.device(\"cuda\"))\n",
    "encodings_size = encodings[0].shape\n",
    "\n",
    "training_recorder_list = []\n",
    "training_hour_list = []\n",
    "training_minute_list = []\n",
    "delete_samples = []\n",
    "training_path_samples = []\n",
    "training_samples_list_torch = torch.ones(len(dataset_train), 5184).to(\"cuda\")\n",
    "\n",
    "for id, item in enumerate(dataset_train):\n",
    "    if id% 500 == 0:\n",
    "        print(f\"id: {id + 1} of {len(dataset_train)}\")\n",
    "    model.to(\"cuda\")\n",
    "    try:\n",
    "        originals, reconstructions, encodings, label, loss, path = testing.reconstruct()\n",
    "    except:\n",
    "        print(f\"error id: {id}\")\n",
    "        delete_samples.append(id)\n",
    "        continue\n",
    "\n",
    "    encodings_size = encodings[0].shape\n",
    "    encodings = encodings.to(\"cuda\").detach()\n",
    "    encodings = encodings.reshape(encodings.shape[0],\n",
    "                                encodings.shape[1]*encodings.shape[2]*encodings.shape[3])\n",
    "    encoding = encodings.squeeze(dim=0)\n",
    "    # training_samples_list.append(encodings)\n",
    "    training_samples_list_torch[id] = encodings\n",
    "    training_recorder_list.append(label[\"recorder\"].reshape(label[\"recorder\"].shape[0]*label[\"recorder\"].shape[1]))\n",
    "    training_hour_list.append(label[\"hour\"].reshape(label[\"hour\"].shape[0]*label[\"hour\"].shape[1]))\n",
    "    training_minute_list.append(label[\"minute\"].reshape(label[\"minute\"].shape[0]*label[\"minute\"].shape[1]))\n",
    "    \n",
    "    path = \n",
    "    training_path_samples.append()\n",
    "\n",
    "torch.save(training_samples_list_torch, \"Features/training_samples_list_torch_70%.pth\")\n",
    "torch.save(training_recorder_list, \"Features/training_recorder_list_70%.pth\")\n",
    "torch.save(training_hour_list, \"Features/training_hour_list_70%.pth\")\n",
    "torch.save(training_minute_list, \"Features/training_minute_list_70%.pth\")\n",
    "training_labels_list = {\"recorder\": training_recorder_list, \"hour\": training_hour_list, \"minute\": training_minute_list}\n",
    "torch.save(training_labels_list, \"Features/training_labels_list_70%.pth\")\n",
    "torch.save(delete_samples, \"Features/corrupted_samples_list_70%.pth\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyML4rZj8OimUwjrD+/g3GML",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
